
# 第3章：ストレージと抽出

### 本章の概要
- 第２章ではデータモデルとクエリ言語について説明し、これらは開発者がデータベースにデータを渡す際のフォーマットとそれを取り出す仕組みのこと
- 本章では、同じことをデータベース側に観点から確認する
    - 与えられたデータを保存する方法
    - 要求された際にデータを見つける方法

### 根源的にデータベースに求められる機能
* 与えられたデータを保存する
* データを要求されたら返却する

> [!NOTE]
> 
> :memo:コメント
> 

## 3.1：データベースを駆動するデータ構造

### 最も単純なデータベースとその問題

#### 実装
* キー、値のペアをファイルの末尾に追加する
* 指定されたキーでファイルから検索し、値を返却する
```
db_set() {
    echo "$1,$2" >> database
}

db_get() {
    grep "^$1," database | sed -e "s/^$1,//"tail -n 1
}
```
#### 特徴と問題点
##### 特徴
* キーと値のペアはファイルの末尾に追加されるので、値を更新しても過去の値は上書きされない
* ファイルへの追記は効率的な処理のため、シンプルなわりにパフォーマンスを発揮する
* このようにログへの追記は多くのデータベースで実装されている

##### 問題点
* レコード数が増えた場合、読み取りパフォーマンスが悪化する
    * ファイル先頭から末尾までスキャンしてキーを探す必要がある
    * 検索のコストがO(n)となるため、レコード数が2倍になれば、検索時間も2倍になる

##### インデックスの必要性
* このように、データベースから特定のキーを効率的に見つけるためには、別のデータ構造が必要
    * インデックスを導入する

### インデックス

#### インデックスとは
* インデックスは、元データと追加で保存されるメタデータで、元データが格納された場所を探す際に使用される
* データベースの内容には影響しないが、パフォーマンスに影響する
* データの書き込みのたびに、インデックスも更新しなければならないため、書き込み速度が低下する

#### トレードオフ
* インデックスはうまく選択すれば
    * ✓読み取りクエリを高速化する
* しかし、
    * ×あらゆるインデックスは書き込みを低速化する
* ※アプリケーションの典型的なクエリパターンに関する知識を用いて、開発者が適切なインデックスを選択する必要がある

### インデックスの種類
* ハッシュインデックス
* Bツリーインデックス

### ハッシュインデックス
#### ハッシュインデックスのアルゴリズム
* プログラミング言語の辞書型に似た構造
* インメモリハッシュマップ内に、すべてのキーに対して、値の場所をバイトオフセット(ファイルの先頭からキーまでの距離)として保存する
* 値を検索する場合、ハッシュマップを用いてバイトオフセットを取得し、データファイルの先頭からその場所を読み取る
* 新しいキー、値のペアを追加するときは、データファイルの末尾に追加していく
* ファイルの追記だけを行うと、最終的にディスク領域を使い切る可能性がある
    * ログが一定容量を超えた場合、ファイルをクローズし、ログをセグメントに分割する
    * それらのセグメントにコンパクション処理(※)を実施し、重複したキーを捨てて、キーに対する最新の値だけを残す
    * 複数のセグメントをコンパクションのタイミングでマージすることもできる

#### ※コンパクション処理とは
* キーと値をディスク内のファイルに追記していくといつかディスクを使い切ってしまうので、ログ内の重複したキーを捨てて最新のキーの情報だけを残す
* これによりセグメントがかなり小さくなるので、このときに複数のセグメントをマージすることもできる（あくまでコンパクション処理とマージ処理は別の処理）


#### ハッシュインデックスを利用したサービス
* Bitcask(Riakのデフォルトストレージエンジン)
    * ハッシュマップをすべてメモリの置く
    * データファイルの中に必要な部分が既にキャッシュ内にあれば、ディスクI/Oなしで読み出しができる
    * 各キーに対する値が頻繁に更新される場合に適する

#### ハッシュインデックスを用いる場合の検討項目
* ファイルフォーマット
    * 文字列の長さをバイトとしてエンコードして生の文字列を続けるようなバイナリフォーマットの方が高速かつシンプル
* レコードの削除
    * キー及びその値を削除する場合、特別な削除のレコードを追加する必要がある（墓石と呼ばれる）
* クラッシュのリカバリ
* 部分的に書き込まれたレコード
    * Bitcaskのファイルにはチェックサムが含まれており、ログの壊れた部分を削除・無視できる
* 並列性の制御
    * 書き込みはシーケンシャルな順序で行われるので書き込みスレッドは１つだけにする
    * データファイルは追記のみが行われ、それ以外はイミュータブルなので読み取りは複数スレッドから並列に行える

#### ハッシュテーブルインデックスの利点
* シーケンシャルな書き込みはランダムな書き込みよりも高速
* 並行処理とクラッシュリカバリは、セグメントファイルが追記のみもしくはイミュータブルであればシンプルになる
    * クラッシュして、一部が古い値のままになってしまうことはなくなる
* 古いセグメントをマージすることで、データファイルがフラグメンテーションを起こす問題を回避できる

#### ハッシュテーブルインデックスの制約
* ハッシュテーブルはメモリ内に収まらなければならないため、キーの数を多くなると管理できなくなる
    * ディスク上で管理させることもできるが、そのためにランダムアクセスI/Oが必要になり、ハッシュの衝突への対応も難しくなる
* 範囲に対するクエリの効率がよくない
    * aからcまでの値をすべてスキャンすることはできず、各キーで検索する必要がある

### SSTable(Sorted String Table；ソート済み文字列テーブル)
#### SSTableとは
* ハッシュインデックスに2つの制約を追加したインデックス
    * キーと値のペアがキーに基づいてソートされていること
    * キーは重複しない（これはコンパクション処理で満たされる）
* マージされたそれぞれのセグメントファイル中にはそれぞれのキーは一度だけしか現れない

ハッシュインデックスをもったログセグメントと比較するといくつかの利点がある
#### SSTableの利点
* ファイルがメモリより大きくなってもセグメントのマージが効率的にできる
* 特定のキーを探す際、キーをすべてメモリに保持しなくて良い
    * いくつかのキーがわかっていればソートされているため、範囲を特定できるから
* 読み取りリクエストの処理では、要求された範囲内にある複数のキーと値のペアをスキャンしなければならなくなるので、ディスクに書き込む前にそれらのレコードをブロックとしてグループ化し、圧縮しておける
    * この場合、疎なインメモリインデックスの各エントリは圧縮されたブロックの開始地点を指すことになる
    * 圧縮はディスク領域の削減だけでなくI/O帯域削減にもなる
#### SSTableを活用したストレージエンジン
* When write:
    * memtable(インメモリツリー)にキーと値を追加する
    * memtableが一定の閾値よりも大きくなった場合、ディスク上のSSTableに追加する
* When read:
    * memtableで探す
    * 次に最新のセグメント、その次に古いセグメントを探し見つかるまで遡る
* マージとコンパクション処理はバックグラウンドで実行する
* 使用しているサービス
    * LevelDB
    * RocksDB

#### SSTableの問題と対策
* 問題
    * 上記の方法では、データベースがクラッシュすると、直近にmemtableに書き込まれた内容が失われる
* 対策
    * 別のログとして、書き込みを即座に追記する
    * memtableのリストアだけが目的なのでソート順になっていなくても問題はない
    * SSTableに書き込まれるたびにこのログを廃棄できる

### LSMツリー
このようなSSTableを活用したものはLog Structured Merge Tree(LSMツリー)と呼ばれる

#### LSMツリーの最適化
##### 存在しないキーのルックアップ
* 課題
    * データベースに存在しないキーのルックアップに時間がかかる
    * memtableを調べた後、最も古いセグメントまですべてのディスクを見る必要があるから
* 対策
    * ブルームフィルター（Bloom Filter）を使う
        * ブルームフィルター：集合の内容についての概要を保持するメモリ効率のいいデータ構造
        * これを使えばキーがないことがわかるため、不要なディスク読み取りを回避できる
##### コンパクションとマージの順序とタイミングの決定
* 課題
    * SSTableのコンパクションとマージの順序とタイミングの決定の戦略が色々ある
* 対策
    * サイズごと及び階層ごとのコンパクション
    * leveledコンパクション
        * キーの範囲を小さなSSTableに分割し、古いデータを分割された「レベル」へ移す
        * これによりコンパクションをインクリメンタルに行える
        * 採用DB
            * LevelDB
            * RocksDB
            * Cassandra
    * size-tieredコンパクション
        * 新しく小さいSSTableを古くて大きいSSTableに連続的にマージしていく
        * 採用DB
            * HBase
            * Cassandra

### Bツリー

#### Bツリーのアルゴリズム
* キーと値のペアをソートされた状態で保存する
* DBを固定サイズ（4KB程度もしくはそれ以上）のブロック/ページに分割し、ページごとに読み書きする
* ページ同様にディスクも固定サイズのブロックを並べる
* 各ページはアドレスによって識別できるので、別のページから参照できる
* 1つのページがBツリーのルートになり、ページには複数のキーと子ページへの参照が含まれる
* 親ページから子ページに順番に参照していき、最終的に個別のキーが格納されているページ（リーフページ）にたどり着く
* 子ページは連続的範囲を受け持つ
    * 1つのページ内の子ページへの参照数は分岐係数と呼ばれる
* 既存のキーの値を更新する場合
    * リーフページを検索して、ページ内の値を更新してページごとディスクに書き戻す
* 新しいキーを追加する場合
    * キーの値を含む範囲を持つページを見つけ、そのページにキーを追加する
    * そのページに空き領域がない場合、そのページの半分だけ埋まった2ページに分割し、親ページをキーの範囲に合わせて更新する
    * このように、ツリーのバランスが保たれることを保証するので、n個のキーを持つBツリーの深さはO(log n)になる
        * ほとんどのDBの深さは3, 4程度
#### Bツリーの信頼性
* DBクラッシュへの耐性
    * 下位層の書き込みはディスクのページを新しいデータで上書きが発生する
        * 操作によっては複数のページを上書きする必要がある
        * 分割処理では2つのページを書き、さらにその親の参照を上書きする
    * 一部のページだけ上書きされた状態でクラッシュすると、インデックスが破損する
    * 対策：WAL（Write Ahead Log; redoログとも呼ばれる）を書く
        * Bツリーへの変更内容をツリーそのもののページに反映させる前に書き込む
        * クラッシュした場合、WALを使ってリカバリする
* 複数スレッドからの同時アクセス
    * 複数スレッドで同時にBツリーにアクセスする場合、十分に注意しないと整合性を保てない
    * 対策：ツリーのデータ構造をラッチ（軽量のロック）で保護する
    * log-structuredではマージ処理はバックグラウンドで実行されるためBツリーと比較してシンプル

#### Bツリーの最適化(Editting)
* WALを管理する代わりにコピーオンライトのスキームを利用する
    * 新しいページに書き込み、参照を更新することで、並行処理の制御に有益
* キー全体ではなく短縮したキーを保存することでページ内の領域を節約する
* リーフページがディスク上でシーケンシャルに並ぶような配置を試みる
* それぞれのリーフページに左右の隣接ページへの参照を持たせる
* フラクタルツリーのような変種はディスクシークを減らすログ構造の考え方を取り入れている

#### BツリーとLSMツリーの比較
簡単に言えば、LSMツリーは書き込み処理を高速に処理でき、Bツリーは読み取りが高速に行えるとみなされている

##### LSMツリーの利点
* SSTableのコンパクションとマージが繰り返されるため、データが複数回書き直されることになる
    * 一回の書き込みから複数回の書き込みが生じることの影響は、**書き込みの増幅**と呼ばれる
        * 特に上書き回数に制限があるSSDで問題になる
        * 書き込み負荷の高いアプリケーションでは、ディスクへの書き込み速度がパフォーマンスのボトルネックになることがある
        * この場合、書き込みの増幅は直接的にパフォーマンスのコストになる
        * 利用可能なディスクの帯域内で処理できる秒あたりの書き込み数が減るから

* 書き込みのスループットを高く保つことができる
    * LSMツリーの書き込みの増幅度合いが低くなる場合があること
    * LSMツリーではツリー内の複数ページを上書きする必要がなく、コンパクトなSSTableにシーケンシャルに書き込めばよいこと
        * シーケンシャルな書き込みはランダムな書き込みよりもはるかに高速になる磁気ハードディスクで特に重要
* LSMツリーは圧縮率を高めることができるのでディスク上のファイルサイズが小さくなる
    * 定期的にSSTableを書き直してフラグメンテーションを除去するので、ストレージのオーバーヘッドが低くなる
    * 多くのSSDはファームウェアが内部的にlog-structuredなアルゴリズムを使用してランダムな書き込みでもストレージレベルではシーケンシャルな書き込みになるようにしているので書き込みパターンの影響は小さくなる

##### LSMツリーの欠点
* LSMツリーで読み取りが遅くなる
    * コンパクションのステージにおいて、複数のデータ構造やSSTableを調べる必要があるから
* コンパクション処理が実行中の読み書きのパフォーマンスに影響がある
    * スループットや平均レスポンスタイムに対する影響は通常小さいが高いパーセンタイルでみると極めて高い値になってしまうことがある
* コンパクション処理で書き込みのスループットが高くなってしまう
    * ディスクの書き込みの帯域は有限で、元々の書き込みとバックグラウンドのコンパクションのスレッドとの間で書き込み帯域が共有される
    * データベースが空であればコンパクション処理を行う必要がなく、元々の書き込みに利用できるが、データベースが大きくなるにつ入れてコンパクションに要するディスク帯域が大きくなる

##### Bツリーの利点
* それぞれのキーがインデックス中の一か所にしか存在しない
* トランザクション機能のために、インデックス中で直接ツリーをロックできる

##### Bツリーの欠点
* Bツリーではすべてのデータを最低でも2回書く必要がある
    * WAL
    * ツリーページそのもの（ページが分割されればさらに書き込みが必要になる）
* 変更が数バイトだけでもページ全体を書かなければならないオーバーヘッドがある
### その他のインデックス構造(Editting)
#### セカンダリインデックス


#### インデックスへの値の保存

#### 複合インデックス

#### 曖昧インデックス

#### 全データのメモリでの保持


> [!NOTE]
> 
> :memo:コメント
>
> 話の流れ的に、最も原始的なデータベース（bashスクリプトで書かれたやつ）の話を取り上げ、構造として単純なハッシュインデックスから始まってLSMの話をし、それと対比する形でBツリーの話をしている...？
> 現代で最も一般的なBツリーから説明すると初心者にとっては混乱するからこの順番なのかも。(RyoyaC, Katsuya)
>
> > ブルームフィルター
> > 
> ブルームフィルターがどんなものかは言及されていない(RyoyaC)
>
> > ディスクのスループットが大きく、コンパクションの設定が十分に練られていなければ、データベースが受け付ける書き込みのペースに対してコンパクションが追いつかなくなるかもしれません(p.90)
>
> つまり、LSMツリーベースのデータベースを使用する場合、設計においてディスクのスループットの大きさやコンパクションの設定を注意深く検討する必要がある(RyoyaC)
> 
> > [SSTableのコンパクションとマージが繰り返されるため、データが複数回書き直されることになる](#####LSMツリーの利点)
> 
> これはLSMの利点ではなく欠点ではないのか？？(RyoyaC)
> 
## 3.2：トランザクション処理か、分析処理か？

### OLTP vs.OLAP
#### OLTP(Online Transaction Processing)
* 何らかのキーで少数のレコードをすっくアップし、ユーザー入力に基づいてレコードの更新や挿入を行う処理
* OLTPの例
    * ブログポストへのコメント
    * ゲーム内のアクション

#### OLAP(Online Analytic Processing)
* 大量のレコードにアクセスし、レコードの中の少数の列だけ読み出し、その記述統計量（レコード数、合計、平均など）を計算する
* OLAPの例
    * 1月の各店舗の総収入
    * 特定のプロモーション期間に、通常時と比較してどれだけ多くの商品が売れたか

#### 特性比較


| 特性 | OLTP | OLAP |
| -------- | -------- | -------- |
| 主な読み取りパターン     | クエリごとに少数のレコードをキーに基づいてフェッチ     | 大量のレコードの少数の列を集計     |
| 主な書き込みパターン     | ランダムアクセスと低レイテンシの書き込み     | バルクインポート（ETL）(※1)・イベントストリーム(※2)     |
| 主な利用者     | エンドユーザー・顧客     | 意思決定者・アナリスト     |
| データの内容     | データの最新の状態     | イベントの履歴     |
| データセットのサイズ     | GB、TB     | TB、PB     |
* ※1:バルクインポート
    * 「大量のデータを少量のデータに区切って圧縮し伝送する」こと
    * 出典：https://www.idcf.jp/words/bulk-import.html
* ※2:イベントストリーム
    * 「連続クエリを使用して、現在のデータと移動中のデータの膨大なデータプールを分析すること」
    * 出典：https://www.databricks.com/jp/glossary/streaming-analytics

### データウェアハウス
* OLTPシステムは通常企業経営にとって重要なので**高可用性・低レイテンシ**が求められる
* アナリストが実行するアドホックな分析クエリは負荷が高く、OLTPシステムで実行すると、並行して実行されるトランザクションのパフォーマンスに影響する可能性がある
* 対して、データウェアハウスは独立したデータベースでOLTPに影響を及ぼさず分析クエリを実行できる
* データはOLTPシステムのすべての**データコピーをリードオンリーで配置**する
* データウェアハウスに取り込む処理はETL(Extract-Transform-Load)と呼ばれる

#### データウェアハウスのメリット
* データベース（データウェアハウス）を分析的なアクセスパターンに最適化できる
* インデックスはOLTPではうまく動作するが、分析的なクエリにはそれほど効果がない

#### OLTPデータベースとデータウェアハウスの相違点(Editting)
* 最適化されているクエリパターンが大きく異なる
    * OLTPデータベース：
    * データウェアハウス：

### 分析のためのスキーマ
* スタースキーマ
    * ファクトテーブルが中心
        * 各行は特定の時点で生じたイベントを表す
        * ファクトテーブルのデータ例
            * 特定の顧客が特定の商品を購入した
            * 特定のユーザーが特定のページをクリックした
        * ファクトテーブルは履歴のようなものなのでテーブルが大きくなりやすい
    * ディメンションテーブルが周辺にある
        * ファクトテーブルから外部キー参照される
        * 人物、対象、日時、理由など
* スノーフレークスキーマ(※)
    * スタースキーマのディメンションテーブルをさらにサブディメンションに分割したもの
        * 例）ディメンションテーブルのプロダクトのブランドや分類を文字列として保存せずに、さらに外部キーとして参照する
    * スタースキーマよりも正規化されているが、分析する上ではスタースキーマの方がシンプルで好まれる
    * ※スノーフレーク：雪の結晶

> [!NOTE]
> 
> :memo:コメント
>

## 3.3：列指向ストレージ
### 行指向の構造：OLTP
* テーブル内の１行にある値はすべて隣り合うように配置される
* OLTPで分析クエリを実行すると、大量の行（各行にも100以上の列がある想定）をディスクからメモリにロードし、条件をみなす行をフィルタリングする必要があり、処理時間が長くなる可能性がある
### 列指向の構造
* 列指向ストレージでは、１つの行の値をまとめて保存するのではなく、それぞれの列に含まれるすべての値を保存する
* それぞれの列が別のファイルに保存されているなら、１つのクエリで読み取るのはそのクエリで必要な列だけなので、効率的にデータをロードできる
* ただし、列指向ストレージでは、それぞれの列ファイルが同じ順序で行を保持する必要がある

### 列の圧縮
* 各列のデータを圧縮すればディスクへの負担をさらに軽減できる
* ビットマップエンコーディング
    * データウェアハウスで特に効果的な手法
    * １つの列の中のユニークな値は行数に比べて小さいため、１つの値に対してワンホットエンコーディング（一致する値の場合=1, else=0）を行い、各行に対応させる
* ランレングスエンコーディング
    * ビットマップエンコーディングではビットマップの大部分は0になり、疎（スパース）になるため、「連続して現れる符号（1/0）を、繰り返しの回数を表す値に置き換える」（※）
    * ※参照：https://e-words.jp/w/%E3%83%A9%E3%83%B3%E3%83%AC%E3%83%B3%E3%82%B0%E3%82%B9%E5%9C%A7%E7%B8%AE.html
    * 例）
        * 元のビットマップ
            * 0001100011110
        * エンコード後
            * 3,2,3,4（3 zeros, 2 ones, 3 zeros, 4 ones, rest zeros）


#### ベクトル化処理(vectorized processing)(Editting)


### ソート順序(Editting)

* 列ストアにおいては行のソート順序は必ずしも問題にはならない
* SSTableのように順序を強制してこれをインデックスの仕組みとして使うこともできる
* それぞれの列を独立してソートすると、異なる列の同じ行に属するアイテムを判別できなくなる
* よく使われるクエリに基づいてソート順序を決める列を選択する
* 例）最後の月など日付の範囲を指定することが多ければ、日付を第一のソートキーにすることで、スキャンする範囲を大幅に狭められる
* ソート列が持つユニーク値が多くない場合、ソート後には同じ値が連続して繰り返される並びになり、行数が数十億以上のテーブルでもランレングスエンコーディングで数キロバイトまで圧縮できることがある

### 列指向ストレージへの書き込み
* これまでみてきたデータウェアハウスの最適化は理にかなっている
    * 負荷の大部分が大規模な読み込み処理のクエリだから
    * 列指向ストレージ、圧縮、ソートは読み取りクエリを高速化する
* しかし、反対に書き込み処理を難しくする
    * テーブルの途中に行を挿入したい場合は、行は列内での一で識別されるため、すべての列ファイルを更新する必要がある
* これの問題に対してはLSMツリーが有効
    * すべての書き込みはインメモリストアに送られ、そこでソート済みの構造に追加されてディスクへの書き込みに備える
    * インメモリストアは行指向か列指向かは問題にならない
    * 十分な書き込みが蓄積されたらディスクの列ファイルとマージされ新しいファイルに書き出される
        * Verticaが採用している方法
### 集計
#### 実体化された集計（materialized aggregates）
* 頻繁に利用されるカウントや合計値などの結果をキャッシュする方法
* 元々のデータが変更されたら、そのデータから作られたマテリアライズドビューも更新しなければならない
    * DBが自動的に行うこともできるが、書き込み負荷を高めてしまう
    * そのため、マテリアライズドビューはOLTPデータベースではそれほど使われない
* 標準的なビューのように定義される
* ビューとの違い
    * マテリアライズドビューは実際にクエリの結果をコピーしたもので、ディスクに書き込まれる
    * ビューは単にクエリを書きやすくするためのショートカットにすぎず、SQLエンジンはクエリを動的に展開し、展開後のクエリを処理する


#### データキューブ
* マテリアライズドビューの特化したケースで使われたもの
* ディメンションごとにグループ化された集計値のグリッド
* 例(二次元の集計の場合)
    * 横軸に商品ID、縦軸に日付をとり、各組み合わせごとに売り上げの合計値を集計する

    | date \ id | 1 | 2 | 3 |
    | --- | --- | --- | --- |
    | 2024/1/1 | 1000 | 5000 | 2500 |
    | 2024/1/2 | 1500 | 7000 | 1000 |
    | 2024/1/3 | 2000 | 6000 | 1500 |
    * ※各値は仮想的な合計値

* データキューブの利点
    * 事前に計算済みの値を使うことで、そうした値を使用するクエリが高速になる
* データキューブの欠点
    * 生データに対してクエリを実行するのと比べ、柔軟性がない

> [!NOTE]
> 
> :memo:コメント
> 
> たしかにDBでは、カテゴリや区分など取り得る値が限られた列が多いので、ビットマップエンコーディングは有効そう（RyoyaC）


## まとめ