
# 第5章：レプリケーション

### 本章の概要
* 本章では、各マシンに全体をコピーしておける程度にデータセットが小さいと仮定する
    * 大きすぎるデータセットの場合は、第6章のパーティショニング（シャーディング）で扱う
* 3つのレプリケーションのそれぞれの長所と短所を説明する
    * シングルリーダーレプリケーション
    * マルチリーダーレプリケーション
    * リーダーレスレプリケーション
* レプリケーションに関するトレードオフについても扱う
    * レプリケーションは同期的、もしくは非同期的に行うのか
    * 障害を起こしたレプリカの扱いはどうするか
    * など

### レプリケーション
* レプリケーションとは、ネットワークで接続された複数マシンに同じデータのコピーを保存しておくこと
* レプリケーションを行う理由
    * データを地理的にユーザーの近くで保持し、レイテンシを下げるため
    * 一部に障害があってもシステム全体が動作し続けられるように可用性を高めるため
    * 読み取りクエリを処理するマシン数をスケールアウトし、スループットを高めるため
* レプリケーションの難しさ
    * 対象のデータが永久に変化しなのであれば、データを各ノードに一度だけコピーすればいいのでレプリケーションは容易
    * レプリケーションのむずかしさはデータへの変更の扱いから生じる

## リーダーとフォロワー
* データベースへのすべての書き込みは、すべてのレプリカで処理されなければならない
    * それができない場合はレプリカのデータに差異が生じる可能性がある
* この問題への対処法として最も一般的なのが、リーダーベースレプリケーション
    * 別名
        * アクティブ/パッシブレプリケーション
        * マスター/スレーブレプリケーション

### リーダーベースレプリケーションの構成

| 処理区分 | リーダー | フォロワー |
| -------- | -------- | -------- |
| 読み取り     | 〇     | 〇     |
| 書き込み     | 〇     | ×     | 

* リーダー
    * 別名
        * マスター
        * プライマリ
    * 役割
        * クライアントから受けた書き込み要求に従い、ローカルストレージに書き込む
        * ローカルストレージに書き込んだ後、このログをフォロワーに送信する
        * クライアントからの読み取り要求も受け付けられる
* フォロワー
    * 別名
        * リードレプリカ
        * スレーブ
        * セカンダリ
        * ホットスタンバイ
    * 役割
        * リーダーから受け取ったログを、リーダー上での処理と同じ順序で書き込みを行い、ローカルストレージにデータをコピーする
        * 書き込み要求は受けられず、読み取り要求のみ受け付ける
* 使用例
    * RDB
        * PostgreSQL
        * MySQL
        * Oracle Data Guard
        * SQL Server Always On可用性グループ
    * 非RDB
        * MongoDB
        * RethinkDB
        * Espresso
    * 分散メッセージブローカー
        * Kafka
        * RabbitMQ
    * その他
        * ネットワークファイルシステム
        * ブロックデバイス
        * など

### レプリケーション方式：同期・非同期・準同期
#### 同期型の特徴
* リーダーが自身のストレージのデータを更新し、フォロワーがデータを書き込みしたことを確認後クライアントにレスポンスを返却する
* 利点
    * フォロワーの持っているデータが最新で、リーダーのデータと一貫性があることを保証できる
    * リーダーに障害が発生しても、フォロワーのデータを利用できる
* 欠点
    * 同期時にフォロワーがレスポンスを返却しない場合、リーダーが書き込み処理を継続できなくなり、フォロワーが使用可能になるまで書き込みがブロックされる
        * フォロワーがレスポンスを返却できないケース
            * フォロワーのクラッシュ
            * ネットワーク障害
            * など
        * どれか1つのフォロワーに障害が発生し、停止しただけでシステム全体が停止するため、すべてのフォロワーを同期的にするのは非現実的

#### 非同期型の特徴
* リーダーが自身のストレージのデータを更新後、フォロワーがデータを書き込むのを確認せずに、クライアントにレスポンスを返却する
* リーダーがレスポンスを返却した時点では、フォロワーはデータの更新を完了していない可能性がある
* フォロワーは完全に非同期で構成されることがある
    * この場合、リーダー障害が発生し、リカバリ不可能であれば、まだフォロワーにレプリケーションされていなかった書き込みはすべて失われる
        * クライアントに成功が返された場合でも書き込みの永続性が保証されない
        * すべてのフォロワーに遅延が生じても、リーダーは書き込み処理を継続できる
        * このトレードオフについては[レプリケーションラグにまつわる問題](##レプリケーションラグにまつわる問題)を参照
* 非同期型のユースケース
    * フォロワーが多い場合
    * フォロワーが地理的に分散している場合

#### 準同期型
* 同期レプリケーションを構成する場合に1つのフォロワーを同期型に設定し、残りのフォロワーは非同期型に設定する構成
    * 例
        * リーダー1つ、同期フォロワー1つ、非同期フォロワー3つ
    * 同期型のフォロワーに問題が生じた場合は別のフォロワーを非同期型に変更する
    * リーダーと少なくとも1つのフォロワーの2つのノードにデータのコピーがあることを保証できる

### 新しいフォロワーのセットアップ

* 新しいフォロワーのセットアップが必要なケース
    * フォロワーを増やす
    * 障害が発生したノードを置き換える
* 新しいフォロワーがリーダーのデータの正確なコピーを持っていることをどのように保証するか？
    * 新しいノードにデータファイルをコピーするだけでは不十分
        * DBには常に新しい書き込みがあり、データは更新され続けているから
    * DBをロックすればディスク上のファイルの一貫性を保つことはできるが、高可用性に反する

#### 新しいフォロワーをダウンタイムなしに実現する概念的な手順
※実際の手順はデータベースごとに大きく異なり、完全に自動化されていることもあるが、多くの手作業を伴う場合もある
1. 特定のタイミングでリーダーからスナップショットを取得する
    *  DB全体にロックを取らずに取得する
2. 取得したスナップショットを新しいフォロワーのノードにコピーする
3. フォロワーはリーダーに接続し、スナップショット取得後に生じたデータ更新ログを要求する
    * そのため、リーダーのレプリケーションログのどの時点か示す位置が必要になる
        * PostgreSQLのログシーケンス番号
        * MySQLのbinlog coordinates
4. フォロワーがスナップショット取得移行のデータ変更ログを処理し終えたら、キャッチアップが完了し、その後はリーダーにデータ更新が発生したタイミングで処理する

### ノード障害への対処：リーダーベースレプリケーションで高可用性を実現する
* システム内のノードでダウンしないものはない
    * 障害による予想外のダウン
    * メンテナンスのための計画されたダウン
        * カーネルのセキュリティパッチの適用のための再起動
* ダウンタイムなしでノードを再起動できるなら、運用やメンテナンスにとって大きなメリットになる
* システム全体でダウンタイムなしにノード停止ができることが目標となる

#### フォロワーの障害：キャッチアップリカバリ
* フォロワーのキャッチアップは容易
    * 通常時
        * 各フォロワーが、リーダーから受信したデータの変更ログをローカルディスクに保持する 
    * フォロワーがデータの変更ログを保持していない場合
        * クラッシュして再起動した場合やネットワークが一時的に切れてしまった場合など
        * フォロワーはリーダーに接続し、接続が切れた後に生じたすべての変更を再取得する
    * それらの変更ログを適用することで再度リーダーの変更に追従できる

#### リーダーの障害：フェイルオーバー
* フェイルオーバーのプロセス
    * いずれかのフォロワーをリーダーに昇格させる
    * クライアントの書き込み先を新しいリーダーに設定する
    * 他のフォロワーはデータの変更を新しいリーダーから受信する
* フェイルオーバーを実行する方法
    * 手動フェイルオーバー
    * 自動フェイルオーバー

#### 自動フェイルオーバーのプロセス
* リーダーに障害が起きたことの確認
    * 生じうる問題
        * クラッシュ
        * 電源喪失
        * ネットワークの問題
        * など
    * 様々な問題を確実に検出する簡単な方法はないため、ほとんどのシステムはタイムアウトを利用する
        * 30秒間反応がなければノードが落ちているとみなすなど
* 新しいリーダーの選出
    * 選出方法
        * 残っているフォロワーの過半数のうちリーダーを選出する
        * 事前に指定されているコントローラノードによって新しいリーダーが指定される
    * リーダーの候補
        * それまでのリーダーのデータ変更に一番最近まで追従していたフォロワー
        * リーダー候補からリーダーを選出するのは、合意の問題で第9章で扱う
* 新しいリーダーを使用するためのシステムの再設定
    * クライアントは新しいリーダーにリクエストする必要がある
    * リーダーが復帰してくると、そのノード自身がまだリーダーであると考えており、フォロワー群に降格させられていることを理解していない可能性もある（設定不備など）ため、古いリーダーをフォロワーにさせ、新しいリーダーを認識させる必要がある

#### フェイルオーバーの問題
以下のような問題は簡単には解決できないため、自動フェイルオーバーをサポートしている場合でも須藤フェイルオーバーを好む場合もある

* データが最新でない可能性
    * 非同期レプリケーションで構成されたフォロワーがリーダーになると、リーダーに障害が起こったときまでのすべての書き込みを受信していない可能性がある
    * 新しいリーダーの選出後、以前のリーダーがクラスタに加わった場合、古いリーダーが一時的に書き込みを受信してしまう可能性もある
    * 最も一般的な解決方法は、古いリーダーのもつレプリケーションされなかった書き込みは単純に破棄する
        * クライアントが期待する永続性に反する
* 外部システムとの整合性
    * GitHubにおけるインシデント
        * 自動インクリメントされたプライマリーキーが、新しく昇格したリーダーと古いリーダーでずれていて、新しいリーダーが古いリーダーで割り当て済みのプライマリーキーを再利用した
        * これがRedisで使われていたことでMySQLとRedisの整合性が失われ、プライベートなデータの一部が間違ったユーザーに公開された
* スプリットブレイン
    * 2つのノードがともに自身をリーダーと信じてしまう状況
    * どちらのリーダーも書き込みを受け付け、衝突を解決するプロセスがないため、データの損失や破損が生じる可能性が高くなる
        * 安全策としては、片方をシャットダウンさせる仕組みが考えられる
        * ただし、両方のノードをシャットダウンさせてしまうリスクがあるため、注意深く設計する必要がある
* リーダーがダウンしていると判断する時間の決定が難しい
    * タイムアウトが長ければ、リーダー障害時のリカバリの時間が長くなる
    * タイムアウトが短ければ、一時的な負荷によるスパイクやネットワークの問題で不要なフェイルオーバーが発生する可能性がある
        * システムがすでに高負荷やネットワークの問題が生じている場合、不要なフェイルオーバーは、その状況を悪化させる可能性がある

ノードの障害、信頼性の低いネットワーク、フォロワーの一貫性に関するトレードオフ、永続性、可用性、レイテンシといった問題は分散システムの基本的な問題
* 第8章と第9章で詳しく説明する

### レプリケーションログの実装
ここではリーダーベースレプリケーションで使われている4つの手法を紹介する
* ステートメントベースのレプリケーション
* WAL転送によるレプリケーション
* 論理ログレプリケーション
* トリガーベースレプリケーション

#### ステートメントベースのレプリケーション
* 方法
    * 実行するすべての書き込みリクエスト（ステートメント）を記録し、ステートメントログをフォロワーに送信する
    * RDBではすべてのINSERT、UPDATE、DELETE文がフォロワーに送信され、それぞれのフォロワーでSQL文をパースし、実行する
* 問題
    * NOW()やRAND()などの非決定的な関数が含まれるステートメントはそれぞれのフォロワーで異なる結果になる
    * 自動インクリメントが設定されている場合、または既存のデータに依存している場合（WHEREで条件指定している場合など）、すべてのレプリカで完全に同じ順序で実行されなければならない
        * 複数のトランザクションを平行して実行できる状況を制約する可能性がある
    * 副作用を持つステートメント（トリガー、ストアドプロシージャ、ユーザー定義関数など）はその副作用が完全に決定的なものでない限り、それぞれのフォロワーで異なる副作用をもたらす可能性がある
* 問題の回避策
    * リーダーは非決定的な関数呼び出しを記録する際は、確定した値で置き換える
        * エッジケースは非常に多く存在するので、別のレプリケーション手法が好まれる
* 採用例
    * バージョン5.1以前のMySQL
        * 非常にコンパクトなので、現在でも使われてはいるものの、今ではMySQLもステートメント中に非決定性がある場合、デフォルトは業ベースのレプリケーションに切り替えられる
    * VoltDB
        * ステートメントベースのレプリケーションを採用しているが、トランザクションは決定的なものでなければならないと制約を追加することで安全性を確保している

#### WAL（write-ahead log）転送によるレプリケーション
* 方法
    * ストレージエンジンではディスク上のデータはすべてログに書き込まれている
        * log-structuredストレージエンジンの場合
            * このログがストレージの中心で、ログのセグメントに対してバックグラウンドでコンパクションとガベージコレクションが行われる
        * Bツリーの場合
            * 個々のディスクのブロックが上書きされ、クラッシュがあってもインデックスが一貫した状態を回復できるようにすべての変更はまずWALに書き込まれる
        * このログはDBに対するすべての書き込みを含んでおり、追記だけが行われるバイトの並びになっているため、フォロワーでデータをコピーするのにそのまま利用できる
    * リーダーは、WALをディスクに書き込むと同時にネットワーク経由でフォロワーに送信する
    * フォロワーでこのログを処理すれば、リーダーと同じデータをコピーできる
* 問題
    * ログはデータを、ディスクブロック中のどのバイトが変更されたかといった、非常に低レベルで記述しており、レプリケーションがストレージエンジンと密結合することになる
        * DBがストレージフォーマットのバージョンを変更した場合、通常リーダーとフォロワーで異なるバージョンを動作させられなくなる
        * これは運用に大きな影響を及ぼす
            * リーダーとフォロワーで異なるDBバージョンが許容される場合
                * まずフォロワーをアップグレードし、続いてフェイルオーバーでアップグレードされたノードの1つを新しいリーダーにすれば、DBをダウンタイムなしにアップグレードできる
            * WAL転送の場合（DBバージョン、ストレージエンジンのバージョン差異が許容されない場合）
                * バージョンのアップグレードにはダウンタイムが必要になる
* 採用例
    * PostgreSQL
    * Oracle

#### 論理ログレプリケーション

* 方法
    * ストレージエンジンの物理的なデータ表現とは区別された論理ログを用いる
    * DBの論理ログは、テーブルへの書き込みを記述するレコードが行単位で並んでいる
        * 挿入された行の場合
            * ログにはすべて列の新しい値が含まれる
        * 削除された行の場合
            * ログには削除された行をユニークに特定する情報が含まれる
            * 通常はプライマリーキーになるが、プライマリーキーがない場合はすべての列の値を記録する
        * 更新された行の場合
            * ログには更新された行をユニークに特定する情報と更新された列の値が含まれる
* 利点
    * ストレージエンジンの内部からは分離されているため、後方互換性を保ちやすくなり、リーダーとフォロワーで異なるバージョンのデータベースを動作させたり、異なるストレージエンジンを動作させたりすることもできる
    * 論理ログのフォーマットはアプリケーションにとってもパースしやすいため、DBの内容を外部に送信する場合に役立つ
        * オフライン分析のためのデータウェアハウスやカスタムインデックスを構築する場合など
        * この手法は変更データキャプチャと呼ばれる
* 採用例
    * MySQLのbinlogで行ベースのレプリケーションの設定ができる

#### トリガーベースレプリケーション

* 方法
    * これまでのレプリケーション手法はDBMSで実装されたもので、アプリケーション側で実装する必要はなかったが、さらなる柔軟性が求められるケースもある
        * データの一部だけレプリケーションしたい場合
        * 異なる種類のデータベース間でレプリケーションを行いたい場合
        * 衝突を解決するためのロジックが必要な場合
    * DBで提供されているトリガーやストアドプロシージャで実装することができる
    * トリガーは、DBのデータの変更が生じた場合に自動的に実行されるカスタムのコードを登録できる
    * トリガーを使えば、データの変更を別のテーブルに記録できるため、その内容を外部プロセスから読み出せる
    * この外部プロセスは、データに対して必要なアプリケーションロジックを適用した上で、他システムにデータの変更をレプリケーションできる
* 問題
    * 他の手法と比べてオーバーヘッドが大きく、バグが生じやすく、制約が生じやすい
* 採用例
    * OracleのDatabus
    * PostgresのBucardo

> [!NOTE]
> 
> :memo:5.1節のコメント
> > WAL（write-ahead log）転送によるレプリケーション
>
> MySQLでは、テーブルごとに異なるストレージエンジンを使用することができるけど、特定のタイミングでストレージエンジンを変える可能性もあるため、WAL転送によるレプリケーションは採用しにくそう(RyoyaC)

## レプリケーションラグにまつわる問題
* レプリケーションを行う理由
    * ノード障害への耐性
        * ノード障害への耐性はレプリケーションを行う理由の1つにすぎない
    * スケーラビリティ
    * レイテンシ
    * など
* 読み取りスケーリングアーキテクチャ
    * フォロワーを追加するだけで読み取りのみを行うリクエストの量を増やせる
        * 書き込みが少なく、読み取りが多い場合はメリットが大きい
        * 非同期の場合のみうまくいく
        * 同期的にレプリケーションをしようとすると、1つのノードの障害やネットワーク断絶で、システム全体が書き込み不能になってしまう
            * ノードが増えれば増えるほど、そのうちの1つがダウンする確率は高まるので、完全な同期レプリケーション構成の信頼性は低くなる
* 非同期のフォロワーの問題点
    * フォロワーが遅延しているため、古い情報を返却する可能性がある
        * リーダーとフォロワーに同じリクエストを同時に送ると、フォロワーにリーダーの書き込みが反映されておらず、異なる結果が得られる可能性がある
            * データベースが明らかに一貫していない
        * リーダーに生じた書き込みとフォロワーへの反映との時間差を**レプリケーションラグ**といい、通常は数分の一秒程度
        * システムの使用率が限界に近づいていたり、ネットワークに問題がある場合は、数秒から数分まで増大する可能性がある
        * レプリケーションラグが大きくなれば、非一貫性の問題は大きくなる
    * この非一貫性は一時的な状態に過ぎず、データベースの書き込みを止めてしばらくすると、フォロワーがリーダーに追いつき、リーダーと一貫した状態になる
        * この現象を**結果整合性**（eventual consistency）と呼ぶ
    * 本節では、レプリケーションラグが生じている場合に起こりやすい3つの問題と、それらを解決するアプローチを説明する


### 自分が書いた内容の読み取り：read-after-write一貫性
* 問題
    * ユーザーがアプリからデータの書き込みを行った直後にそのデータを見た場合、新しいデータはまだフォロワーに到達していない可能性がある
    * このとき、フォロワーに読み取りリクエストが送られると、ユーザーは自分で登録したデータが失われたように見えてしまう
* read-after-write一貫性
    * このような状況下で求められるのが、read-after-write一貫性
        * read-your-writes一貫性とも呼ばれる
    * 自分で投入した更新は必ず反映されていることを保証する
    * 他のユーザーの変更については何も保証しない
* 実現方法
    * ユーザーが変更した可能性のあるデータを読み込む場合はリーダーから読み込み、それ以外はフォロワーから読み込む
        * 何が変更されたかどうかをクエリを行うことなく知る必要がある
        * 例）SNSでユーザーのプロフィールを更新するのは自分自身だけなので、自身のプロフィールの読み取りはリーダーに、他のユーザーのプロフィールはフォロワーから読み取る
    * アプリケーションの持つ情報のほとんどをユーザーが更新できる場合、最後に更新を行った時刻を追跡し、最新の更新から1分以内に行う読み取りはリーダーから行うようにする
        * フォロワーのレプリケーションラグをモニタリングしておき、１分以上リーダーから遅延しているフォロワーにはルーティングしないようにすることもできる
    * クライアントが最後に書き込んだタイムスタンプを記録しておき、それをもとにルーティング先を制御する
        * そのユーザーからの読み取りを行うフォロワーに対して、少なくともその時点までに行われた更新が反映済みであることを保証できる
        * フォロワーが十分に追従できていなければ、そのフォロワーに追いついてくるまで待つか、別のフォロワーにルーティングする
        * タイムスタンプには、論理的なタイムスタンプ（ログのシーケンス番号など）やシステムクロックを使うことができる
    * フォロワーが複数のデータセンターに分散配置されている場合、リーダーが応答するリクエストは、リーダーを含むデータセンターまでルーティングする必要がある
* 追加的な問題
    * 同じユーザーがデスクトップやWebブラウザ、モバイルアプリのように異なるデバイスでサービスにアクセスする場合さらに複雑になる
        * この時、クロスデバイスread-after-write一貫性を提供する必要があるかもしれない
        * ユーザーは１つのデバイスから書き込みを行い、別のデバイスから書き込んだ情報が表示されるべき
    * あるデバイスで実行通のコードは他のデバイス上で行われた変更を関知していないから、ユーザーの最終更新タイムスタンプを記憶しておくアプローチの難易度は高まる
        * このメタデータを集中配置しておく必要がある
    * フォロワーが分散配置されている場合、別々のデバイスからの接続が同じデータセンターにルーティングされる保証はない
        * デスクトップPCでは家庭のブロードバンド接続で、モバイルデバイスではセルラーデータネットワークを使っている場合、ネットワーク経路は異なる可能性がある

### モノトニックな読み取り
* 問題
    * ある時点でユーザーが読み取りリクエストを送って得た結果は、その後同じユーザーが再度読み取りリクエストを送り、リーダーにキャッチアップできていないフォロワーにリクエストが送信された場合、過去に遡った情報が見えてしまう可能性がある
* モノトニックな読み取り
    * このような問題が起きないことを保証する
    * 強い一貫性ほどの保証はないが、結果整合性よりも強い保証になる
    * データを読み取るとき、古いデータを読み取る可能性はあるが、特定の誰かが連続いて行った複数の読み取りにおいては、時間が巻き戻らないことを保証する
    * 一度新しいデータを読んだ場合、それよりも古いデータはそのユーザーには読まれなくなる
* 実現方法
    * 各ユーザーごとに常に読み取りを同じフォロワーから行うようにする
        * ユーザーが違えばフォロワーも異なるが問題はない
    * リクエストを受けるフォロワーをランダムに決めるのではなく、ユーザーIDのハッシュに基づいてい決める
    * フォロワーに障害が起きれば、他のフォロワーにリクエストをルーティングせざるを得ないので、過去の値を読んでしまう可能性は残る


---
以下編集中
---

### 一貫性のあるプレフィックス読み取り
問題
一貫性のあるプレフィックス読み取り
実現方法
### レプリケーションラグへの対処方法
ラグにどう対処するか考える
アプリケーションレベルで対処すれば複雑で間違いが起こりやすくなる
トランザクション
分散システムでのトランザクションは複雑

> [!NOTE]
> 
> :memo:5.2節のコメント
> > レプリケーションラグ
>
> - レプリケーションを行う必要があるシステムにおいて、アプリケーションのドメイン層でDDDを採用する場合、レプリケーションラグをどう対処するのか気になる。(RyoyaC)
>   - レプリケーションラグは完全になくすことはできないから、ドメイン層でDBに保存されたエンティティをリポジトリから取得して再インスタンス化するとき、本来あるべき状態（リーダーに書き込まれた最新の状態）とは異なった状態になる可能性があり、集約の不変条件を満たさなくなる可能性がある。(RyoyaC)
>
> - レプリケーションラグによって生じる問題への対処方法を実装しようとすると、アプリケーション側がかなり複雑になりそう。(RyoyaC)
>   - 書き込み、読み込みそれぞれにおいて、特定のロジックをもとにDBのルーティング先を判断するロジックを書かなければならず、複雑になるだけでなく、様々なパターンでテストするのも難しくなりそう。(RyoyaC)


## マルチリーダーレプリケーション
### リーダーベースレプリケーションの欠点
リーダーが1つで、すべての書き込みを1つのリーダーが引き受ける

### マルチリーダーレプリケーション
マスター・マスター
アクティブ・アクティブレプリケーション


### マルチリーダーレプリケーションのユースケース
#### マルチデータセンターでの運用

#### オフラインで運用されるクライアント

#### コラボレーティブな編集


### 書き込みの衝突の処理
#### 同期の衝突検出と非同期の衝突検出


#### 衝突の回避

#### 一貫した状態への収束

#### カスタムの衝突解決ロジック

#### 衝突とは何か

### マルチリーダーレプリケーションのトポロジー
#### all-to-all型
#### 循環型
#### スター型

> [!NOTE]
> 
> :memo:5.3節のコメント
> 


## リーダーレスレプリケーション
### ノードがダウンしている状態でのDBへの書き込み
#### 読み取り修復と反エントロピー
#### 読み書きのためのクオラム

### クオラムの一貫性の限界
#### 遅延のモニタリング

### いい加減なクオラム

### 並列書き込みの検出

> [!NOTE]
> 
> :memo:5.4節のコメント
> 

## まとめ