# 第6章：パーティショニング

### 本章の概要
* 本章では、大規模なデータセットをパーティショニングするアプローチを説明する
* さらに、クラスタのノードの増減に伴い、ノード間のデータを移動させるリバランシングについて解説する
* 最後に、クライアントがどのように適切なパーティションにアクセスするか説明する

### レプリケーションとパーティショニング
* レプリケーション
    * 同じデータのコピーを複数ノードでもつ
    * 大規模なデータセットの場合やクエリのスループットが大きい場合は不十分
* パーティショニング
    * データを複数のパーティションという単位で分割し、それぞれのデータを独立したデータベースでもつ
    * 呼び方
        * シャーディングと呼ばれることもある

### パーティショニングを行う主な理由
* スケーラビリティのため
    * シェアードナッシングクラスタの別々のノードにデータを配置できるため、クエリの負荷を分散させられる
    * 単一のパーティションに対して実行されるクエリはパーティションそれぞれに独立して実行できるのでスループットが上がる
        * ※しかし、多くのノードにまたがるクエリは並列化させるのが難しい

### パーティション化できるDB
* Teradata
* Tandem NonStopSQL
* Hadoop

> [!NOTE]
> 
> :memo:コメント
> 

## パーティショニングとレプリケーションの組み合わせ

* 通常、パーティショニングはそれぞれのデータが複数ノードに保存されるから、耐障害性をもたせるためにレプリケーションと組み合わされる
    * 1つのパーティションのリーダーは1つのノードに割り当てる
    * その他のノードはそのパーティションにおいてフォロワーとなる
    * それぞれのノードはあるパーティションではリーダーであると同時に他のパーティションではフォロワーになることがある
* 第5章の内容は、パーティションのレプリケーションにも当てはまる
    * パーティショニングの手法の選択はレプリケーションとは独立しているため、本章ではレプリケーションのことは扱わない

> [!NOTE]
> 
> :memo:6.1節のコメント
> > パーティショニングとレプリケーションの組み合わせ
> 
> RAIDっぽい(RyoyaC)
>   - RAID0は、複数のディスクにデータを分割して保存
>     - パーティショニング
>   - RAID1は、同じデータを複数のディスクに保存
>     - レプリケーション
>   - RAID10(1+0)は、データを複数のディスクに分割しつつ、それらのデータを複数ディスクに保存
>     - レプリケーション+パーティショニング

## キー・バリューデータのパーティショニング

### パーティショニングの目標
* データとクエリの負荷をノード間で均等に分散させること
* スキュー：データの分布の歪み
    * 均等になっておらず、一部のパーティションが他に比べて、割り当てられたデータが多い状態を**スキュー**（skew）と呼ぶ
    * スキューがあると、パーティショニングの効果は大きく損なわれる
    * 不均等な高負荷が集中しているパーティションは**ホットスポット**と呼ばれる

### キー・バリューデータに対するパーティショニング手法
- ランダムなパーティショニング
- キーの範囲の基づくパーティショニング
- キーのハッシュに基づくパーティショニング

### ランダムなパーティショニング
* 方法
    * ノード群に対して、ランダムにレコードを割り当てる
* 利点
    * ノード間で均等にデータを分散できる
* 問題
    * あるアイテムを読み込むとき、そのアイテムがどのノードにあるか知る方法がないため、すべてのノードに並行にクエリを実行しなければならない

### キーの範囲の基づくパーティショニング
* 方法
    * 連続的なキーの範囲（a ≦ key < b）を各パーティションに割り当てる
        * 例）紙の百科事典の各巻
* 利点
    * どのパーティションがどのノードに割り当てられているかわかるため、リクエストを適切なノードに直接発行できる
        * キーの範囲は必ずしも均等になっている必要はなく、データが均等に分散していれば良い
        * ある特定のキー付近でデータが集中している場合、範囲を均等にするとデータの分布にスキューが生じる
    * それぞれのパーティション内ではLSMツリーのようにキーをソートしておくことで範囲に対するクエリが容易になる
* 問題点
    * アクセスパターンによってホットスポットが生じうる
        * キーがタイムスタンプで、日ごとにパーティションが分割されている場合、現在の書き込みはすべて同じパーティションに集中し、ホットスポットとなる
    * 回避方法
        * タイムスタンプの前に、別のキーを置いて組み合わせる（複合キーのようなイメージ）
        * 追加したキーで同時にアクティブになるものがあっても、そのキーに応じて書き込み負荷分散できる
* パーティション境界の選択
    * 適切なパーティション境界（上記のaやb）の選択する方法は以下
        * 管理が自らから選択する
        * データベースに自動的に選択させる
            * 採用例
                * Bigtable
                * HBase
                * RethinkDB
                * MongoDB(ver2.4以前)

### キーのハッシュに基づくパーティショニング
* 方法
    * キーの文字列をハッシュ関数に入れると、生成されたハッシュを一定の範囲の乱数を変えすように見なせる
    * それぞれのパーティションに、キーの範囲ではなく、ハッシュ値の範囲を割り当てる
    * パーティションの境界を疑似乱数的に選択するコンシステントハッシュ法というのもある
    * ハッシュ関数は暗号として強力である必要はないが、実装によっては適していない可能性がある
* 利点
    * パーティションにキーを均等に分散させられる
* 問題点
    * キーの範囲によるパーティションの特性のクエリ実行の効率性は失われる
    * 元々近接していたキーもハッシュ値にするとばらばらになり、ソート順が失われる
        * MongoDBではすべてのパーティションにクエリを送る
        * Riak, CouchDB, Voldemortではパーティショニングをサポートしていない
* 複合プライマリーキーの活用
    * キーを複数列で構成し、パーティションの決定はキーの先頭部分だけのハッシュを使う
    * Cassandraで採用されている方法
    * 先頭列で範囲検索はできないが、最初の列が固定されれば、キーの他の列に対しては範囲スキャンができる
        * 1:Nの関係に有効

### ワークロードのスキューとホットスポットの軽減

* ホットスポットは完全にはなくならない
    * 極端なケース
        * すべての読み書きが同じキーに対して行われるとすべてのリクエストは同じパーティションにルーティングされる
    * 例
        * ソーシャルメディアサイトで、数十万（or それ以上）オーダーのフォロワーをもつユーザーがなにかをすると、フォロワーがそれに反応して一気にアクティビティが増える
            * 大量の書き込みが同じキーに生じる可能性がある
* 自動ですべて対策できない
    * スキューを抑えることはアプリケーション側の役割
        * あるキーにアクセスが集中する場合、ランダムな2桁の数値を追加すると、１つのきーへの書き込みを100個のキーに均等に分散できる
        * しかし、読み込み時に分割したキーのすべてから読み取りを行い、結合する必要があり、管理系処理が増えてしまう

> [!NOTE]
> 
> :memo: 6.2節のコメント
> > スキュー（skew）
>
> おそらく統計学における歪度（skewness）と同じアイデアだと思う。
> 各ノードのデータを、$D=(d_1, d_2, d_3, ..., d_n)^T$ $where$ $n=ノード数$のような各ノードに割り当てられたデータ数$d_i$のベクトルで考えると、歪度は以下の式で計算できるので、全体で均等にした場合の数（$\mu$）から乖離が大きくなればなるほど歪み(skew)が大きいと判断できる。(RyoyaC)
> $$
>  E[(D-\mu)^3]/\sigma^3
> $$
> - ※ $\muはDの平均$、$\sigmaはDの標準偏差$
> - ※ 歪度は、$d_i=\mu$、つまり偏りがないと0になるので、パーティションで均等に分散されたときの歪度は0になる
> 
> > パーティショニング手法
> 
> - パーティショニング手法として、本章で紹介されていない例として、グローバルなサービスで、各地域でのレイテンシを抑えるために、各地域ごとにパーティションを作成して各地域ごとにルーティングするといった手法をAWS、GCPの試験勉強でよく出ていた気がする。(RyoyaC)
> - この本で紹介されていないのは、あくまで仕組みを説明しているだけで、その具体的な使い方をすべて説明しているわけではないから？(RyoyaC)
> - → リストに基づくパーティショニングというものがあるらしい[link](https://www.fujitsu.com/jp/products/software/resources/feature-stories/postgres/article-index/partitioning-overview/)


## パーティショニングとセカンダリインデックス
ここまでのパーティショニング手法は、キー・バリューデータを前提にしており、プライマリーキーでのみアクセスされる。RDBではプライマリーキーと別にセカンダリインデックスが設定されることがあり、その場合はさらに複雑になる

* セカンダリインデックスが設定される場合
    * セカンダリインデックスはレコードをユニークに特定するものではなく、特定の値を含むすべてのレコードにアクセスする
        * Solr, Elasticsearchといった検索サーバーのレーゾンデートル（存在意義）でもある
* パーティショニングにおけるセカンダリインデックスの問題点
    * セカンダリインデックスとパーティションに対応付けるのが難しい
    * セカンダリインデックスをもつデータベースでのパーティショニングには主に2つのアプローチがある
        1. ドキュメントベースのパーティショニング
        2. 語ベースのパーティショニング

### ドキュメントによるセカンダリインデックスでのパーティショニング

* 方法
    * ドキュメントのID（主キー）でパーティションを決定する
    * 各パーティション内でセカンダリインデックスを張ったフィールドの各値に対して各主キーの値を対応させる
* 利点
    * 各パーティションは完全に分離されており、他のパーティションのデータは関知しない
    * ドキュメントの追加・削除・更新はドキュメントIDを含むパーティションだけで扱える
        * このようなインデックスをローカルインデックスと呼ぶ
* 問題点
    * セカンダリインデックスで特定の値でクエリを送るとき、すべてが同じパーティションにあるとは限らないため、すべてのパーティションにクエリを送り、結果を結合する必要があるため、読み取りクエリの付加が高くなる
        * このようなアプローチを「スキャター/ギャザー」と呼ぶ

### 語によるセカンダリインデックスでのパーティショニング

* 方法
    * セカンダリインデックスを設定したフィールドの特定の値によってパーティションを決定する
        * 例
            * a-rまでの文字で始まる色はパーティション0に、s-zで始まる色はパーティション1に配置する
        * 語という名前は全文検索インデックスに由来する
    * 語そのものでパーティショニング
        * 範囲に対するスキャンができる
    * 語のハッシュでパーティショニング
        * 負荷の分散の効果が高まる
* 利点
    * セカンダリインデックスの値によって、対応するパーティションがわかるため、ドキュメントベースのパーティショニングと比べて読み取りを効率的にできる
* 問題点
    * 1つのドキュメントの書き込みがインデックスの複数のパーティションに影響する可能性があり、書き込みが低速になる
        * ドキュメント中の語は別々のパーティションやノードにあるかもしれないため、通常セカンダリインデックスの更新は非同期で行われる
        * そのため、書き込み直後に読み取るとインデックスの変更が反映されていない可能性がある
        * 理想的にはインデックスは常に最新にしておきたいが、語でパーティショニングされたインデックスの場合、1つの書き込みで影響を受けるすべてのパーティションに渡る分散トランザクションが必要になるため、すべてのDBでサポートされているわけではない

### ローカルインデックスとグローバルインデックス


| | Read | Write |
| -------- | -------- | -------- |
| ローカルインデックス     | 遅い     | 速い     |
| グローバルインデックス     | 速い     | 遅い     |

* ローカルインデックス
    * パーティションごとに個別のセカンダリインデックスを管理する
    * 書き込みは効率的だが、読み取り負荷が高い
* グローバルインデックス
    * すべてのパーティションのセカンダリインデックスを管理する
    * 読み取りが効率的な一方書き込みが低速になる

> [!NOTE]
> 
> :memo: 6.3節のコメント
> > レーゾンデートル（存在意義）
> 
> フランス語の「raison d’etre」。英語で直訳すると
>   - raison(French) = reason(English)
>   - d' = de(French) = of(English)
>   - etre(French) = be(English)  
> 「reason of be」のような意味で、存在理由のような意味(RyoyaC)

## パーティションのリバランシング

### 時間経過とともに発生するデータベースの変化
#### 変化の例
- クエリのスループットが増大するため、CPUを追加して負荷に対処する
- データベースのサイズが大きくなるので、保存のためにディスクやRAMを追加する
- マシンに障害が発生し、他のマシンがそのマシンが受け持っていた処理を肩代わりすることになる

#### 変化への対応：リバランシング
* こうした変化が生じた場合、あるノードから別のノードへのデータやリクエストに移動が必要になる
* 負荷をクラスタ内のあるノードから別のノードへ移行することをリバランシングと呼ぶ

#### リバランシングの要件
1. リバランシング終了後、負荷（データストレージ、読み書きリクエスト）はクラスタ内のノードで均等に分散されること
2. リバランシングが行われている間、データベースは読み書きを受け付け続けられること
3. ノードを移動させるデータは必要最小限にとどめ、リバランシングが高速に行われ、ネットワークやディスクI/Oの負荷を最小にすること

### リバランス戦略

#### 取るべきではない方法：ハッシュの剰余
* 方法
    * ハッシュのmodをとり、剰余によってノードを割り当てる
        * hash(key) mod 10を計算すると、0~9の数値を返すため、10個のノードそれぞれに均等に割り当てることができる
* なぜダメか
    * ノード数が変化すると、ほとんどのキーをノード間で移動させる必要がある
    * 頻繁にデータの移動が発生し、リバランシングの負荷が高くなる
    * 要件1は満たすが、要件3によりNG

#### パーティション数の固定
* 方法
    * ノード数よりも多いパーティションを作成し、1つのノードに複数のパーティションを割り当てる
    * ノードを追加した場合
        * そのノードには、パーティションの分散が均等になるまで既存のすべてのノードからいくつかのパーティションを移動させる
    * ノードを減らす場合
        * 逆に1つのノードのパーティションを複数のノードに割り当てる
* 利点
    * ノード間を移動するのは、ノードに割り当てらえたパーティション全体のみで、パーティションのノードへの割り当てのみが変化する
    * パーティション数は変化せず、キーのパーティションへの割り当ても変化しない
    * 強力なマシンスペックのノードには多くのパーティションを割り当てることで負荷を調整できる
* 採用例
    * Riak
    * Elasticsearch
    * Couchbase
    * Voldemort
* 適切なパーティション数の選択
    * パーティション数は、データベースをセットアップしたときに決定され、それ以降変更しない
        * 原理的にはパーティションの分割やマージも可能だが、パーティションの分割は多くのデータベースでは実装されていない
        * そのため、最初に設定したパーティション数が利用可能なノードの最大数となるため、将来の成長を考慮して十分に大きな数を選択する必要がある
        * しかし、大きすぎる数にすると、管理のオーバーヘッドが大きくなる
    * データセットの合計サイズが大きく変動する場合は適切なパーティション数を選択するのが難しい
        * 各パーティションのサイズはクラスタのデータの総量に比例して大きくなる
        * パーティションが大きくなれば、リバランシングやノード障害のリカバリの負担が大きくなる
        * パーティションのサイズが小さいと、管理のオーバーヘッドが大きくなる

#### 動的なパーティショニング
* 背景
    * キーの範囲によるパーティショニングの場合、パーティション間の境界を固定すると不便になる
        * 境界が不適切な場合、すべてのデータが1つのパーティションに集中し、他のパーティションが空になる可能性がある
        * パーティション境界を手動で再設定するのは手間がかかる
* 手法
    * パーティションが事前に設定したパーティションサイズの下限、上限それぞれの閾値を超えた場合、パーティションの分割とマージを行う
        * 設定されたサイズ上限以上に大きくなった場合
            * そのパーティションを2つのパーティションに分割し、それぞれに半分のデータを割り当てる
            * データが増えたとき
        * 設定されたサイズ下限以上に小さくなった場合
            * 近接するパーティションにマージする
            * データが減ったとき
        * Bツリーのページ分割/マージと似ている
    * パーティション数を固定する場合と同じく、それぞれのパーティションは1つのノード割り当てられ、ノードは複数のパーティションを扱う
        * HBaseの場合、パーティションファイルの転送は下位層の分散ファイルシステムであるHDFSを通じて行われる
    * 分割とマージが行われるため、各パーティションのサイズは閾値の下限と上限の間に保たれるため、パーティション数はデータサイズに比例する
* 利点
    * パーティション数をデータの総量に適合させられる
    * データが少ない場合はパーティション数は少なくても十分で、データが多くなった場合にパーティションを分割できる
* 問題点
    * 空のデータベースが単一のパーティションからスタートする
    * パーティションの境界をどこに引けばいいか事前情報がないため
    * データセットが小さく、パーティションが分割されるまではすべての書き込み処理は単一のノードに処理され、他のノードは遊んでいる状態になる
    * 問題の緩和
        * HBaseやMongoDBでは空のデータベースに対して初期のパーティション群を設定できる
            * 事前分割という
            * キーの分布がどうなっていくかをユーザーが把握している必要がある
* 適しているケース
    * 動的なパーティショニングは、キーの範囲によるパーティショニングだけでなく、ハッシュパーティショニングにも適している

#### ノード数に比例するパーティショニング
* 方法
    * パーティション数をノード数に比例させ、ノード当たりのパーティション数を固定する
        * ノード数に変化がなければ、各パーティションのサイズはデータセットのサイズに比例
        * ノードを増やすとパーティションのサイズは小さくなる
        * データ量が多くなれば、保存するために必要なノード数も増えるため、このアプローチは各パーティションのサイズが安定したままになる
    * 新しいノードが追加された場合
        * 他の既存のパーティションを分割し、分割後の片方のパーティションを引き受け、他方を元のノードにそのまま置いておく
        * この処理をランダムに実施すると均等にならない可能性があるが、多数のパーティションに対して平均すれば新しいノードは既存のノードと均等に負荷を受け持つことになる
        * Cassandra3.0では不均等な分割を回避するような別のリバランシングアルゴリズムが導入された
* 利点
    * ノードの増減がなければリバランシングが発生せず、各パーティションのサイズが安定する
* 注意点
    * パーティションの境界をランダムに選択するためには、ハッシュベースのパーティショニングを使用する必要がある
        * ハッシュ関数が生成する数値の範囲から境界を選択できるようにするため
        * 実際のところ、このアプローチはコンシステントハッシュの定義に最も近い

### 運用：自動のリバランスと手動のリバランス
* 完全に自動化されたリバランシングは、メンテナンスの運用作業が減るため便利になる
* しかし、リバランシングはリクエストを再ルーティングし、大量のデータをノード間で移動させる負荷の大きい処理のため、注意深く実行しなければ、リバランシング進行中に他のリクエストのパフォーマンスに影響する可能性がある
* さらに、自動的な障害検出と組み合わされると危険になり得る
    * 例
        * あるノードが過負荷になり、レスポンス速度が落ちたとき、他のノードは過負荷になったノードが落ちたと判断し、自動的にクラスタをリバランスしてそのノードから負荷を退避させようとする
        * その場合、過負荷になったノードや他のノードにさらにネットワーク負荷がかかり、状況を悪化させ、カスケード障害を引き起こす可能性がある
* 上記の例のような事態を防ぐために、リバランシングの処理のどこかは人を介在させるとよい
    * 予想外の事態が発生するのを防ぐことができるかもしれない

> [!NOTE]
> 
> :memo: 6.4節のコメント
>
> > リバランシングの要件
> > 1. リバランシング終了後、負荷（データストレージ、読み書きリクエスト）はクラスタ内のノードで均等に分散されること
> 
> - 使用可能なすべてのノードでデータを厳密に均等にしようとすると、多少のデータの増減でもリバランスすることになってしまうので、ある程度のデータの分布の歪みは許容する必要がある。(RyoyaC)
> - しかし、どの程度歪みを許容してよいかはケースバイケースで、均等に分散されているかどうかを監視するよりも、ホットスポットが生じていないか監視する方が重要だと思う。(RyoyaC)
>
> > 6.4.1.2 パーティション数の固定
>
> - この戦略は、パーティション数をデータベースセットアップ時に決め、後から変更できない（するべきではない）パラメータのため、パーティショニングを設定する当初の担当者がこのようなことを知らずに設定すると解決の難しい負債になってしまう。(RyoyaC)
> - 組織としては、パーティショニングを行う際に確認するべきれ観点をまとめておいて、それぞれの知識・経験の有無になるべく依存しなくても進められるようにすることで品質担保できる。(RyoyaC)
>
> > あるノードから別のノードへのデータやリクエストに移動
> - 主キーなどでDBで自動インクリメントする数値のIDなどを使っている場合、リバランス自体が難しそう。(RyoyaC)
>   - パーティションはそれぞれ独立したDBだから、それぞれでIDは採番されるが、数値型のIDなどはIDが被る可能性が高い。
>   - リバランスするときは、ノードによって採番済みのIDが違うので、移動先のノードに合うようにIDを変換する必要がある。
>   - 主キーを変換させるとなると、外部キー参照している箇所やユーザーがIDを記憶してアクセスするような箇所で、整合性を意識する必要がある。
>
> > 手動のリバランシング
> 
> パーティションのリバランシングをパーティショニング経験の少ないスクラムチーム、かつ人数が少ない場合、リバランシングの調査や実行、確認などで容易に1スプリント以上かかってしまいそう。これに対応するためには機能開発を一時的に止めなければならず、ビジネスサイドとの調整が重要になりそう。(RyoyaC)

## リクエストのルーティング
* 背景
    * 前節までの内容で、複数ノードでデータをパーティショニングする方法はわかった
    * リクエストを発行するとき、クライアントは適切な接続先のノードをどのように判断すればいいか？
* サービスディスカバリ
    * ソフトウェアがネットワーク経由で別のサービスにアクセスしていて、そのサービスが高可用性のため冗長構成をとっている場合に、適切な接続先を管理する

#### 適切なノードへリクエストをルーティングする３つの方法
1. 各ノードで接続先情報を管理する
    * クライアントは任意のノードに接続し、そのノードにデータがあればそのままレスポンスを返却し、そのノードに対象のパーティションがない場合、リクエストを転送して結果をクライアントに返す
2. ルーティング層で接続先情報を管理する
    * ルーティング層がクライアントからのすべてのリクエストを引き受け、それぞれのリクエストを適切なノードに転送する
    * ルーティング層はリクエストを処理せず、パーティションの状態を把握するロードバランサとしてのみ振る舞う
3. クライアント側で接続先情報を管理する
    * クライアントは仲介なしに直接適切なノードにリクエストする


#### パーティションのノードへの割り当ての変化を検知する方法
* ルーティングの判断を行うコンポーネントが、パーティションのリバランスによってノードへの割り当てが変化したとき、どのように気づき、ルーティング情報を更新するか
    * ルーティング情報は、すべての要素が一致していることが重要
* ZooKeeper
    * 独立したサービスとしてパーティションとノードのマッピングを管理する
    * 割り当てが変化した場合はルーティング層に通知し、ルーティング情報を最新の状態に保つ
        * LinkedInのEspressoはZooKeeperに依存するHelixを利用している
        * HBase, SolrCloud, KafkaなどもZooKeeperを利用
* gossip
    * リクエストは任意のノードに送信し、各ノードが適切なノードに転送する
    * ノードが複雑になるが、外部サービスに依存する必要がなくなる
        * CassandraとRiakが採用するアプローチ
* moxi
    * moxiと呼ばれるルーティング層を構成する
    * moxiはルーティング情報の変更を、各ノードから知る
        * Couchbaseが採用するアプローチ

### パラレルクエリの実行
* 分析処理に使われる大規模並列処理（massively parallel processing, MPP）
    * 複数の結合、フィルタリング、グループ化、集計などの処理
    * クエリオプティマイザが複雑なクエリをいくつもの実行ステージとパーティションに分割し、複数のノードで並列に処理する
    * データセットの大部分を読み取る必要があるクエリの場合、並列実行は効果的
    * 並列クエリの実行手法は第10章で扱う

> [!NOTE]
> 
> :memo: 6.5節のコメント
>
> > 独立したサービスとしてパーティションとノードのマッピングを管理する
> 
> Kubernetesが各Podの情報を管理する際にもサービスディスカバリが行われていて（Service）、コントロールプレーンのetcdでPodと内部IPを管理して、外部からのリクエストを適切なPodに送信するアプローチをとっていたはず。(RyoyaC)


## まとめ
* パーティショニングの目標
    * 大規模なサービスにおいて、データを保持するノードのホットスポットを生じさせないようにすること
    * そのためにデータを複数のノードに均等に分散すること
* ２つのパーティショニングのアプローチ
    * キーの範囲に基づくパーティショニング
    * キーのハッシュに基づくパーティショニング
* セカンダリインデックスを用いる場合のパーティショニング手法
    * ドキュメントベースのパーティショニング
    * 語ベースのパーティショニング
* リバランス戦略
    * NG: ハッシュの剰余によるリバランス
    * パーティション数の固定
    * 動的なパーティショニング
    * ノードに比例するパーティショニング
* リクエストのルーティング
    * 各ノードで接続先情報を管理する
    * ルーティング層で接続先情報を管理する
    * クライアント側で接続先情報を管理する

> [!NOTE]
> 
> :memo: 全体へのコメント
>
> - パーティショニングの個別の手法について説明した文献はちょくちょくみる気がするけど、リバランシングとそれに伴う運用負荷の側面まで説明しているのはかなり有益。(RyoyaC)
>
> ---
> パーティショニングを行う際に監視するべき項目の整理(RyoyaC)
> - パーティションごとのデータ量（レコード数）
>   - データの分布にスキューが生じていないか
> - パーティションごとの読み取り数、書き込み数
>   - 負荷はどの程度か
>   - 想定以上の読み取り、書き込み数が増加していないか
> - 各ノードのCPU、メモリ、ディスク使用率
>   - ホットスポットが生じていないか
> - サービスとしてのSLI
>   - サービスとして適切なサービスレベルを維持できているか
>   - SLIが下がっており、すぐにリバランスが必要か、すぐには必要ないが準備が必要かなど判断する
> - リクエストのレイテンシ
>   - ルーティングによって想定以上にレスポンスの返却までに時間がかかっていないか
> - データ不整合が発生していないか
