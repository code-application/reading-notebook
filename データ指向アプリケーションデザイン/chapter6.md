# 第6章：パーティショニング

### 本章の概要



> [!NOTE]
> 
> :memo:コメント
> 

### レプリケーションとパーティショニング
* レプリケーション
    * 同じデータのコピーを複数ノードでもつ
    * 大規模なデータセットの場合やクエリのスループットが大きい場合は不十分
* パーティショニング
    * データを複数のパーティションという単位で分割し、それぞれのデータを独立したデータベースでもつ
    * 呼び方
        * シャーディングと呼ばれることもある

### パーティショニングを行う主な理由
* スケーラビリティのため
    * シェアードナッシングクラスタの別々のノードにデータを配置できるため、クエリの負荷を分散させられる
    * 単一のパーティションに対して実行されるクエリはパーティションそれぞれに独立して実行できるのでスループットが上がる
        * ※しかし、多くのノードにまたがるクエリは並列化させるのが難しい

### パーティション化できるDB
* Teradata
* Tandem
* NoStopSWL
* NoSQL
* Hadoop

## パーティショニングとレプリケーションの組み合わせ

* 通常、パーティショニングはそれぞれのデータが複数ノードに保存されるから、多障害性をもたせるためにレプリケーションと組み合わされる
    * 1つのパーティションのリーダーは1つのノードに割り当てる
    * その他のノードはそのパーティションにおいてフォロワーとなる
    * それぞれのノードはあるパーティションではリーダーであると同時に他のパーティションではフォロワーになることがある
* 第5章の内容は、パーティションのレプリケーションにも当てはまる
    * パーティショニングの手法の選択はレプリケーションとは独立しているため、本章ではレプリケーションのことは扱わない

> [!NOTE]
> 
> :memo:6.1節のコメント
> > パーティショニングとレプリケーションの組み合わせ
> 
> RAIDっぽい(RyoyaC)
>   - RAID0は、複数のディスクにデータを分割して保存
>     - パーティショニング
>   - RAID1は、同じデータを複数のディスクに保存
>     - レプリケーション
>   - RAID10(1+0)は、データを複数のディスクに分割しつつ、それらのデータを複数ディスクに保存
>     - レプリケーション+パーティショニング

## キー・バリューデータのパーティショニング

### パーティショニングの目標
* データとクエリの負荷をノード間で均等に分散させること
* 均等になっておらず、一部のパーティションが他に比べて、割り当てられたデータが多い状態を**スキュー**（skew）と呼ぶ
* スキューがあると、パーティショニングの効果は大きく損なわれる
* 不均等な高負荷が集中しているパーティションは**ホットスポット**と呼ばれる

### スキュー：データの分布の歪み

### キー・バリューデータに対するパーティショニング手法
- ランダムなパーティショニング
- キーの範囲の基づくパーティショニング
- キーのハッシュに基づくパーティショニング

### ランダムなパーティショニング
* 方法
    * ノード群に対して、ランダムにレコードを割り当てる
* 利点
    * ノード間で均等にデータを分散できる
* 問題
    * あるアイテムを読み込むとき、そのアイテムがどのノードにあるか知る方法がないため、すべてのノードに並行にクエリを実行しなければならない

### キーの範囲の基づくパーティショニング
* 方法
    * 連続的なキーの範囲（a ≦ key < b）を各パーティションに割り当てる
        * 例）紙の百科事典の各巻
* 利点
    * どのパーティションがどのノードに割り当てられているかわかるため、リクエストを適切なノードに直接発行できる
        * キーの範囲は必ずしも均等になっている必要はなく、データが均等に分散していれば良い
        * ある特定のキー付近でデータが集中している場合、範囲を均等にするとデータン分布にスキューが生じる
    * それぞれのパーティション内ではLSMツリーのようにキーをソートしておくことで範囲に対するクエリが容易になる
* 問題点
    * アクセスパターンによってホットスポットが生じうる
        * キーがタイムスタンプで、日ごとにパーティションが分割されている場合、現在の書き込みはすべて同じパーティションに集中し、ホットスポットとなる
    * 回避方法
        * タイムスタンプの前に、別のキーを置いて組み合わせる（複合キーのようなイメージ）
        * 追加したキーで同時にアクティブになるものがあっても、そのキーに応じて書き込み負荷分散できる
* パーティション境界の選択
    * 適切なパーティション境界（上記のaやb）の選択する方法は以下
        * 管理が自らから選択する
        * データベースに自動的に選択させる
            * 採用例
                * Bigtable
                * HBase
                * RethinkDB
                * MongoDB(ver2.4以前)

### キーのハッシュに基づくパーティショニング
* 方法
    * キーの文字列をハッシュ関数に入れると、生成されたハッシュを一定の範囲の乱数を変えすように見なせる
    * それぞれのパーティションに、キーの範囲ではなく、ハッシュ値の範囲を割り当てる
    * パーティションの境界を疑似乱数的に選択するコンシステントハッシュ法というのもある
    * ハッシュ関数は暗号として強力である必要はないが、実装によっては適していない可能性がある
* 利点
    * パーティションにキーを均等に分散させられる
* 問題点
    * キーの範囲によるパーティションの特性のクエリ実行の効率性は失われる
    * 元々近接していたキーもハッシュ値にするとばらばらになり、ソート順が失われる
        * MongoDBではすべてのパーティションにクエリを送る
        * Riak, CouchDB, Voldemortではパーティショニングをサポートしていない
* 複合プライマリーキーの活用
    * キーを複数列で構成し、パーティションの決定はキーの先頭部分だけのハッシュを使う
    * Cassandraで採用されている方法
    * 先頭列で範囲検索はできないが、最初の列が固定されれば、キーの他の列に対しては範囲スキャンができる
        * 1:Nの関係に有効

### ワークロードのスキューとホットスポットの軽減

* ホットスポットは完全にはなくならない
    * 極端なケース
        * すべての読み書きが同じキーに対して行われるとすべてのリクエストは同じパーティションにルーティングされる
    * 例
        * ソーシャルメディアサイトで、数十万（or それ以上）オーダーのフォロワーをもつユーザーがなにかをすると、フォロワーがそれに反応して一気にアクティビティが増える
            * 大量の書き込みが同じキーに生じる可能性がある
* 自動ですべて対策できない
    * スキューを抑えることはアプリケーション側の役割
        * あるキーにアクセスが集中する場合、ランダムな2桁の数値を追加すると、１つのきーへの書き込みを100個のキーに均等に分散できる
        * しかし、読み込み時に分割したキーのすべてから読み取りを行い、結合する必要があり、管理系処理が増えてしまう

> [!NOTE]
> 
> :memo:コメント
> > スキュー（skew）
>
> おそらく統計学における歪度（skewness）と同じアイデアだと思う。
> 各ノードのデータを、$D=(d_1, d_2, d_3, ..., d_n)^T$ $where$ $n=ノード数$のような各ノードに割り当てられたデータ数$d_i$のベクトルで考えると、歪度は以下の式で計算できるので、全体で均等にした場合の数（$\mu$）から乖離が大きくなればなるほど歪み(skew)が大きいと判断できる。(RyoyaC)
> $$
>  E[(D-\mu)^3]/\sigma^3
> $$
> - ※ $\muはDの平均$、$\sigmaはDの標準偏差$
> - ※ 歪度は、$d_i=\mu$、つまり偏りがないと0になるので、パーティションで均等に分散されたときの歪度は0になる
> 


## パーティショニングとセカンダリインデックス
ここまでのパーティショニング手法は、キー・バリューデータを前提にしており、プライマリーキーでのみアクセスされる。RDBではプライマリーキーと別にセカンダリインデックスが設定されることがあり、その場合はさらに複雑になる

* セカンダリインデックスが設定される場合
    * セカンダリインデックスはレコードをユニークに特定するものではなく、特定な対を含むすべてのレコードにアクセスする
        * Solr, Elasticsearchといった検索サーバーのレーゾンデートル（存在意義）でもある
* パーティショニングにおけるセカンダリインデックスの問題点
    * セカンダリインデックスとパーティションに対応付けるのが難しい
    * セカンダリインデックスをもつデータベースでのパーティショニングには主に2つのアプローチがある
        1. ドキュメントベースのパーティショニング
        2. 語ベースのパーティショニング

### ドキュメントによるセカンダリインデックスでのパーティショニング

* 方法
    * ドキュメントのID（主キー）でパーティションを決定する
    * 各パーティション内でセカンダリインデックスを張ったフィールドの各値に対して各主キーの値を対応させる
* 利点
    * 各パーティションは完全に分離されており、他のパーティションのデータは関知しない
    * ドキュメントの追加・削除・更新はドキュメントIDを含むパーティションだけで扱える
        * このようなインデックスをローカルインデックスと呼ぶ
* 問題点
    * セカンダリインデックスで特定の値でクエリを送るとき、すべてが同じパーティションにあるとは限らないため、すべてのパーティションにクエリを送り、結果を結合する必要があるため、読み取りクエリの付加が高くなる
    * スキャタ/ギャザー

### 語によるセカンダリインデックスでのパーティショニング

* 方法
    * セカンダリインデックスを設定したフィールドの特定の値によってパーティションを決定する
        * 例
            * a~rまでの文字で始まる色はパーティション0に、s~zで始まる色はパーティション1に配置する
        * 語という名前は全文検索インデックスに由来する
    * 語そのものでパーティショニング
        * 範囲に対するスキャンができる
    * 語のハッシュでパーティショニング
        * 負荷の分散の効果が高まる
* 利点
    * セカンダリインデックスの値によって、対応するパーティションがわかるため、ドキュメントベースのパーティショニングと比べて読み取りを効率的にできる
* 問題点
    * 1つのドキュメントの書き込みがインデックスの複数のパーティションに影響する可能性があり、書き込みが低速になる
        * ドキュメント中の語は別々のパーティションやノードにあるかもしれないため、通常セカンダリインデックスの更新は非同期で行われる
        * そのため、書き込み直後に読み取るとインデックスの変更が反映されていない可能性がある
        * 理想的にはインデックスは常に最新にしておきたいが、語でパーティショニングされたインデックスの場合、1つの書き込みで影響を受けるすべてのパーティションに渡る分散トランザクションが必要になるため、すべてのDBでサポートされているわけではない

### ローカルインデックスとグローバルインデックス


| | Read | Write |
| -------- | -------- | -------- |
| ローカルインデックス     | 遅い     | 速い     |
| グローバルインデックス     | 速い     | 遅い     |

* ローカルインデックス
    * パーティションごとに個別のセカンダリインデックスを管理する
    * 書き込みは効率的だが、読み取り負荷が高い
* グローバルインデックス
    * すべてのパーティションｎセカンダリインデックスを管理する
    * 読み取りが効率的な一方書き込みが低速になる

## パーティションのリバランシング

### 時間経過とともに発生するデータベースの変化
#### 変化の例
- クエリのスループットが増大するため、CPUを追加して負荷に対処する
- データベースのサイズが大きくなるので、保存のためにディスクやRAMを追加する
- マシンに障害が発生し、他のマシンがそのマシンが受け持っていた処理を肩代わりすることになる

#### 変化への対応：リバランシング
* こうした変化が生じた場合、あるノードから別のノードへのデータやリクエストに移動が必要になる
* 負荷をクラスタ内のあるノードから別のノードへ移行することをリバランシングと呼ぶ

#### リバランシングの要件
1. リバランシング終了後、負荷（データストレージ、読み書きリクエスト）はクラスタ内のノードで均等に分散されること
2. リバランシングが行われている間、データベースは読み書きを受け付け続けられること
3. ノードを移動させるデータは必要最小限にとどめ、リバランシングが高速に行われ、ネットワークやディスクI/Oの負荷を最小にすること

### リバランス戦略

#### 取るべきではない方法：ハッシュの剰余
* 方法
    * ハッシュのmodをとり、剰余によってノードを割り当てる
        * hash(key) mod 10を計算すると、0~9の数値を返すため、10個のノードそれぞれに均等に割り当てることができる
* なぜダメか
    * ノード数が変化すると、ほとんどのキーをノード間で移動させる必要がある
    * 頻繁にデータの移動が発生し、リバランシングの負荷が高くなる
    * 要件1は満たすが、要件3によりNG

#### パーティション数の固定
* 方法
    * ノード数よりも多いパーティションを作成し、1つのノードに複数のパーティションを割り当てる
    * ノードを追加した場合
        * そのノードには、パーティションの分散が均等になるまで既存のすべてのノードからいくつかのパーティションを移動させる
    * ノードを減らす場合
        * 逆に1つのノードのパーティションを複数のノードに割り当てる
* 利点
    * ノード間を移動するのは、ノードに割り当てらえたパーティション全体のみで、パーティションのノードへの割り当てのみが変化する
    * パーティション数は変化せず、キーのパーティションへの割り当ても変化しない
    * 強力なマシンスペックのノードには多くのパーティションを割り当てることで負荷を調整できる
* 採用例
    * Riak
    * Elasticsearch
    * Couchbase
    * Voldemort
* 適切なパーティション数の選択
    * パーティション数は、データベースをセットアップしたときに決定され、それ以降変更しない
        * 原理的にはパーティションの分割やマージも可能だが、パーティションの分割は多くのデータベースでは実装されていない
        * そのため、最初に設定したパーティション数が利用項なノードの最大数となるため、将来の成長を考慮して十分に大きな数を選択する必要がある
        * しかし、大きすぎる数にすると、管理のオーバーヘッドが大きくなる
    * データセットの合計サイズが大きく変動する場合は適切なパーティション数を選択するのが難しい
        * 各パーティションのサイズはクラスタのデータの総量に比例して大きくなる
        * パーティションが大きくなれば、リバランシングやノード障害のリカバリの負担が大きくなる
        * パーティションのサイズが小さいと、管理のオーバーヘッドが大きくなる



#### 動的なパーティショニング(Editing)
* 背景
    * キーの範囲によるパーティショニングの場合、パーティション間の境界を固定すると不便になる
    * 境涯が不適切な場合、すべてのデータが1つのパーティションに集中し、他のパーティションが空になる可能性がある
    * パーティション境界を手動で再設定するのは手間がかかる
* 手法
    * パーティションが設定されたサイズ以上に大きくなった場合、そのパーティションを2つのパーティションに分割し、それぞれに半分のデータを割り当てる
    * データが削除され、パーティションが特定の閾値より小さくなった場合、近接するパーティションにマージする
    * Bツリーのページ分割/マージと似ている
    * パーティション数を固定する場合と同じく、それぞれのパーティションは1津のノード割り当てられ、ノードは複数のパーティションを扱う
    * HBaseの場合、パーティションファイルの転送は下位層の分散ファイルシステムであるHDFSを通じて行われる
    * 分割とマージが行われるため、各パーティションのサイズは閾値の下限と上限の間に保たれるため、パーティション数はデータサイズに比例する
* 利点
    * パーティション数をデータの総量に適合させられる
    * データが少ない場合はパーティション数は少なくても十分で、データが多くなった場合にパーティションを分割できる
* 問題点
    * 空のデータベースが単一のパーティションからスタートする
    * パーティションの境界をどこに引けばいいか事前情報がないため
    * データセットが小さく、パーティションが分割されるまではすべての書き込み処理は単一のノードに処理され、他のノードは遊んでいる状態になる
    * 問題の緩和
        * HBaseやMongoDBでは空のデータベースに対して初期のパーティション群を設定できる
        * 事前分割という
        * キーの分布がどうなっていくかをユーザーが把握している必要がある

動的なパーティショニングは、キーの範囲によるパーティショニングだけでなく、ハッシュパーティショニングにも適している
適しているケース

#### ノード数に比例するパーティショニング
方法
パーティション数をノード数に比例させ、ノード当たりのパーティション数を固定する
ノード数に変化がなければ、各パーティションのサイズはデータセットのサイズに比例し、ノードを増やすとパーティションは小さくなる
データ量が多くなれば、保存するために必要なノード数も増えるため、このアプローチは各パーティションのサイズが安定したままになる
新しいノードが追加された場合
他の既存のパーティションを分割し、分割後の片方のパーティションを引き受け、他方を元のノードにそのまま置いておく
この処理をランダムに実施すると均等にならない可能性があるが、多数のパーティションに対して平均すれば新しいノードは既存のノードと均等に負荷を受け持つことになる
Cassandra3.0では不均等な分割を回避するような別のリバランシングアルゴリズムが導入された
パーティションの境界をランダムに選択するためには、ハッシュベースのパーティショニングを使用する必要がある
ハッシュ関数が生成する数値の範囲から境界を選択できるようにするため
実際のところ、このアプローチはコンシステントハッシュの定義に最も近い
利点

注意点

### 運用：自動のリバランスと手動のリバランス
#### 自動のリバランス
完全に自動化されたリバランシングは、メンテナンスの運用作業が減るため便利になる
しかし、リバランシングはリクエストを再ルーティングし、大量のデータをノード間で移動させる負荷の大きい処理のため、注意深く実行しなければ、リバランシング進行中に他のリクエストのパフォーマンスに影響する可能性がある
さらに、自動的な障害検出と組み合わされると危険になり得る
例
あるノードが過負荷になり、レスポンス速度が落ちたとき、他のノードは過負荷になったノードが落ちたと判断し、自動的にクラスタを理バランsしてそのノードから負荷を退避させようとする
その場合、過負荷になったノードや他のノードにさらにネットワーク負荷がかかり、状況を悪化させ、カスケード障害を引き起こす可能性がある
そのため、リバランシングの処理のどこかは人を介在させるとよい
予想外の事態が発生するのを防ぐことができるかもしれない

##### 利点

##### 欠点

#### 手動のリバランス


## リクエストのルーティング

### サービスディスカバリ

#### 適切なノードへリクエストをルーティングする３つの方法

#### gossipプロトコル

### パラレルクエリの実行

#### 大規模並列処理

## まとめ
* パーティショニングの目標
* ２つのパーティショニングのアプローチ
* セカンダリインデックスとの関係
* リバランス戦略