# データシステムの将来

## 将来のアプリケーション設計

### はじめに
* 現在の姿について説明する内容が中心だった
* 本章では将来のあるべき姿について論じる
* アプリケーション設計・構築方法の改善を提案

### 視点と目的
* 将来に関する意見や推測は主観的である
* 個人的な意見を述べる際には一人称を使用
* 読者は意見に反対し、自分の意見を形成してよい
* 生産的な議論の出発点となることを目指す
* 混乱している概念を明確にする

### 本書の目標
* 信頼性があり、スケーラブルで、メンテナンス性が高いアプリケーションやシステムの作成方法を調査
* 全章を通じて流れるテーマ
  * 信頼性向上のための耐障害性アルゴリズム
  * スケーラビリティ改善のためのパーティショニング
  * メンテナンス性改善のための進化や抽象化の仕組み

### 本章の内容
* 過去の発想を基盤とし、未来を思い描く
* 頑健性、正確性、進化性、人類への貢献において優れたアプリケーション設計方法を探る

## データのインテグレーション
#### 解決策の多様性
* 問題には複数の解決策が存在
* 各解決策には利点と欠点、トレードオフがある
    * ストレージエンジンの議論
        * log-structuredストレージ
        * Bツリー
        * 列指向ストレージ
    * レプリケーションの議論
        * シングルリーダー
        * マルチリーダー
        * リーダーレス
#### ソフトウェアの実装と選択
* 通常1つのアプローチを選択
* 1つのコードパスを頑健で高性能にするのは難しい
* 汎用ソフトウェアでも特定の利用パターンに合わせて設計されている

#### ソフトウェアと環境の対応づけ
* ソフトウェア製品と適した環境との対応づけを見いだす
* ソフトウェアが適さないワークロードについての理解が重要

#### 複雑なアプリケーションとデータ利用
* データは異なる複数の方法で利用される
* 単一のソフトウェアで対応するのは困難
* 複数のソフトウェアを組み合わせる必要がある

### データの導出による特化したツールの組み合わせ

#### 全文検索インデックスとOLTPデータベースの統合
* 任意のキーワードクエリ処理のために、OLTPデータベースに全文検索インデックスを結合することが一般的
    * PostgreSQLのようなデータベースは全文検索インデックス機能を持つ
* 簡単なアプリケーションには十分だが、専門的な情報抽出ツールには洗練された機能が必要

#### 検索インデックスと永続性のあるシステム
* 検索インデックスは永続性のある記録システムには適していない
* 多くのアプリケーションで異なるツールを組み合わせる必要がある

#### データシステムの結合問題
* データ表現の種類が増えると結合の問題が難しくなる
* データベースと検索インデックスの分離
* 分析システム（データウェアハウス、バッチ処理、ストリーム処理）のデータコピー保持
* キャッシュや非正規化バージョンのオブジェクト管理
* 機械学習、クラシフィケーション、ランク付け、レコメンデーションシステムへのデータ供給
* データ変更に基づく通知

#### 技術の実際の有用性
* ソフトウェアエンジニアの発言（「99%の人々はXしか必要としない」「Xは必要ない」）は個人の経験に基づくことが多い
* データを使ってやりたいことの多彩さは非常に幅広い
* ある人には不要な機能も、別の人には中核的な要求である場合がある

#### データ結合の必要性
* 組織全体のデータフローを考えることで明らかになることが多い

### データフローについての考慮
#### 入出力の明確化
* 同じデータのコピーを複数のストレージシステムで管理する必要がある
* データがどこに書かれ、どの表現がどのソースから導出されるかを明確にする

#### データ保存の流れ
* データはまず記録のシステムのデータベースに書き込む
* データベースに対して行われた変更をキャプチャする（変更データキャプチャ: CDC）
* 変更を順序を保って検索インデックスに適用する

#### 一貫性の確保
* CDCが検索インデックスを更新する唯一の方法なら、一貫性が保たれる
* 新たな入力を渡す唯一の方法は、データベースへの書き込み
* アプリケーションから直接検索インデックスとデータベースの両方に書き込むと一貫性が失われる可能性がある

#### 書き込み順序の決定
* ユーザーからの入力を単一のシステムを通じて流し込むことで、書き込み順序を決定
* 書き込みを同じ順序で処理することでデータの他の表現形式への導出が容易になる

#### ステートマシンレプリケーションの応用
* 全順序を決定する原理が重要
* CDCやイベントソーシングログの使用は二次的
* イベントログに基づいて導出データシステムを更新することで、決定的で冪等にできる
* 障害からの回復が容易になる

### 導出データと分散トランザクション

#### 分散トランザクションの古典的アプローチ
* 「9.4.1アトミックなコミットと2相コミット（2PC）」で論じた手法を利用
* 様々なデータシステム間で一貫性を保つための手法

#### 導出データシステムのアプローチ
* 分散トランザクションと同様の目標を異なる手段で達成
* 分散トランザクション：書き込みの順序をロックで決定（「7.3.2ツーフェーズロック（2PL）」）
* CDC及びイベントソーシング：ログによって順序を決定

#### アトミックなコミットとログベースシステムの比較
* 分散トランザクション：アトミックなコミットで変更が1回だけ適用されることを保証
* ログベースシステム：決定的なリトライと冪等性に基づく

#### 線形化可能性の提供
* トランザクションシステム：線形化可能性を提供、自分で行った書き込みが読み取れる保証
* 導出データシステム：更新が非同期に行われるため、タイミングに関する同様の保証はない

#### 分散トランザクションの限界
* XAの耐障害性とパフォーマンス特性は貧弱、利用性は限定的（「9.4.2分散トランザクションの実際」）
* 優れた分散トランザクションプロトコルの開発は可能だが、広く利用されることは難しい

#### ログベースの導出データシステムの優位性
* 様々なデータシステムを結合する上で最も期待できるアプローチ
* 結果整合性の扱い方を学ぶ必要がある
* 「12.3正確性を求めて」では、非同期システム上で強い保証を実装するためのアプローチを論じる

### 全順序の限界

#### 小規模システムでの全順序
* 小規模システムでは全順序を持つイベントログの構築が現実的
* シングルリーダーレプリケーションを行うデータベースが普及

#### 規模拡大と複雑化による限界
* システムの規模が大きくなりワークロードが複雑化すると限界が生じる
* 全順序を持つログを構築するには、単一のリーダーノードを通過する必要がある
* イベントのスループットが単一のマシンで処理できない場合、パーティショニングが必要（「11.1.2パーティション化されたログ」）

#### パーティショニングと順序の曖昧性
* パーティショニングにより異なるパーティション内のイベントの順序が曖昧になる

#### 地理的に分散したデータセンター
* データセンターが分散している場合、各データセンターに個別のリーダーを置く
* 異なるデータセンターから生じたイベントの順序は定義されない（「5.3 マルチリーダーレプリケーション」）

#### マイクロサービスアーキテクチャ
* サービスとその永続性のある状態を独立した単位としてデプロイ
* 異なるサービスから発生するイベントの順序は定義されない（「4.2.2 サービス経由でのデータフロー：RESTとRPC」）

#### クライアント側の状態管理
* クライアント側でユーザー入力に基づいて即座に更新される状態を管理
* クライアントとサーバーは異なる順序でイベントを見る可能性が高い

#### 全順序ブロードキャストと合意
* イベントの全順序を決定することは全順序ブロードキャストと呼ばれ、合意と等価（「9.4.3.1 合意アルゴリズムと全順序ブロードキャスト」）
* ほとんどの合意アルゴリズムは単一のノードのスループットに依存

#### 合意アルゴリズムの課題
* 単一ノードのスループットを超えてスケールし、地理的に分散した環境で働く合意アルゴリズムの設計は未解決の研究課題

### 因果律を把握するためのイベントの順序づけ

#### 全順序が不要な場合
* 因果関係がないイベントは任意の順序で並べられる
* 同じオブジェクトに対する更新は全順序を決定できる
* 因果関係の例
    * ソーシャルネットワークでの友人関係解除とメッセージ送信の順序
      * 友人解除後にメッセージ送信した場合、元友人には見られないと期待
      * 友人関係とメッセージが別々の場所に保存されている場合、順序依存関係が失われる可能性

#### 順序依存関係の問題
* 因果関係が把握されないと順序が狂う可能性
* 友人解除イベントより先にメッセージ送信イベントが処理されると誤った通知が元友人に送られる

#### 解決策の模索
* 論理タイムスタンプの利用
  * 全順序を提供できるが、受信側で順序どおりに配送されないイベントに対応する必要
* イベントに追加のメタデータを持たせる
  * イベントの識別子を後に生じたイベントから参照して因果関係を記録

### 今後の展望
* 全順序ブロードキャストのボトルネックを避けつつ、因果関係を効率的に把握できるアプリケーション開発のパターンの出現を期待

## バッチ処理とストリーム処理

### データ結合の目標
* データを適切な場所に適切なフォーマットで置く
* 入力データの取り込み、変換、結合、フィルタリング、集計、モデルのトレーニング、評価、出力の書き出しが必要

### バッチおよびストリームプロセッサの役割
* 検索インデックスやマテリアライズドビュー、レコメンデーション、集計メトリクスなどの導出データセットを生成
* バッチ処理: 既知の固定サイズの入力を処理
* ストリーム処理: 無限のデータセットを処理

### 処理エンジンの実装
* Spark: ストリームをマイクロバッチに分割してバッチ処理エンジン上でストリーム処理
* Apache Flink: バッチ処理をストリーム処理エンジン上で実行
* パフォーマンスの特徴に違いがある

### 導出された状態の管理

#### バッチ処理の特徴
* 関数型プログラミングのアプローチ
* 出力が入力にのみ依存し、副作用を持たず、入力をイミュータブルとして扱う
* 出力には追記のみを行う、決定的で純粋な関数を推奨

#### ストリーム処理の特徴
* 耐障害性を持つ管理された状態を扱う
* 決定的関数の原則は、耐障害性とデータフローのシンプル化に優れる

#### 導出データシステムの管理
* データセットから他のデータセットを導出するパイプライン
* システムからの状態の変更のプッシュ
* 導出システムへの変更の適用

#### 同期と非同期の違い
* リレーショナルデータベース: 同期的にセカンダリインデックスを更新
* イベントログ基盤のシステム: 非同期に動作し、障害の影響を限定

#### 分散トランザクションの限界
* 一部で失敗があれば中断し、障害がシステム全体に広がる可能性がある

#### パーティショニングとセカンダリインデックス
* セカンダリインデックスがパーティションの境界をまたぐ場合
* 書き込みを複数のパーティションに送る、または読み取りをすべてのパーティションに送る必要がある
* 非同期管理のインデックスが信頼性とスケーラビリティに優れる

### アプリケーションの進化に伴うデータの再処理

#### バッチ処理とストリーム処理の役割
* ストリーム処理: 入力の変化をわずかな遅延で導出ビューに反映
* バッチ処理: 大量の履歴データを再処理し、新たなビューを導出

#### システムのメンテナンスと進化
* 再処理によって新しい機能や要求の変化をサポート
* スキーマの進化: 再処理を行わない場合は単純な変更に限定される
  * 新しいフィールドや種類のレコードの追加など
* 再処理を行うことでデータセットを異なるモデルに再構築し、新しい要求に対応

#### 導出ビューの段階的進化
* 突然のマイグレーションではなく、並行に新旧のスキーマをメンテナンス
* 少数のユーザーを新しいビューに移行させ、パフォーマンステストやバグ発見を行う
* 徐々に新しいビューへ移行し、最終的に古いビューを削除

#### 段階的マイグレーションの利点
* 問題が発生した場合に容易に反転できる
* 回復不能なダメージのリスクを減らし、システム改善の速度を高める

### ラムダアーキテクチャ

#### ラムダアーキテクチャの概要
* バッチ処理: 履歴データの再処理
* ストリーム処理: 直近の更新の処理
* イミュータブルなイベントを成長し続けるデータセットに追加
* 読み取りに最適化されたビューを導出

#### 二つのシステムの並列動作
* バッチ処理システム（Hadoop MapReduce）
* ストリーム処理システム（Storm）

#### ストリームプロセッサとバッチプロセッサの役割
* ストリームプロセッサ: イベントを取り込み、ビューの大まかな更新を迅速に行う
* バッチプロセッサ: 後から同じイベントの集合を消費し、完全に正しいバージョンの導出ビューを生成

#### 設計の根拠
* バッチ処理はシンプルでバグが少ない
* ストリーム処理は信頼性で劣り、耐障害性を持たせるのが難しい
* ストリーム処理は高速な概算アルゴリズムを利用
* バッチ処理は低速だが正確なアルゴリズムを使用

#### 現実的な問題
* 同じロジックをバッチ処理とストリーム処理の両方でメンテナンスする負担
* バッチとストリーミングの環境で動作する演算を抽象化するライブラリの存在（SummingBird）
* 2つの異なるシステムでのデバッグ、チューニング、メンテナンスの運用上の複雑さ

#### 出力のマージ
* ストリームパイプラインとバッチパイプラインは別々の出力を生成
* ユーザーからのリクエストにレスポンスを返すためにマージが必要
* シンプルな集計なら容易だが、複雑な操作だとマージの処理は難しい

#### インクリメンタルなバッチ処理の必要性
* 履歴データセット全体の頻繁な再処理は負担が大きい
* インクリメンタルなバッチ処理（例: 1時間分のデータを1時間の終わりごとに処理）
* はぐれイベントやバッチ間の境界をまたぐウィンドウの処理などの問題

#### バッチ演算の複雑化
* インクリメンタルなバッチ処理で複雑さが増す
* バッチ層をシンプルに保ちたい目標に反する可能性

### バッチ処理とストリーム処理の統合

#### 統合の利点
* ラムダアーキテクチャの欠点を解消し、利点を享受
* バッチ演算とストリーム演算を同じシステム上で実装可能

#### 必要な機能
* **履歴イベントのリプレイ機能**
    * ログベースのメッセージブローカーはメッセージのリプレイが可能（「11.1.2.6古いメッセージのリプレイ」参照）
    * ストリームプロセッサはHDFSのような分散ファイルシステムからの入力を読み取れる
* **exactly-onceセマンティクス**
    * 出力が障害が生じなかった場合と同じになることを保証（「11.3.4耐障害性」参照）
    * 障害を起こしたタスクの断片的な出力をすべて破棄する必要
* **イベント発生時刻によるウィンドウ処理**
    * 処理の時間ではなく、イベントの発生時刻によってウィンドウ処理を行うツール
    * 履歴イベントの再処理では処理の時刻は無意味（「11.3.2時間に関する考察」参照）
    * Apache Beamはこういった演算を表現するAPIを提供し、Apache FlinkやGoogle Cloud Dataflowで実行可能

## データベースを解きほぐす
#### 情報管理システムの共通機能
* データベース、Hadoop、オペレーティングシステムはデータを保存し、ユーザーがデータを処理しクエリを実行できるようにする
    * データベース: テーブルの行、ドキュメント、グラフ中の頂点などのデータモデルのレコードにデータを保存
    * オペレーティングシステム: データをファイルに保存
* 核となる機能は「情報管理」

#### HadoopエコシステムとUnixの類似点
* Hadoopは分散バージョンのUnixのようなもの
* 実際には多くの違いが存在
  * 多くのファイルシステムは一千万の小さなファイルを扱うのが苦手
  * データベースが一千万の小さなレコードを持つのは普通

#### Unixとリレーショナルデータベースの哲学
* Unix: 低レベルなハードウェアの抽象化を提供
* リレーショナルデータベース: ディスク上のデータ構造、並行性、クラッシュからのリカバリなどの複雑さを隠蔽する高レベルの抽象化を提供
* Unixはパイプとバイト列に過ぎないファイルを提供
* データベースはSQLとトランザクションを提供

#### どちらのアプローチが優れているか
* Unix: ハードウェアリソースの薄いラッパーとして「シンプル」
* リレーショナルデータベース: クエリの最適化、インデックス、結合の手法、並列性の制御、レプリケーションなどのインフラを隠蔽する「シンプル」
* 1970年代から続く緊張関係、決着はついていない

#### NoSQLムーブメントの解釈
* Unix風の低レベルの抽象化のアプローチを分散OLTPのデータストレージの分野に適用

#### 両者の哲学の調和
* Unixとリレーショナルデータベースの最善の部分を組み合わせることを目標にする

### データストレージ技術の組み合わせ

#### データベースが提供する機能
* **セカンダリインデックス**
  * フィールドの値に基づいてレコードを効率的に検索
  * 例: 「3.1.5その他のインデックス構造」

* **マテリアライズドビュー**
  * 事前にクエリ結果を計算したキャッシュ
  * 例: 「3.3.4集計：データキューブとマテリアライズドビュー」

* **レプリケーションログ**
  * 他のノード上にあるデータのコピーを最新に保つ
  * 例: 「5.1.4レプリケーションログの実装」

* **全文検索インデックス**
  * キーワードによるテキスト検索を可能にする
  * 例: 「3.1.5.3全文検索と曖昧インデックス」
  * リレーショナルデータベースに組み込まれることもある

#### バッチプロセッサやストリームプロセッサの役割
* **全文検索インデックスの構築**
  * 例: 「10.2.4バッチワークフローの出力」

* **マテリアライズドビューの管理**
  * 例: 「11.3.1.3マテリアライズドビューの管理」

* **変更データのレプリケーション**
  * 例: 「11.2.2変更データのキャプチャ」

#### データベースと導出データシステムの類似点
* バッチプロセッサやストリームプロセッサを使って構築される機能は、データベースや導出データシステムに組み込まれる機能と類似している

### インデックスの生成

#### インデックス作成のプロセス
* `CREATE INDEX`の実行で新しいインデックスを作成
* データベースが一貫性のあるテーブルのスナップショットをスキャン
  * インデックス対象フィールドのすべての値を取り出し、ソートし、インデックスを書き出す

#### 書き込みのバックログ処理
* インデックス作成中にテーブルはロックされず、書き込みが継続される
* スナップショット後の書き込みのバックログを処理
* 処理完了後、テーブルへの書き込み時にインデックスを最新状態に保つ

#### プロセスの類似性
* 新たにフォロワーのレプリカをセットアップするプロセスに似ている（「5.1.2新しいフォロワーのセットアップ」）
* ストリーミングシステムで変更データキャプチャを立ち上げるプロセスにも類似（「11.2.2.2初期のスナップショット」）

#### 既存データの再処理
* `CREATE INDEX`は既存データセットの再処理
  * 既存データに対する新しいビューとしてインデックスを導出
  * 既存データは、すべての変更ログではなく、状態のスナップショットからも導出可能（「11.2.4状態、ストリーム、イミュータビリティ」参照）

### すべてに関するメタデータベース

#### データフローの統一的視点
* 組織全体のデータフローは巨大なデータベースのように見える
* バッチ、ストリーム、ETLプロセスはデータベースのサブシステムのように動作

#### バッチおよびストリームプロセッサの役割
* トリガ、ストアドプロシージャ、マテリアライズドビューのメンテナンスルーチンのように機能
* 管理する導出データシステムは様々な種類のインデックスのような役割

#### 導出データシステムのアーキテクチャ
* 機能を単一の統合データベース製品ではなく、様々なマシン上で動作し、異なるチームが管理するソフトウェアとして提供

#### 将来の方向性
* 単一のデータモデルやストレージフォーマットは存在しない
* 様々なストレージや処理ツールを一つのシステムにまとめるための2つのアプローチ
* フェデレーテッドデータベース（Federated Database）
    * 読み取りの統合
    * 統一されたクエリインターフェースを提供（ポリストアアプローチ）
        * 例: PostgreSQLのForeign Data Wrapper
    * 高レベルのクエリ言語と洗練されたセマンティクスを持つが、実装は複雑
* 解体されたデータベース（Unbundled Database）
    * 書き込みの統合
    * 複数のシステムにわたる書き込みの同期を重視
    * 変更データキャプチャやイベントログを通じてデータの変更を適切な場所に到達させる
    * 信頼性を保ちながらストレージシステムをつなぎ合わせる
    * Unixの伝統に従い、小さなツール群を一様な低レベルAPI（パイプ）で通信し、高レベルの言語（シェル）で合成

### 解体されたシステムと結合されたシステム

#### データベースの役割の継続
* 解体が未来の方向性であっても、現在の形のデータベースは依然として必要
* データベースはストリームプロセッサの状態管理やバッチ・ストリームプロセッサの出力クエリ処理に不可欠（「10.2.4バッチワークフローの出力」及び「11.3ストリームの処理」参照）

#### 特化したクエリエンジンの重要性
* 特定のワークロードに最適化されたクエリエンジンの需要は続く
* 例: MPPデータウェアハウスのクエリエンジンは探索的な分析クエリに最適化（「10.2.5Hadoopと分散データベースとの比較」参照）

#### 複数のインフラストラクチャの複雑さ
* 多様なインフラストラクチャを管理することの複雑さ
  * 学習曲線、設定の問題、運用の落とし穴
* デプロイする部品の数を減らす価値がある
* 統合された単一のソフトウェア製品は、設計目標に対して優れたパフォーマンスを発揮し、予測しやすい

#### 早すぎる最適化のリスク
* 不必要な規模を想定して構築することは無駄な努力
* 柔軟性を欠く設計に陥るリスク
* 解体の目標は、特定のワークロードで個々のデータベースと競うことではない
* 複数の異なるデータベースを組み合わせ、幅広いワークロードにおいて優れたパフォーマンスを実現する

#### 深さではなく幅の問題
* 「10.2.5Hadoopと分散データベースとの比較」で論じた多様性に関連
* 単一の技術で必要なすべてを実現できる場合は、その製品を利用する方が良い
* 解体と合成のメリットは、すべての要求を満たす単一のソフトウェアが存在しない場合に現れる

### 欠けているものは何か？

#### 現状の課題
* データシステムを合成するためのツールは改善されているが、大きな欠けている部分がある
* Unixのシェルに相当する高レベル言語がない

#### 理想のツール
* Unixのパイプのようにシンプルにデータシステムを合成できるツール
  * 例: `mysql | elasticsearch` のように宣言できるもの

#### 解体版のCREATE INDEX
* MySQLデータベース内のすべてのドキュメントをElasticsearchクラスタにインデックス作成
* カスタムアプリケーションコードを書かずに、MySQLの変更をキャプチャし検索インデックスに自動適用

#### 広範なシステムでの結合
* あらゆる種類のストレージやインデックス付けシステムで同様の結合が可能
* 更新キャッシュの事前計算をもっと容易にする

#### マテリアライズドビューの定義
* 事前計算されたキャッシュとしてのマテリアライズドビューを宣言的に定義
  * グラフに対する再帰的なクエリやアプリケーションロジックを含む複雑なクエリ

#### 初期研究の期待
* 差分データフロー（differential dataflow）のような初期研究がある
* これらのアイデアがプロダクションシステムに実装されることを期待

### データフロー中心のアプリケーション設計

#### データベースの解体アプローチ
* **「データベースインサイドアウト」アプローチ**
  * 2014年のカンファレンス発表に由来
  * 特化したストレージと処理システムをアプリケーションコードで合成

#### デザインパターンと議論の出発点
* 新しいアーキテクチャではなく、デザインパターンや議論の出発点として捉える
* 他者の考えや学ぶべき概念を練り合わせたもの

#### 関連する言語と概念
* **データフロー言語**
  * 例: Oz、Juttle
* **関数型リアクティブプログラミング言語（FRP）**
  * 例: Elm
* **論理プログラミング言語**
  * 例: Bloom
* **解体（unbundling）**
  * Jey Krepsの提唱

#### スプレッドシートのデータフロープログラミング機能
* セルに数式を入力し、入力データの変化に応じて再計算
* データシステムでも同様の機能を目指す
  * レコードの変化に応じてインデックスやキャッシュビューを自動更新

#### データシステムの要件
* 耐障害性、スケーラビリティ、データの永続性
* 異なる技術を結合し、既存のライブラリやサービスを再利用
* 特定の1つの言語、フレームワーク、ツールに依存しない

#### 今後の調査
* 解体されたデータベースとデータフローを中心にアプリケーションを構築する方法を調べる

### 導出関数としてのアプリケーションコード

#### データセットの導出
* データセットが他のデータセットから導出される際、変換関数を経由する

#### セカンダリインデックス
* 単純明快な変換関数による導出データセット
* ベーステーブル中の各行やドキュメントからインデックス対象の値を取り出し、ソート
* 例: BツリーやSSTableのインデックス（3章参照）

#### 全文検索インデックス
* 言語検出、単語の切り分け、ステミング、レンマ化、スペル修正、同義語識別などの自然言語処理関数を適用
* 効率的なルックアップのための転置インデックスを構築

#### 機械学習システム
* モデルはトレーニングデータに特徴抽出と統計解析関数を適用して導出
* 新しい入力データにモデルを適用すると、出力はトレーニングデータから導出される

#### キャッシュ
* UIに表示される形式に集約されたデータを含む
* UIが変化するとキャッシュの展開や再構築方法も更新が必要

#### データベースの組み込み機能
* セカンダリインデックスの導出関数は中核的な機能として多くのデータベースに組み込まれている
  * `CREATE INDEX`で呼び出せる
* 全文検索インデックスの基本的な機能はデータベースに組み込まれていることもあるが、洗練された機能にはドメイン固有のチューニングが必要

#### 機械学習と特徴エンジニアリング
* 特徴エンジニアリングはアプリケーション固有になりがち
* ユーザーとのやりとりやアプリケーションのデプロイに関する知識が必要

#### カスタムコードの必要性
* 標準的でない導出データセットの生成にはカスタムコードが必要
* リレーショナルデータベースではトリガ、ストアドプロシージャ、ユーザー定義関数がサポートされるが、後付けのものである（「11.1イベントストリームの転送」参照）

### アプリケーションコードと状態の分離

#### データベースの限界
* 理論的にはデータベースは任意のアプリケーションコードをデプロイする環境になりえる
* 実際には、データベースは現代的なアプリケーション開発の要求を満たしていない
  * 依存関係、パッケージ管理、バージョン管理、ローリングアップグレード、進化性、モニタリング、メトリクス、ネットワークサービスの呼び出し、外部システムとの結合

#### クラスタ管理ツールの役割
* Mesos、YARN、Docker、Kubernetesはアプリケーションコードの実行を目標に設計
* データベースのユーザー定義関数よりも特化している

#### 状態管理とアプリケーションコードの分離
* 永続性のあるデータストレージ部分とアプリケーションコードの実行部分を分離するのが妥当
* 独立性を保ちながらやりとり可能

#### 状態を持たないサービス
* 多くのWebアプリケーションは状態を持たないサービスとしてデプロイ
* 任意のユーザーリクエストを任意のアプリケーションに渡し、リクエスト処理後はサーバーがリクエストを忘れる
* 状態は通常データベースに保持

#### 状態とロジックの分離
* トレンドは状態を持たないアプリケーションロジックと状態管理（データベース）の分離
* アプリケーションロジックをデータベースに置いたり、永続化される状態をアプリケーションに置くことではない

#### データベースの役割
* データベースはミュータブルな共有変数として振る舞う
* 永続性、並行性の制御、耐障害性を提供

#### ミュータブルな変数の変更通知
* 多くのプログラミング言語はミュータブルな変数の変更通知をサポートしていない
* 通常は定期的なポーリングが必要
* 変更へのサブスクライブ機能は立ち上がったばかり（「11.2.2.4変更ストリームのためのAPIサポート」参照）

### データフロー：状態の変化とアプリケーションコードとの相互作用

#### データフローの概念
* アプリケーションコードと状態管理の関係を再調整
* 状態の変化に反応して他の場所での状態の変化を引き起こす

#### データベースの受動的な扱いからの転換
* データベースをアプリケーションから操作される受動的な変数として扱うのではなく、状態と変化を処理するコードとの相互作用を重視

#### イベントの反応
* データベース変更ログをサブスクライブ可能なイベントストリームとして扱う（「11.2データベースとストリーム」）
* メッセージパッシングシステムやタプル空間モデルの概念に基づく

#### データベースの解体
* データベース内でのトリガやセカンダリインデックスの更新をプライマリデータベースの外部に適用
* キャッシュ、全文検索インデックス、機械学習、分析システムなどに適用

#### ストリーム処理とメッセージングシステムの役割
* ストリーム処理やメッセージングシステムを使用
* 非同期ジョブの実行と導出データの管理は異なる性質を持つ

#### 順序の重要性
* 状態の変更の順序が重要
* イベントログから導出される複数のビューが一貫性を保つために同じ順序でイベントを処理する必要

#### 耐障害性の必要性
* メッセージの配信と導出された状態の更新の信頼性
* メッセージの順序と処理の耐障害性を保証することが重要

#### ストリームプロセッサの利点
* 順序と信頼性の保証を大規模な環境で提供
* アプリケーションコードがストリームのオペレータとして動作

#### システム構築の方法
* パイプでUnixのツールを連鎖させるようにストリームプロセッサを合成
* それぞれのオペレータが入力として状態の変更のストリームを取り、出力として別の状態の変更のストリームを出力

### ストリームプロセッサとサービス

#### 現在のアプリケーション開発のスタイル
* REST APIのような同期的なネットワークリクエストを通じてやりとりするサービスに機能を分割（「4.2.2サービス経由でのデータフロー：RESTとRPC」参照）
* サービス指向アーキテクチャの主要な利点は疎結合を通じた組織的なスケーラビリティ
  * 各チームが独立して作業、デプロイ、更新できる

#### ストリームのオペレータとデータフローシステム
* マイクロサービスに似た特徴が多いが、通信は非同期のメッセージストリームを使用
* 耐障害性と高パフォーマンスの利点（「4.2.3メッセージパッシングによるデータフロー」）

#### 通貨換算の例
* マイクロサービスアプローチ
  * 購入処理コードが為替レートサービスやデータベースに問い合わせ
* データフローアプローチ
  * 購入処理コードが為替レートの更新ストリームをサブスクライブ
  * ローカルデータベースに為替レートを記録し、購入時にはローカルデータベースに問い合わせ

#### データフローアプローチの利点
* 高速な処理と高い耐障害性
* ネットワークリクエストを不要にすることで信頼性と速度を向上
* 購入イベントと為替レートの更新イベントとのストリーム結合（「11.3.3.2ストリーム‐テーブル結合（ストリームのエンリッチ）」参照）

#### 時間に依存する結合
* 購入イベントが再処理される場合、為替レートは変わる可能性がある
* オリジナルの出力を再構築するには、購入時点の為替レートの履歴が必要
* 時間に対する依存性への対応が必要（「11.3.3.4結合の時間に対する依存」参照）

#### 変更のストリームをサブスクライブ
* スプレッドシートの演算モデルに近い
* データが変化すると、そのデータに依存する導出データも素早く更新

#### データフロー中心のアプリケーション構築の将来性
* 解決していない問題はあるが、データフローの発想を中心に置くアプローチは将来性がある

### 導出された状態の監視

#### データフローシステムの提供
* 導出データセット（検索インデックス、マテリアライズドビュー、予測モデルなど）の生成と最新状態の維持
* 書き込みパス（writepath）：情報がシステムに書き込まれ、バッチ及びストリーム処理を経て導出データセットに反映されるプロセス

#### 導出データセットの目的
* クエリを行うために作成
* 読み取りパス（readpath）：ユーザーからのリクエストを処理し、導出データから読み取り、ユーザーへのレスポンスを構築

#### 書き込みパスと読み取りパス
* 書き込みパス：データがやってきた時点で処理可能な部分を事前に計算
* 読み取りパス：データに対する問い合わせがあった時点で行われる処理
* 書き込みパスは先行評価に、読み取りパスは遅延評価に似ている

#### 導出データセットの役割
* 書き込みパスと読み取りパスの接点
* 書き込み時の処理量と読み取り時の処理量のトレードオフを表す

### マテリアライズドビューとキャッシュ

#### 全文検索インデックスの例
* **書き込みパス**
  * 全文検索インデックスを更新
  * ドキュメント中の全語のインデックスエントリを更新

* **読み取りパス**
  * インデックスからキーワードを検索
  * クエリ中の語に対して検索を行い、ブール論理を適用

#### インデックスの有無による処理の違い
* **インデックスがない場合**
  * 書き込みパスの処理は少ない
  * 読み取りパスの処理が多くなり、全ドキュメントをスキャン（grepのように）

* **インデックスがある場合**
  * 書き込みパスの処理が多い
  * 読み取りパスの処理が少ない

#### 事前計算とキャッシュ
* **ありえるすべてのクエリに対する事前計算**
  * 読み取りパスの処理が非常に少なくなる
  * 無限の時間とストレージ空間が必要になるため非現実的

* **有限のクエリに対する事前計算**
  * 最もよく現れるクエリに対してのみ検索結果を事前計算
  * 新しいドキュメントが現れた場合は更新が必要

#### キャッシュとマテリアライズドビュー
* **頻出クエリに対するキャッシュ**
  * インデックスを使わずに高速に結果を返す
  * 更新が必要な場合はマテリアライズドビューと呼ぶことも

#### 書き込みパスと読み取りパスの境界
* インデックスだけでなく、キャッシュやマテリアライズドビューも関与
* 結果を事前に計算しておくことで書き込みパスの処理を増やし、読み取りパスの処理を減らす

#### 境界の調整例
* **Twitterの例（「1.3.1負荷の表現」参照）**
  * 通常のユーザーと有名人で書き込みパスと読み取りパスの境界を異なる場所に設定
* 600ページにわたる議論の集大成

### ステートフルでオフライン動作できるクライアント

#### 境界をずらす考え方
* 境界をずらすことで実際的な視点から書き込みと読み取りパスを議論可能

#### サーバークライアントモデルの前提
* Webアプリケーションの普及により、クライアントは大部分が状態を持たず、サーバーがデータを掌握するモデルが一般的に

#### 技術の進化
* クライアント側での状態管理が可能に
  * シングルページJavaScript Webアプリケーションがクライアント側でのユーザーインターフェースのインタラクションやローカル永続化ストレージを含む
  * モバイルアプリケーションも多くの状態をデバイス上に保存可能

#### オフラインファーストのアプリケーション
* ローカルデータベースを活用し、ネットワーク接続が利用できるときにバックグラウンドで同期を行う
* ユーザーインターフェースが同期的なネットワークリクエストを待たず、ほとんどの作業をオフラインで行える
    * 例: モバイルデバイスの低速で信頼できないセルラーインターネット接続（「5.3.1.2オフラインで運用されるクライアント」参照）

#### 新しい機会
* ステートレスのクライアントから、デバイス上で状態を管理する方向へ進む
* デバイス上の状態はサーバー上の状態のキャッシュと考えられる
* 画面上のピクセルはクライアントアプリ内のモデルオブジェクトに対するマテリアライズドビューであり、そのモデルオブジェクトはリモートデータセンター内の状態のローカルレプリカ

### クライアントへの状態の変化のプッシュ

#### 静的なWebページと状態の更新
* 通常のWebページでは、ページをリロードしない限り、サーバー側でのデータ変化をブラウザは認識しない
* ブラウザはデータをある時点でのみ読み込み、静的なものと見なす

#### 更新のポーリングとサブスクリプション
* RSSのようなHTTPベースのフィードのサブスクリプションプロトコルは基本的なポーリング
* デバイスの状態は明示的にポーリングしない限り更新されない古いキャッシュ

#### サーバー送信イベントとWebSockets
* HTTPのリクエスト／レスポンスパターンより進んだプロトコル
* サーバー送信イベント（EventSource API）やWebSocketsは、TCP接続を開いたままにしてサーバーから能動的にメッセージをプッシュ可能
* クライアント側の状態を古くなりにくくできる

#### 書き込みパスの拡張
* 状態の変化をクライアントデバイスにプッシュすることは、書き込みパスをエンドユーザーにまで広げること
* 初期化時点では読み取りパスで初期状態を取得し、その後はサーバーからの状態変更ストリームに依存

#### エンドユーザーのデバイスへの拡張
* ストリーム処理やメッセージングの考え方はエンドユーザーのデバイスにも適用可能
* エンドユーザーのデバイスがオフラインになることがあるが、この問題は既に解決済み
  * 「11.1.2.3コンシューマのオフセット」で論じたログベースのメッセージブローカーの方法を使用
  * 各デバイスが小さなイベントストリームのサブスクライバとして動作

### エンドツーエンドのイベントストリーム

#### 最近のツール群の特徴
* Elm言語、FacebookのReact、Reduxなどはイベントストリームをサブスクライブしてクライアント側の状態を管理
* このイベントストリームはイベントソーシングに似た構造を持つ（「11.2.3イベントソーシング」参照）

#### プログラミングモデルの拡張
* サーバーが状態変化のイベントをクライアント側のイベントパイプラインにプッシュできるようにする
* 状態の変化がエンドツーエンドで書き込みパスを流れる
* ユーザーの操作による状態変化が他のデバイスのユーザーインターフェースにまで到達

#### 低遅延の伝播
* 状態の変化が1秒以下の遅延で伝播
* インスタントメッセージングやオンラインゲームなどでリアルタイムアーキテクチャが既に使用されている

#### 課題
* 状態を持たないクライアントとリクエスト／レスポンスのインタラクションが既存のデータベース、ライブラリ、フレームワーク、プロトコルに深く浸透
* ほとんどのデータストアは読み取りや書き込みの操作をリクエスト／レスポンスの形でサポート
* 変更へのサブスクライブを提供するものは少数（「11.2.2.4変更ストリームのためのAPIサポート」）

#### 構築方法の再考
* 書き込みパスをエンドユーザーに至るまで拡張するためには、システムの構築方法を根本的に考え直す必要
* リクエスト／レスポンスのインタラクションからデータフローのパブリッシュ／サブスクライブに移行

#### メリット
* 反応性の良いユーザーインターフェースとオフラインサポートの向上

#### 設計への提案
* データシステムを設計する際に、現在の状態に対するクエリだけでなく、変更のサブスクライブという選択肢も考慮

### 読み取りもイベントである

#### ストリームプロセッサとストアの関係
* ストリームプロセッサが導出データをストアに書き込み、ユーザーがそのストアにクエリを実行
* ストアは書き込みパスと読み取りパスの境界として機能
* ストアではランダムアクセスでの読み取りクエリが可能

#### ストリームプロセッサの役割
* ストリームプロセッサも状態を管理する必要がある（「11.3.3ストリームの結合」参照）
* フレームワークによってはストリームプロセッサの状態に対して外部のクライアントからクエリを実行可能

#### 読み取りリクエストのイベント化
* 読み取りリクエストをイベントのストリームとして表現
* 書き込みイベントと読み取りイベントの両方をストリームプロセッサを通じて送信
* プロセッサは読み取りイベントに対応して結果を出力ストリームに流す

#### ストリーム‐テーブル結合の実行
* 読み取りクエリのストリームとデータベース間でストリーム‐テーブル結合を行う
* 読み取りイベントはデータを保持しているデータベースパーティションに送信（「6.5リクエストのルーティング」参照）

#### 読み取りイベントのログのメリット
* 因果関係とデータの履歴を追跡しやすくなる
* ユーザーがどのデータを見て判断したかを再構築可能
* 例: オンラインショップでの予想出荷日や在庫状況が購入に与える影響の分析

#### システム最適化の課題
* 読み取りイベントの永続化はストレージとI/Oのコスト増大を招く
* オーバーヘッドを軽減するための最適化は未解決の研究課題

#### 実運用上のログの活用
* 読み込みリクエストのログを運用上の目的で記録しているなら、そのログをリクエストのソースとして利用可能

### 複数パーティションにわたるデータの処理

#### 単一パーティションのクエリ
* 単一パーティションにアクセスするクエリにストリームを使うのは過剰
* ストリームプロセッサのメッセージルーティング、パーティショニング、結合のインフラを活用

#### 分散実行の可能性
* 複雑なクエリの分散実行にストリームプロセッサのインフラを活用
* Stormの分散RPCがこのパターンをサポート（「11.3.1.5メッセージパッシングとRPC」）

#### Twitterの例
* URLを見た人数を計算
* URLをツイートした人物のフォロワーの和集合の要素数を計算
* Twitterのユーザー集合はパーティショニングされているため、多数のパーティションの結果を組み合わせる

#### 不正検知の例
* 購入イベントの不正リスクを評価
* ユーザーのIPアドレス、メールアドレス、支払い住所、出荷先住所のレピュテーションスコアを調査
* レピュテーションデータベースはパーティショニングされているため、データセットの結合が必要

#### MPPデータベースのクエリ実行グラフ
* 複数パーティションにわたる結合の実行
* 内部的なクエリ実行グラフが類似の特徴を持つ（「10.2.5Hadoopと分散データベースとの比較」）

#### ストリームプロセッサの利用
* 複数パーティションにわたる結合にはストリームプロセッサを利用可能
* 既製品のデータベースを使う方がシンプルな場合もある
* クエリをストリームとして扱うのは大規模なアプリケーションに有用

#### まとめ
* ストリームプロセッサのインフラは複数パーティションの分散クエリに適用可能
* 従来のデータベースソリューションが限界に達する場合の選択肢


## 正確性を求めて

#### ステートレス vs. ステートフルシステム
* ステートレスなサービス（読み取りのみ）は問題が発生しても修正が容易
* ステートフルなシステム（データベース）は問題が発生すると永続的な影響が出るため、より慎重な考慮が必要

#### 信頼性と正確性の追求
* 信頼性が高く、正確なアプリケーションを構築する必要
* セマンティクスが明確で理解可能なプログラムが求められる

#### トランザクションの役割と限界
* 40年間、原子性、分離性、永続性（ACID）が正確なアプリケーション構築の基本ツール
* 弱い分離レベルの混乱やトランザクションの放棄が見られる分野も存在
* 一貫性の定義が不明確で、可用性向上のために弱い一貫性を受け入れるケースも

#### 問題の複雑さとエンジニアリングの課題
* 特定のアプリケーションが特定のトランザクション分離レベルで安全かどうかを判断するのは困難
* 並行性が低い状況では単純な解決方法が有効に見えるが、負荷が大きい環境ではバグが露見
* Kyle KingsburyのJepsenテストで、製品の安全性の主張と実際の挙動の不一致が明らかに

#### インフラストラクチャとアプリケーションのコード
* インフラストラクチャ製品に問題がなくても、アプリケーションのコードが正しく利用する必要
* 設定が理解しにくい場合（弱い分離レベルやクオラムの構成など）、間違いが生じやすい

#### データ破損への対応
* データが壊れたり失われたりしても耐えられるアプリケーションなら、単純に祈るだけで済むかもしれない
* 強い正確性の保証が必要な場合、直列化可能性とアトミックなコミットが定評のあるアプローチ
* これらはコストが伴い、単一のデータセンター内でしか利用できない

#### トランザクションの限界
* トランザクションのアプローチは重要だが、アプリケーションを正しく動作させるための唯一の手段ではない

#### 提案する方法
* データフローアーキテクチャの文脈で正確性について考えるいくつかの方法を提唱

### データベースのエンドツーエンド論

#### 強い安全性とデータの損失・破壊
* 強い安全性を提供するデータシステム（例：直列化可能なトランザクション）を使用しても、データの損失や破壊が完全に防げるわけではない
* アプリケーションにバグがあれば、正しくないデータの書き込みやデータベースからのデータ削除が発生する可能性がある
* 直列化可能なトランザクションではこうした問題は防げない

#### アプリケーションのバグと人間のミス
* アプリケーションには必ずバグが存在し、人間はミスをするもの
* イミュータブルで追記だけのデータは、問題のあるコードによるデータ破壊の可能性を減らし、回復を容易にする

#### イミュータビリティの限界
* イミュータビリティは有益だが、すべての問題を解決するわけではない
* より繊細なデータ破壊の例を考慮する必要がある

### 操作を厳密に一度だけ実行する

#### 概念とリスク
* **exactly-once（厳密に一度だけ）セマンティクス**:
  * 障害が発生した場合、メッセージ処理を諦めるか再処理する
  * 再処理すると、最初の処理が成功していた場合でも二重処理のリスクがある
  * 二重処理の例:
    * 顧客への二重課金（過剰請求）
    * カウンタの二重インクリメント（メトリクスの過大計上）

#### 目標
* **effectively-once（事実上一度だけ）セマンティクス**:
  * 処理が障害でリトライされても、最終的な効果は障害がなかった場合と同じにする

#### アプローチ
* **冪等性の保証**:
  * 操作が一度でも複数回でも同じ効果を持つようにする
  * 冪等でない操作を冪等にするための手間と注意が必要

#### 実装方法
* **メタデータの管理**:
  * 値を更新した操作IDの集合など
* **フェイルオーバー時のフェンシング**:
  * ノード間でのフェンシングの保証（「8.4.1.1リーダーとロック」）

### 重複の抑制

#### 重複の発生場面
* **ストリーム処理以外の例**:
  * TCPではパケットにシーケンス番号を付け、重複パケットを削除
  * 例12-1: TCP接続でのトランザクションの実行

#### データベーストランザクションの問題
* **クライアントとデータベースの接続**:
  * クライアントからの複数のクエリが同じトランザクションに属することをTCP接続で判断
  * ネットワーク中断後、COMMITのレスポンスを受け取れなければ、クライアントはトランザクションの成功を確認できない

#### 非冪等性の例
* **例12-1: 冪等性を持たない金銭転送トランザクション**:
  ```sql
  BEGIN TRANSACTION;
  UPDATE accounts SET balance=balance+11.00 WHERE account_id=1234;
  UPDATE accounts SET balance=balance-11.00 WHERE account_id=4321;
  COMMIT;
  ```
  * 再試行時、意図した11ドルではなく22ドルが送金される可能性

#### 2相コミットとTCP
* **2相コミット（2PC）**:
  * トランザクションコーディネータがネットワーク障害後に再接続し、トランザクションをコミットまたは中断

#### エンドユーザーとの通信
* **エンドユーザーからアプリケーションサーバーへの通信**:
  * HTTP POSTリクエストのリトライ問題
  * 弱いセルラーデータ接続でのタイムアウト
  * ユーザーの手動リトライによる独立したリクエストとして扱われる

#### Webブラウザのリトライ
* **フォーム再送信の警告**:
  * 「このフォームを本当に再送信しますか？」の警告
  * ユーザーが「はい」と答えると独立したリクエストとして扱われ、重複が発生

#### 重複抑制の重要性
* **トランザクションの重複抑制の必要性**:
  * データベースクライアントとサーバー間だけでなく、エンドユーザーデバイスとの間でも重複抑制が重要

### 操作識別子

#### エンドツーエンドの冪等性の確保
* データベースのトランザクションだけに依存せず、リクエスト全体のフローを考慮
* 操作に対してユニークな識別子（UUIDなど）を生成
  * クライアントアプリケーション内の隠しフィールドとして含める
  * 関連するフォームフィールドからハッシュを計算して操作IDを導出

#### 操作IDの利用
* WebブラウザがPOSTリクエストを2回送信した場合、2つのリクエストは同じ操作IDを持つ
* この操作IDをデータベースに至るまでの全過程で渡す
* 操作IDを一度だけ実行しているかチェックすることで、重複リクエストを抑制

#### 例12-2 ユニークなIDを利用した重複リクエストの抑制
```sql
ALTER TABLE requests ADD UNIQUE (request_id);

BEGIN TRANSACTION;

INSERT INTO requests (request_id, from_account, to_account, amount)
VALUES ('0286FDB8-D7E1-423F-B40B-792B3608036C', 4321, 1234, 11.00);

UPDATE accounts SET balance = balance + 11.00 WHERE account_id = 1234;
UPDATE accounts SET balance = balance - 11.00 WHERE account_id = 4321;

COMMIT;
```

* **ユニーク制約**:
  * `request_id` 列のユニーク制約に依存
  * 既存のIDを挿入しようとするとINSERTが失敗し、トランザクションが中断される
  * これにより、重複した操作の影響が2回生じるのを防止

* **イベントログとしてのrequestsテーブル**:
  * requestsテーブルはイベントログのように機能
  * イベントソーシングの方向性を示唆（「11.2.3イベントソーシング」参照）

* **口座残高の更新**:
  * イベントの挿入と同じトランザクション内で行う必要はない
  * 下流のコンシューマ側でリクエストイベントから導出可能
  * イベントが厳密に一度だけ処理される場合、リクエストIDを使って強制される場合に限る

### エンドツーエンド論

#### エンドツーエンド原理の概要
* 提唱者: Saltzer、Reed、Clark（1984年）
* 問題の機能を完全かつ正しく実装するには、通信システムの両エンドポイントにあるアプリケーションの知識と支援が必要
* 通信システム自身でその機能を完全に提供することは不可能
* 通信システムが不完全なバージョンを提供することはパフォーマンス向上に有益

#### 重複トランザクションの抑制
* 問題の機能の例: 重複の抑制
* TCPがパケットを重複抑制、ストリームプロセッサがexactly-onceセマンティクスを提供
* しかし、ユーザーが重複するリクエストを投入するのを完全には防げない
* 解決策: エンドユーザーのクライアントからデータベースに至るまでのトランザクション識別子（ID）

#### データの整合性チェック
* Ethernet、TCP、TLSに組み込まれたチェックサムはネットワーク内のパケット破損を検出
* 送信側や受信側ソフトウェア内のバグ、ディスク上の破損は検出できない
* エンドツーエンドのチェックサムが必要

#### 暗号化
* 自宅のWiFiネットワークのパスワード: WiFiトラフィックのスヌープ対策
* クライアントとサーバー間のTLS/SSL: ネットワーク攻撃者対策
* エンドツーエンドの暗号化と認証が必要

#### 低レベル機能の役割
* TCPの重複抑制、Ethernetのチェックサム、WiFiの暗号化は高レベルの問題の可能性を引き下げる
* 低レベルの信頼性機能だけではエンドツーエンドの正確性を保証できない
    * 例: HTTPのリクエストはTCPがパケットを適切な順序に戻さなければめちゃくちゃになる

### データシステムへのエンドツーエンドの考え方の適用

#### データシステムとエンドツーエンドの安全性
* 強い安全性を提供するデータシステム（例：直列化可能なトランザクション）を使っても、アプリケーションのデータ損失や破損を完全には防げない
* アプリケーション自体がエンドツーエンドで重複抑制などの処置を行う必要がある

#### 耐障害性の課題
* 耐障害性の仕組みを正しく動作させるのは難しい
* 低レベルの信頼性メカニズム（例：TCP）は非常にうまく動作する
* 高レベルのフォールト耐性を抽象化して、アプリケーションコードから心配を取り除くことが理想的

#### トランザクションの役割と限界
* トランザクションは長きにわたって優れた抽象化と見なされてきた
* トランザクションは多くの問題（並行書き込み、整合性違反、クラッシュ、ネットワークの中断、ディスクの障害）をコミットまたは中断にまとめる
* トランザクションはプログラミングモデルを単純化するが、負荷が大きくヘテロなストレージ技術が関わる場合に十分でない

#### 分散トランザクションの現実
* 負荷が大きすぎるため、分散トランザクションを利用しない場合もある
* 耐障害性の仕組みをアプリケーションのコード内で再実装する必要が生じる
* 並行性や部分的な障害について十分に考慮するのは難しく、直感に一致しないことが多い
* アプリケーションレベルの仕組みが正しく動作しない結果としてデータの損失や破損が起こる

#### 探求すべき耐障害性の抽象化
* アプリケーション固有のエンドツーエンドの正確性を容易に提供する
* 優れたパフォーマンスや運用上の良い特徴を保つ
* このような耐障害性の抽象化は探究する価値がある

### 制約の強制

#### ユニーク制約の適用
* ユニーク制約はデータベースの解体の文脈で重要
* クライアントからデータベースまでの過程でリクエストIDを渡すことでエンドツーエンドの重複抑制が実現可能

#### ユニーク性の強制例
* ユーザー名やメールアドレスはユニークである必要がある
* ファイルストレージサービスでは同じ名前のファイルが複数存在してはいけない
* 飛行機や劇場の席は同時に2人が予約できないようにする

#### その他の制約例
* 口座の残高がマイナスにならない
* 倉庫の在庫以上の商品を販売しない
* 会議室の予約が重複しないようにする

#### 制約の強制方法
* ユニーク性を強制する手法は、上記のような制約にも適用可能

### ユニーク制約には合意が必要

#### 合意の必要性
* 分散システムではユニーク制約を強制するために合意が必要
* 複数のリクエストが並行して同じ値を持つ場合、システムは受け入れるリクエストを決定し、その他を拒否する必要がある

#### リーダーによる判断
* 最も一般的な方法は、1つのノードをリーダーとし、すべての判断を任せること
* すべてのリクエストが1つのノードに集中する
* リーダーに障害が発生しない限り、この方法はうまく機能する

#### 障害耐性と再合意
* リーダーの障害に耐えるためには、再び合意の問題に戻る必要がある
* シングルリーダーレプリケーションと合意の問題に関連する（9.4.3.2参照）

#### パーティショニングによるスケーリング
* ユニーク性のチェックは、値をパーティションに分けることでスケールさせることが可能
* 例12-2では、リクエストIDによるユニーク性を保証するために同じリクエストIDを持つすべてのリクエストを同じパーティションに回す
* ユーザー名のユニーク性を保証するためには、ユーザー名のハッシュでパーティショニングを行う

#### 非同期のマルチマスターレプリケーションの問題
* 非同期のマルチマスターレプリケーションでは、複数のマスターが並行して競合する書き込みを受け付けるため、ユニーク性が保証されないことがある（9.2.3参照）
* 制約違反になる書き込みをすべて即座に拒否するには、同期による調整が必要

#### まとめ
* 分散システムにおけるユニーク制約の強制には、リーダーによる判断やパーティショニングによるスケーリングが有効
* 非同期のマルチマスターレプリケーションではユニーク性が保証されないため、同期による調整が必要

### ログベースのメッセージングにおけるユニーク性

#### ログの保証
* すべてのコンシューマが同じ順序でメッセージを見ることを保証
* この保証は全順序ブロードキャストと呼ばれ、合意と等価（「9.3.3 全順序のブロードキャスト」参照）

#### ユニーク制約の強制
* ログベースのメッセージングを用いる解体されたデータベースのアプローチでは、ユニーク制約を強制するために同様のアプローチを利用
* ストリームプロセッサは、1つのログパーティション内のすべてのメッセージをシングルスレッドでシーケンシャルに消費（「11.1.2.2 従来のメッセージングとログの比較」参照）

#### ユーザー名の例
* 複数のユーザーが同じユーザー名を要求する場合、リクエストはメッセージとしてエンコードされ、ユーザー名のハッシュで決まるパーティションに追記
* ストリームプロセッサは、ログのリクエストをシーケンシャルに読み取り、ローカルのデータベースを使って使用済みのユーザー名を追跡
  * 利用可能なユーザー名に対するリクエストの場合、名前が取られたことを記録し、成功のメッセージを出力ストリームに送出
  * すでに取られているユーザー名に対するリクエストの場合、拒否のメッセージを出力ストリームに送出
* ユーザー名を要求したクライアントは出力ストリームを監視し、自身のリクエストに対する成功もしくは拒否のメッセージを待つ

#### アルゴリズムの特長
* 各パーティションが独立して処理を行えるため、パーティション数を増やすことでスケーラビリティが向上
* ユニーク性の制約だけでなく、他の種類の制約でも有効
* 基本原則は、衝突する可能性がある書き込みは同じパーティションに送られ、シーケンシャルに処理されること

#### その他の考慮事項
* 衝突の定義はアプリケーションに依存する場合がある（「5.3.2.5衝突とは何か？」及び「7.2.4 書き込みスキューとファントム」参照）
* ストリームプロセッサはリクエストを検証する際に任意のロジックを利用可能
* このアイデアは、Bayouが1990年代に開拓したアプローチに似ている

### マルチパーティションのリクエスト処理

#### 複数のパーティションに関係する処理
* 例12-2では、リクエストID、受取人アカウント、支払者アカウントの3つのパーティションが考えられる
* 旧来のデータベースアプローチでは、これらパーティション間のアトミックコミットが必要で全順序を強制

#### パーティショニングされたログのアプローチ
* アトミックコミットなしで正確性を達成可能
* 送金リクエストにはユニークなリクエストIDを付与し、ログのパーティションに追記
* ストリームプロセッサは、リクエストログを読み取り、出金指示と入金指示の2つのメッセージを出力ストリームに送出
* メッセージにはオリジナルのリクエストIDを含め、重複排除を行う

#### 分散トランザクションの回避
* クライアントが直接出金と入金の指示を送信すると、アトミックコミットが必要
* ログにリクエストメッセージを記録し、そこから出金と入金のメッセージを導出
* 単一オブジェクトへの書き込みはアトミックであり、ログへのリクエスト記録でアトミックコミット不要

#### フォールトトレランスと重複排除
* ストリームプロセッサがクラッシュした場合、最後のチェックポイントから処理を再開
* 同じメッセージを複数回処理しても、重複排除が可能

#### 借り越し防止の追加プロセッサ
* 残高を管理し、トランザクションを検証するストリームプロセッサを追加（支払者のアカウント番号でパーティショニング）
* 正当なトランザクションのみがリクエストログに記録される

#### エンドツーエンドの正確性
* パーティショニングの方法が異なる複数のステージを利用し、エンドツーエンドのリクエストIDを用いる
* フォールトがある場合でも、アトミックコミットプロトコルなしで正確性を達成
* 「12.2.3.6 複数パーティションにわたるデータの処理」及び「11.2.4.3 並行性の制御」で論じた方法に似ている

### 適時性と整合性

#### トランザクションと線形化可能性
* トランザクションは通常、線形化可能である
* コミット後、書き込みはすべてのリーダーから即座に見える
* 複数ステージのストリームプロセッサではこの性質が当てはまらない

#### 非同期設計とメッセージ処理
* ログのコンシューマは非同期で、送信側はメッセージ処理を待たない
* クライアントが出力ストリームのメッセージを待つことで、ユニーク制約のチェックを同期的に行える

#### 一貫性の2つの要求
1. **適時性（timeliness）**
   * ユーザーが最新の状態のシステムを観察できることを保証
   * 非一貫性は一時的で、待つことで解決する
   * CAP定理での「一貫性」は適時性の制約を強くしたもの

2. **整合性（integrity）**
   * データの損失や矛盾がないこと
   * 非一貫性は恒久的で、待っても解決しない
   * ACIDトランザクションでは、整合性はアプリケーション固有の表現

#### 適時性と整合性の比較
* 適時性違反は一時的であるが、整合性違反は致命的
* 適時性違反は「結果整合性」、整合性違反は「恒久的な非一貫性」
* ほとんどのアプリケーションでは整合性が適時性より重要

#### 適時性と整合性の例
* クレジットカード明細における適時性違反は許容されるが、整合性違反は致命的
* 適時性違反：過去24時間以内の取引が表示されない
* 整合性違反：明細の残高が取引の合計と一致しない、業者への支払いがされない

### データフローシステムの正確性

#### ACIDトランザクションと正確性
* ACIDトランザクションは適時性（線形化可能性）と整合性（アトミックなコミット）を保証
* 適時性と整合性の違いはACIDトランザクションの観点ではほとんど重要ではない

#### イベントベースのデータフローシステム
* 適時性と整合性を分離する
* イベントストリームを非同期で処理する場合、適時性は保証されない
* ストリーミングシステムの中核は整合性

#### 整合性の維持
* exactly-onceあるいはeffectively-onceセマンティクスは整合性を保つための仕組み
* イベントのロストや重複は整合性を破綻させる可能性がある
* 耐障害性のあるメッセージ配信と重複抑制（冪等な操作）が重要

#### 分散トランザクションなしでの整合性
* 信頼性のあるストリーム処理システムは分散トランザクションやアトミックなコミットプロトコルを必要としない
* 同等の正確性を持ちながら高いパフォーマンスと運用上の頑健性を実現可能

#### 整合性の達成方法
1. **書き込み操作の内容を単一のメッセージとして表現**
   * アトミックな書き込みが容易
   * イベントソーシングと相性が良い

2. **決定的な導出関数の利用**
   * 単一のメッセージからすべての他の状態の更新を導出
   * ストアドプロシージャに似ている

3. **リクエストIDの通過**
   * クライアントが生成したリクエストIDを処理のすべてのレベルで渡す
   * エンドツーエンドの重複抑制や冪等性の実現

4. **イミュータブルなメッセージ**
   * メッセージをイミュータブルにし、導出データを後から再処理可能にする
   * バグからの回復が容易になる

#### 期待される方向性
* これらの仕組みの組み合わせは、耐障害性を持つアプリケーションの構築において将来的に非常に有望

### 制約の緩やかな解釈

#### ユニーク制約の強制と合意
* ユニーク制約の強制には合意が必要
* これは通常、単一ノードにイベントを通すことで実現
* ストリーム処理でもこの制約は回避できない

#### 現実のアプリケーションにおける緩やかなユニーク性
* 多くの現実のアプリケーションでは、弱いユニーク性で問題なし
* 同じユーザー名や席を登録しようとする場合、謝罪して別の選択を求める補正トランザクションが有効
* 在庫数以上に注文があれば発送の遅れを謝罪して対応
* 補正トランザクションは、ビジネスの一部として必要

#### オーバーブッキングの例
* 航空会社やホテルはオーバーブッキングを行う
* 需要が供給を上回る場合、補償プロセスが必要（返金、アップグレードなど）
* 悪天候やストライキでのキャンセルにも謝罪と補償プロセスが必要

#### 金融業界の例
* 残高以上の引き出しに対して、銀行は当座貸越費を課し、返済を求める
* 一日に引き出せる金額の上限を設け、リスクを制限

#### 許容される制約違反
* 一時的な制約違反とその後の謝罪は多くのビジネスで受け入れられる
* 訂正のフォローアップメールや、二重課金の返金が可能
* ATMの過払いも負債の回収で対応可能
* 謝罪のコストが許容範囲なら、従来の厳しい制約チェックは不要

#### 楽観的な処理のすすめ
* 楽観的に書き込みを進め、その後で制約チェックを行うアプローチ
* 回復の負担が大きくなりうることを事前に検証するが、書き込み前に行う必要はない
* 重要なのは整合性であり、適時性は必須ではない
* 生じた問題は後から謝罪して埋め合わせることで対応可能

#### 衝突解決のアプローチ
* 倉庫にある以上の商品を販売しても後から謝罪して対応
* これは「5.3.2書き込みの衝突の処理」で論じた方法に似ている

### 調整を回避するデータシステム

#### 所見
* データフローシステムは、アトミックなコミット、線形化可能性、パーティションをまたぐ同期的な調整なしに整合性を管理できる
* 多くのアプリケーションでは、一時的な違反が生じても後から修復する緩い制約で問題ない
* データフローシステムは調整を必要とせず、強い整合性の保証を提供しながらデータ管理サービスを実現できる

#### 調整回避データシステムの魅力
* 高いパフォーマンスと耐障害性を実現可能
* マルチリーダー構成で複数のデータセンターにまたがり、非同期にレプリケーションをしながら分散運用が可能
* 任意のデータセンターは他から独立して運用を継続できる
* 線形化可能性は保証しないが、強い整合性は保証可能

#### トランザクションの利用
* 直列化可能なトランザクションは、導出された状態の管理機能として有益
* 小さなスコープでうまく動作する場合に限り利用
* XAトランザクションのようなヘテロな分散トランザクションは必要ではない
* 同期的な調整は必要な場所に限定して導入

#### 調整と制約の効果
* 非一貫性による謝罪の数を減らすが、システムのパフォーマンスと可用性を引き下げる可能性がある
* サービスの中断による謝罪の数が増えるかもしれない
* 謝罪の数をゼロにすることはできないが、最善のトレードオフを見つけることが目指すべき目標
* 非一貫性や可用性の問題が少ないスイートスポットを探る

### 信頼しつつも検証を

#### システムモデルと仮定
* 本書の議論は、特定の問題が起こる可能性を仮定している
  * 例: プロセスのクラッシュ、電源の喪失、メッセージの遅延や消失
* 同時に仮定されること
  * fsync後にディスクに書かれたデータは失われない
  * メモリ中のデータは破損しない
  * CPUの乗算命令は常に正しい答えを返す

#### 二者択一のアプローチ
* システムモデルは従来、フォールトに対して二者択一のアプローチを取ってきた
  * あることは起こり、他のことは決して起こらないという仮定
* 現実には確率的な問題
  * あることは起こりそうで、他のことは起こりそうにない

#### 発生頻度と注意
* 仮定に反することが現実にどれほど高頻度で起こるかが問題
* ディスクやネットワーク上のデータ破損事例
  * データが操作されていない状態でも壊れる場合がある
  * TCPのチェックサムをすり抜けるデータの破損

#### ランダムなビット反転とフォールト
* クライアントデバイスでのランダムなメモリのビット反転
  * クラッシュレポートから判明
* 異常なメモリアクセスパターンによるビット反転
  * ハードウェアのフォールトなしでも発生
  * セキュリティの仕組みを破るために使用される例も（rowhammer）

### ソフトウェアのバグがあっても整合性を保つ

* **ソフトウェアのバグのリスク**
  * ハードウェアの問題以外にもソフトウェアのバグは常に存在
  * 低レベルのネットワーク、メモリ、ファイルシステムのチェックサムでは捕捉できない

* **データベースソフトのバグ例**
  * MySQLがユニーク制約の管理に失敗することがある
  * PostgreSQLのserializable分離レベルで書き込みスキューの異常が発生
  * 頑健で評価の高いMySQLやPostgreSQLでもバグが存在

* **設計とテストの重要性**
  * 注意深い設計、テスト、レビューに労力を費やしてもバグは入り込む
  * バグが見つかり修正されるまでの期間はデータを壊す可能性がある

* **アプリケーションコードのリスク**
  * データベースのコードに比べてレビューやテストが少ないため、バグが多い
  * 多くのアプリケーションは外部キーやユニーク制約を正しく使っていない

* **ACIDの一貫性**
  * データベースが一貫した状態から立ち上がり、トランザクションが一貫した状態に変換することを前提
  * この主張が理にかなうのは、トランザクションにバグがないと仮定した場合のみ
  * 弱い分離レベルを安全ではない方法で使用すると整合性が保証されない

### 約束を単純に盲信してはならない

* **データ破損の不可避性**
  * ハードウェアもソフトウェアも理想通りには動かない
  * 遅かれ早かれデータの破損が生じる可能性がある

* **データ整合性の確認と修復**
  * データが壊れていないか確認する方法が必要
  * 壊れていた場合の修復方法も備えるべき
  * データ整合性チェックは監査（auditing）と呼ばれる

* **金融アプリケーションと監査**
  * 金融分野では監査が特に重要
  * 間違いが起こる前提で問題を検出・修正する必要性が認識されている

* **成熟したシステムのアプローチ**
  * HDFSやAmazon S3のような大規模ストレージシステムもディスクを全面的に信用しない
  * 継続的にファイルを読み直し、他のレプリカと比較するプロセスを動作させている
  * データ破損リスクを緩和するためのバックグラウンドプロセスを持つ

* **データの存在確認**
  * データが依然として存在することを確認するためには、実際にデータを読み取り、チェックする必要がある
  * データ破損を早期に発見するために継続的なチェックが重要

* **バックアップの重要性**
  * 定期的にバックアップからのリストアを試みることが重要
  * バックアップが破損していることに気付かないままでは、データを失うリスクがある

* **盲目的な信頼の危険性**
  * すべてがうまく動作していると盲信してはいけない
  * 定期的なチェックと検証が必要

### 検証の文化

* **信じつつも検証するアプローチ**
  * HDFSやS3のようなシステムは、ディスクが正しく動作すると仮定しつつも、継続的に自身を監査する
  * 多くのシステムは、正確性の保証が絶対であると仮定し、データ破損の可能性を無視

* **自己検証や自己監査の重要性**
  * 盲目的な信頼に頼るよりも、継続的に整合性をチェックするシステムが増えることが望ましい
  * ACIDデータベース文化が、技術を盲目的に信頼し監査性を軽視する傾向を生んだ可能性

* **変化するデータベースの風景**
  * NoSQLの普及に伴い、弱い一貫性の保証や成熟度の低いストレージ技術が広がる
  * 監査の仕組みを取り入れずに盲目的な信頼の上にアプリケーションを構築する危険性が増加

* **監査性の設計の必要性**
  * 監査性を考慮した設計が求められる
  * システムの自己検証と自己監査の文化を育てることが重要

### 監査性のための設計

* **トランザクションの複雑性**
  * トランザクションが複数のオブジェクトを変更すると、その意味を後から説明するのは難しい
  * トランザクションログをキャプチャしても、変更の理由が必ずしも明確にはならない

* **イベントベースシステムの利点**
  * イベントソーシングは、システムへの入力を単一のイミュータブルなイベントとして表現する
  * 結果として生じた状態の更新は、そのイベントから決定的かつ再現可能に導出される
  * 同じイベントログを同じコードで再実行すれば、同じ状態更新が行われる

* **データの系統と整合性のチェック**
  * データフローを明確化すれば、データの系統（provenance）も明確になり、整合性チェックが容易に
  * イベントログのハッシュを使って、イベントのストレージが破損していないかをチェック可能
  * バッチやストリームプロセッサを再実行して、イベントログから状態を再導出し、結果の一致を確認
  * 冗長な導出を並行して行うことも可能

* **デバッグとトレース**
  * データフローが決定的かつ十分に定義されていれば、実行のデバッグやトレースが容易に
  * 予想外の出来事が起きたとき、その環境を正確に再現できる診断機能が役立つ
  * これは一種のタイムトラベルデバッグ機能といえる

### エンドツーエンド論

* **ハードウェアとソフトウェアのリスク**
  * ハードウェア部品には障害が発生する可能性があり、ソフトウェア部品にはバグが存在する可能性がある
  * システムの個々のコンポーネントが破損しないと全面的に信用することはできない

* **データ整合性の重要性**
  * データの整合性は定期的にチェックしなければならない
  * 整合性チェックを行わないと、破損が下流のどこかでダメージを引き起こすまで気づかない
  * 問題が明らかになる時点では、修復が難しく手間がかかる

* **エンドツーエンドの整合性チェック**
  * 整合性チェックはエンドツーエンドで行うのが最善
  * 整合性チェックが組み込まれたシステムが増えると、破損が気づかれないままになる可能性が減る
  * 導出データパイプラインがエンドツーエンドで正しいことをチェックすることで、ディスク、ネットワーク、サービス、アルゴリズムも含まれる

* **連続的なエンドツーエンドの整合性チェック**
  * システムの正確性に対する自信が増し、開発を早めることができる
  * 監査によってバグを早期に発見し、システムへの変更や新しいストレージ技術によるリスクを減らせる
  * 変更を恐れなくなり、変化する要求にあわせてアプリケーションを進化させやすくなる

### 監査可能なデータシステムのためのツール

* **現状の監査性**
  * 多くのシステムでは監査性がトップレベルの関心事項とはなっていない
  * アプリケーション独自に監査の仕組みを実装する場合もあるが、監査ログとデータベースの整合性保証は難しい

* **暗号化による監査**
  * ハードウェアのセキュリティモジュールを用いてトランザクションログの改竄を防止する方法があるが、正しいトランザクションの保証は難しい
  * 幅広いハードウェアやソフトウェアの問題、悪意ある行動に対して耐性を持つ方法でシステムの整合性を証明する技術が求められる

* **暗号通貨と分散台帳技術**
  * Bitcoin、Ethereum、Ripple、Stellarなどの暗号通貨やブロックチェーン技術が登場している
  * これらは分散データシステムであり、データモデルやトランザクションの仕組みがある
  * 信頼し合わない組織によってホストされるレプリカ群が、整合性をチェックし合い、合意プロトコルを使ってトランザクションについて同意する

* **技術的懐疑**
  * ビザンチン障害耐性には懐疑的
  * 作業検証（Proof of Work）の手法は無駄が多い
  * ビットコインのトランザクションスループットは低い

* **暗号による監査と整合性チェック**
  * Merkle Treesに依存することが多い
  * Merkle Treesはハッシュツリーであり、データセットにレコードが含まれるかを効率的に確認するために使われる

* **証明の透過性**
  * TLS/SSL証明書の正当性をチェックするためにMerkle Treesが使われている
  * 証明の透過性や分散台帳のアルゴリズムが、データシステムに広く使われるようになる可能性がある

* **将来の展望**
  * これらのシステムをスケーラブルにし、パフォーマンスのペナルティを最小限にするためにはさらなる研究が必要
  * この領域は将来にわたって注目すべき興味深い領域と考えられる

## 正しいことを行う

* **システムの目的**
  * すべてのシステムは特定の目的のために構築される
  * 目的がシンプルであっても、システムの結果は予期しない広範な影響を及ぼす可能性がある

* **エンジニアの責任**
  * システムの影響について慎重に考える必要がある
  * どのような世界を作りたいかを意識的に判断する責任がある

* **データの扱い**
  * 多くのデータは人に関するものであり、尊敬を持って扱う必要がある
  * ユーザーの尊厳を最優先にする

* **倫理的な選択**
  * ソフトウェア開発には重要な倫理的な選択が含まれる
  * ACMのSoftware Engineering Code of EthicsやProfessional Practiceがガイドラインとして存在するが、実際にはあまり議論・適用されていない

* **プライバシーと影響**
  * エンジニアやプロダクトマネージャーがプライバシーや製品の影響について軽視することがある

* **技術の中立性**
  * 技術そのものは良いものでも悪いものでもない
  * 重要なのはその技術がどのように使われ、人々にどのような影響を与えるか

* **倫理的な責任**
  * 技術の影響を無視することは適切ではない
  * エンジニアには倫理的な責任がある
  * 倫理について深く考えることは難しいが、重要な課題である

### 予測分析

* **予測分析の役割**
  * ビッグデータブームの一部
  * 天気や疾病の広がり、受刑者の再犯、ローンの不履行、保険の高額要求などの予測

* **影響とリスク**
  * 予測分析は個々人の生活に直接的な影響を与える
  * 不正トランザクションの防止、ローンの回避、ハイジャックの防止、信用に値しない従業員の雇用回避など

* **ビジネスの観点**
  * 機会損失のコストは小さい
  * 悪質なローンや問題のある従業員のコストは高いため、組織は注意を払う
  * 疑わしい場合は拒否する方が良いとされる

* **アルゴリズムの影響**
  * アルゴリズムによる意思決定の広がり
  * リスクがあるとラベル付けされた人物が大量の「ノー」という拒否を受ける
  * 雇用、空の旅、保険、借家、金融サービスなどからの排除
  * 「アルゴリズムによる監獄」と呼ばれる個人の自由の大きな制限

* **推定無罪の原則との対比**
  * 有罪確定までは推定無罪の原則が適用される
  * 自動化されたシステムは反訴の機会を与えずに人を疎外する

### バイアス（偏見）と差別

* **アルゴリズムの判断の質**
  * 人間の判断と比べて必ずしも良いわけでも悪いわけでもない
  * 人間はバイアスを持ちやすく、差別的な行いは文化的に慣習化することがある
  * データに基づく判断が旧来のシステムよりも公平であることへの期待

* **予測分析システムの開発**
  * ソフトウェアで人間の判断を自動化
  * ルールそのものもデータから推測
  * 学習したパターンが不透明で理由が分からない場合もある

* **システマチックなバイアス**
  * 入力データにバイアスがあれば、システムもそのバイアスを学習し増幅する

* **反差別法とアルゴリズム**
  * 多くの国では民族、年齢、性別などに基づく差別が禁じられている
  * これら保護特性と相関する特徴がある場合の問題
  * 例：人種によって分断された地域の郵便番号やIPアドレスが人種の推定材料になる

* **機械学習のバイアス**
  * バイアスのかかったデータからフェアな出力を期待するのは困難
  * 「機械学習はバイアスをマネーロンダリングしている」との批判

* **未来をより良くするための道徳的想像力**
  * 過去の差別を体系化する危険
  * 未来を過去より良くするためには人間の道徳的想像力が必要
  * データとモデルは道具であり、主人であってはならない

### 責任と説明責任

* **自動化された判断と説明責任**
  * 人間がミスを犯した場合は説明責任を負うが、アルゴリズムがミスをした場合の責任は不明確
  * 自動運転の事故や信用スコアの差別的な判断の責任は誰が負うのか？
  * 司法審査の際にアルゴリズムの判断を説明できるか？

* **信用スコアと機械学習のスコアリング**
  * 信用スコアは個人の借り入れ履歴に基づくが、機械学習のスコアリングは幅広い入力を受け付け、不透明
  * 特定の判断が下された理由や不公平な扱いを受けた理由を理解するのが難しい

* **予測分析のアプローチ**
  * 信用スコアは「過去の振る舞い」に基づくが、予測分析は「似た人の過去の振る舞い」に基づく
  * 住んでいる場所などのステレオタイプに基づく判断が行われる可能性
  * 間違った分類に入った場合の救済はほぼ不可能

* **統計的データと個別の間違い**
  * データは統計的であり、全体の確率分布は正しくても個々のケースでの間違いはあり得る
  * 予測システムの出力は確率的なものであり、個々のケースでは間違いが生じる可能性

* **データの優位性を盲信する危険**
  * データに基づく意思決定の広がりに対し、アルゴリズムを説明可能で透明性のあるものにする方法を見つける必要
  * バイアスの強化を避け、データに基づく意思決定の間違いを修復する方法を見つける

* **データの良い方向の可能性**
  * 分析によって人々の経済的、社会的な特徴を明らかにし、支援を必要とする人々に焦点を当てる
  * 搾取的な企業によって弱い立場の人々がターゲットにされるリスク

### フィードバックループ

* **予測アプリケーションの影響**
  * レコメンデーションシステムはユーザーに影響を及ぼす
  * ユーザーの好みに基づいたコンテンツ表示はエコーチェンバーを生む
  * 選挙運動でのソーシャルメディアのエコーチェンバー効果を目撃

* **自己強化フィードバックループの問題**
  * 予測分析が人々の生活に影響を及ぼす場合に発生
  * 採用候補者の評価に信用スコアを使う雇用者の例
    * 経済的な不幸により信用スコアが悪化
    * 信用スコアの悪化が仕事の獲得を困難にし、貧困状態に陥る
    * 貧困がさらなる信用スコアの悪化を引き起こし、雇用がますます難しくなる
  * 有害な前提による下降スパイラル

* **フィードバックループの予測とシステム思考**
  * フィードバックループの発生は常に予測できるわけではない
  * システム全体を考慮することで予測できる場合がある
    * コンピュータ化された部分だけでなく、人々との関わりも含めて
  * システム思考（system thinking）のアプローチ
    * データ分析システムが人々の差異を強化するか、不当と戦うかを理解する
    * 最善の意図でも予想外の結果が生じることを認識

### プライバシーと追跡

* **データ収集の倫理的問題**
  * データ収集の方法とその影響
  * 明示的なデータ入力 vs. 副作用としてのアクティビティ追跡
  * ユーザーとシステムの関係性の不明確さ

* **ユーザーの行動追跡の重要性**
  * 検索結果のクリック追跡でランキング改善
  * レコメンデーションシステムの有効性
  * A/Bテストやユーザーフロー分析でUI改善
  * これらの機能はユーザーに利益をもたらす

* **ビジネスモデルの影響**
  * 広告収入モデルでは広告主が本当の顧客
  * ユーザーの利益が二の次になる可能性
  * 詳細なデータ追跡と長期保存の問題

* **企業とユーザーの関係の変化**
  * 無料サービスの提供と利用促進
  * 広告主の要求によるユーザー追跡
  * 監視としてのデータ収集の可能性

### 監視

* **監視の視点でデータ収集を再考**
  * データを監視という言葉に置き換えてみる
  * 例：「私たちの監視駆動型組織では、リアルタイムの監視ストリームを収集し、それを監視ウェアハウスに保存します」
  * この思考実験は、データ収集の本質を強調するために重要

* **大規模監視インフラストラクチャの構築**
  * Internet of Thingsの普及
  * スマートフォン、スマートTV、音声制御のアシスタントデバイスなど、あらゆる場所にインターネット接続されたマイクロフォン
  * デバイスのセキュリティの実績は不十分

* **自発的な監視社会の受け入れ**
  * 監視を受け入れる理由
    * 隠すべきことがないという感覚
    * 社会の周縁にいるマイノリティではないため、迫害を恐れない
  * 善なる目的に見えるための受け入れ
    * 優れたレコメンデーションやパーソナライズされたマーケティング

* **監視の現実的な影響**
  * 自動車保険のプレミア料金や健康保険の保証範囲に影響
  * 健康保険や雇用など重要な決定に監視が関与

* **データ分析の驚くべき詳細**
  * スマートウォッチやフィットネストラッカーの移動センサーがタイピング内容を判別
  * アルゴリズムの進化により、ますます詳細な分析が可能になる

### 承諾と選択の自由

* **ユーザーの承諾とサービス利用**
  * ユーザーはアクティビティ追跡サービスの利用を選択し、利用規約とプライバシーポリシーに同意している
  * データ提供の見返りに価値のあるサービスを受けているという見方もある
  * ソーシャルネットワークや検索エンジンなどの無料サービスはユーザーにとって価値がある

* **プライバシーポリシーの問題**
  * ユーザーはサービス側のデータベースに何が供給され、どう保存され処理されるかをほとんど知らない
  * プライバシーポリシーは理解しづらく、ユーザーは意味のある承諾ができない
  * ユーザーのデータが他の人々に関する情報も伝える場合がある

* **データの収集と非対称な関係**
  * データは一方的なプロセスでユーザーから収集され、対話や選択肢がない
  * ユーザーはデータ提供の対価を交渉することができない
  * 規約はサービス側によって設定され、ユーザーには選択の余地がない

* **サービス利用の必須性**
  * 監視されることを承諾しない唯一の選択肢はサービスを利用しないこと
  * 広く使われるサービスは基本的な社会参加に不可欠なものと見なされている
  * サービスを使わないことには社会的コストが伴い、現実的には利用が必須となる

* **選択の自由の欠如**
  * サービスのプライバシーポリシーを理解し、社会参加や職業的機会を失うことを許容できる少数の人だけがサービス利用を拒否できる
  * 多くの人々には意味のある選択の自由が存在せず、監視から逃れることができない

### プライバシーとデータの利用

* **プライバシーの誤解**
  * プライバシーを持つことは、すべてを秘密にすることではない
  * 何を誰に明らかにするか、何を秘密にするかを選択する自由を持つこと

* **データ収集とプライバシーの移管**
  * データが企業によって収集されると、プライバシーの権利が企業に移管される
  * 企業は「データを適切に扱う」という信頼に基づいてデータを使用
  * データ収集による結果の多くは秘密にされる

* **企業の目的とユーザーのプライバシー**
  * 企業はユーザーからの不気味だと思われないように努める
  * データ収集の侵入性に対する疑問を避け、ユーザーの認識を管理することに焦点を当てる
  * 企業はプライバシーポリシーに従ってデータを自由に利用

* **ユーザーのコントロールとその限界**
  * プライバシー設定でユーザーにある程度のコントロールを戻すことができる
  * サービスは依然としてデータに自由にアクセスし、内部的な処理と分析を行う

* **プライバシー権の大規模な移管**
  * 企業による大規模なプライバシー権の移管は歴史的に前例がない
  * 信頼関係がある従来の監視は厳密な制約があったが、インターネットサービスは大量のセンシティブな情報を収集
  * ユーザーが自分のデータの利用方法を理解することなく、大規模なデータ利用が容易に行われる

### 資産や権力としてのデータ

* **データの価値**
  * 行動データはサービス利用の副産物であり、「出がらしデータ」と呼ばれる
  * 経済的観点から見ると、ターゲット広告のための行動データはサービスの中核的資産
  * ユーザーの行動データはデータ抽出マシンによって搾取されている

* **データブローカーの存在**
  * データブローカーは侵入的なデータの秘匿、購入、集計、分析、推定、再販を行う
  * スタートアップの価値はユーザー数と監視能力によって計られる

* **データの需要**
  * 多くの企業や政府がデータを欲しがる
  * 企業破綻時には個人データが売却される資産となる

* **データの危険性**
  * データへの不正アクセスは頻繁に生じる
  * データは「毒性を持った資産」や「危険物」として批判される

* **データ収集のリスク**
  * データ収集にはメリットとリスクがある
  * データは犯罪者や諜報機関によって侵入されるリスクがある
  * 政府が変わることでデータが悪用される可能性がある

* **政治環境とデータの利用**
  * 未来の政府が人権や自由を尊重する保証はない
  * 技術の導入は将来の警察国家を助長するリスクがある

* **権力としてのデータ**
  * 「知は力なり」という格言の通り、データは強力な権力の源
  * 全体主義的な政府は監視を利用して人々をコントロールする
  * テクノロジー企業もデータによって大きな影響力を持ち、その力は公に知られていない

### 産業革命を忘れない

* **情報時代の特徴**
  * データ、インターネット、データストレージ、処理、ソフトウェアを中心とした自動化
  * グローバルな経済と人間社会に大きな影響を与えている

* **産業革命との比較**
  * 産業革命は技術的・農業的な進歩を通じて持続的な経済成長と生活基準の改善をもたらした
  * 同時に大気汚染、水質汚染、労働環境の悪化などの問題を招いた
  * 環境保護規制や労働法の確立には時間がかかった

* **規制の重要性**
  * 環境保護、労働者の権利保護、食品の安全などの規制により社会全体が利益を享受した
  * 規制のなかった時代に戻りたいとは誰も思わない

* **情報化時代の課題**
  * データの収集と利用が大きな問題となっている
  * Bruce Schneierの見解
    * データは情報化時代の公害問題であり、プライバシーの保護は環境の課題
    * データは常に存在し腐敗している
    * 情報経済の健全性のためにデータの対処、封じ込め、廃棄方法が重要

* **未来への責任**
  * 将来の世代が私たちのデータ収集と誤用の課題への取り組みを評価する
  * 彼らが誇りに思えるよう努力する必要がある

### 法律と自己規制

* **データ保護法の役割**
  * 1995年のEUデータ保護条例
    * 個人データの収集は明示的かつ合法的な目的の下で行われ、目的に適合しない方法で処理してはならない
    * データは収集された目的に関連し、適切かつ過剰であってはならない

* **現状の課題**
  * ビッグデータの哲学と対立
    * データ収集の最大化、他データセットとの組み合わせ、新しい知見の生成を目指す
  * データの新しい用途はユーザーの承諾を得た目的に反することが多い

* **規制とイノベーションのバランス**
  * 過剰な規制は医療データの共有や新たな治療法の発見などのブレークスルーを阻害する可能性がある

* **文化的変化の必要性**
  * ユーザーを最適化すべきメトリクスとしてではなく、尊重されるべき人間として扱う
  * データ収集と処理の実践を自己規制し、ユーザーからの信頼を維持する
  * エンドユーザーにデータ利用について教育し、自分のデータを管理できるようにする

* **プライバシーの保護**
  * 普遍的な監視を防ぐために、データを永久に保存せず不要になった時点で廃棄する
  * アクセス制御を強制する暗号化プロトコルの利用
  * 文化と考え方の変化が必要

## まとめ

本章ではデータシステム設計の新しいアプローチについて論じた。ここには筆者の個人的な意見や未来に関する推測も含まれてる。

#### データインテグレーションの問題

* 単一のツールではすべてのユースケースに対応できない
* アプリケーションは複数のソフトウェア部品を組み合わせる必要がある
* バッチ処理とイベントストリーミングを使ってデータ変更をシステム間で流す
* 記録のシステムから導出されたデータを管理
  * インデックス
  * マテリアライズドビュー
  * 機械学習のモデル
  * 統計サマリ

#### 非同期処理とシステムの頑健性

* 非同期かつ疎結合の処理でシステム全体の頑健性を高める
* データフローを変換として表現し、アプリケーションの進化を容易に
* 問題が発生した場合、修正コードを再実行して回復

#### データベースとコンポーネント

* データフローアプリケーションをデータベースの疎結合コンポーネントとして見直す
* 導出された状態は元データの変更を観察して更新
* エンドユーザーデバイスまでデータフローを拡張
  * 動的に更新されオフラインでも動作

#### 障害対応と整合性保証

* 非同期イベント処理とエンドツーエンドの操作識別子で冪等性を実現
* 非同期に制約をチェックし、強い整合性を保証
* クライアントは制約チェックの結果を待つか、先に進めるリスクを取る

#### 監査とデータの整合性

* 監査によるデータ整合性の検証と破損検出

#### 倫理的側面

* データ利用には倫理的な考慮が必要
* 差別や搾取、監視のリスクを理解
* 情報漏洩や予想外の結果に注意

#### エンジニアの責任

* 社会に対して思いやりと尊重を持つ
* 良い社会を目指して働く責任