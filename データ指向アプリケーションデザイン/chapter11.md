# 第11章：ストリーム処理

### バッチ処理の概要
* バッチ処理は、一連の入力ファイルを読み取り、新しい一連の出力ファイルを生成する手法
* 出力は導出データの一種で、再生成が可能
* 検索インデックス、レコメンデーションシステム、分析などに利用可能

#### バッチ処理の前提
* 入力は有限であり、サイズが既知で限られている
* 処理の完了を確認するためには、全ての入力を読み取り終える必要がある
* 例: MapReduceのソート処理は、全入力を読み終えてから出力を生成

#### 現実のデータの性質
* 多くのデータは時間の経過とともに徐々に生成され、有限ではない
* ユーザーは日々データを生成し続け、ビジネスが続く限りプロセスは終わらない
* データセットが「完成」することはない

#### バッチ処理の制約と対策
* データを固定期間ごとのチャンクに分割する必要がある
    * 例: 1日分のデータを日の終わりに処理、1時間分のデータを毎時間の終わりに処理
    * 問題点: 日次バッチ処理では、出力が1日遅れるため、多くのユーザーにとって遅すぎる

### ストリーム処理の考え方
* 処理をもっと頻繁に行う
    * 例: 毎秒のデータを毎秒の終わりに処理
* イベントが生じるたびに連続的に処理する方法
* ストリームは、時間の経過に伴って徐々に利用できるデータを指す

### ストリームの概念の応用
* Unixのstdinやstdout
* プログラミング言語の遅延リスト
* ファイルシステムAPI（例: JavaのFileInputStream）
* TCP接続
* インターネット経由での音声およびビデオ配信

### 本章の概要
* イベントストリームの表現、保存、ネットワーク経由での転送について論じる
* ストリームとデータベースの関係を調査（11.2データベースとストリーム）
* ストリームを連続的に処理するアプローチとツール、アプリケーションの構築方法（11.3ストリームの処理）

## 11.1 イベントストリームの転送

### ストリーム処理の入力と出力
* バッチ処理の入出力はファイル（分散ファイルシステム上のものも含む）
* ストリーム処理では入力をレコードにパースする
* レコードは一般にイベントと呼ばれる

#### イベントの特徴
* 小さく自己完結しているイミュータブルなオブジェクト
* ある時点で生じたことの詳細を含む
* 通常、発生時点を示すタイムスタンプを含む

#### イベントの例
* ユーザーアクション（ページ閲覧、商品購入など）
* マシンからの定期的な計測（温度センサー、CPU利用率など）
* Webサーバーログの各行がイベントに該当

#### イベントのエンコーディング
* テキスト文字列、JSON、バイナリ形式
* イベントの保存方法（ファイル追記、リレーショナルテーブル挿入、ドキュメントデータベース書き込み）
* ネットワーク経由で他のノードに送信

### ストリーム処理システムの構成
* イベントはプロデューサ（パブリッシャー、送信者）により生成
* イベントは複数のコンシューマ（サブスクライバ、受信者）により消費
* 関連するイベント群はトピックやストリームとしてグループ化

#### プロデューサとコンシューマの接続方法
* データストアにプロデューサがイベントを書き込み、コンシューマがポーリングを行う
* 例: 1日分のデータに対して1日の終わりにバッチ処理

#### ポーリングの問題点と解決策
* 高頻度のポーリングは負荷が高くなる
* リクエストに対する新しいイベントの返答率が低くなる
* 新しいイベントが現れた際に通知する方が効率的

#### データベースの通知機能の限界
* リレーショナルデータベースのトリガは限定的
* データベース設計において後付けの仕組み

#### イベント通知ツールの開発
* イベント通知の配信を目的とした特化ツールの必要性と開発

### メッセージングシステム
#### メッセージングシステムの役割
* 新しいイベントをコンシューマに通知するために利用される
* プロデューサがイベントを含むメッセージを送信し、コンシューマ群にプッシュされる

#### 直接通信チャネルの実装
* UnixのパイプやTCP接続など
* シンプルな実装方法だが、送信者と受信者が1つずつ

#### パブリッシュ／サブスクライブモデル
* 複数のプロデューサノードが同じトピックにメッセージを送信
* 複数のコンシューマノードが1つのトピック中のメッセージを受信
* システムにより異なるアプローチが存在し、正しい唯一の回答はない

#### 重要な質問
1. プロデューサの送信速度がコンシューマの処理速度を超えた場合
    * メッセージをドロップする
    * メッセージをキューにバッファリングする
    * バックプレッシャーを適用する（フロー制御）
        * UnixのパイプやTCPはバックプレッシャーを利用
2. キューが大きくなった場合
    * メモリに収まらなくなるとシステムはクラッシュするか
    * メッセージをディスクに書き出すか
        * ディスクアクセスがメッセージングシステムのパフォーマンスに影響を与える可能性

#### ノードクラッシュや一時的なオフライン
* メッセージが失われる可能性
* 永続性のためにはディスクへの書き出しとレプリケーションが必要
* データベースの場合と同様のコストが発生

#### アプリケーションによる許容範囲
* 一部のメッセージが失われることが許容できる場合、スループットと低レイテンシが向上
* 例: 定期的に転送されるセンサーの測定値やメトリクス
* メッセージが大量に欠落するとメトリクスが不正確になる可能性

#### イベント配信の信頼性
* イベントの数を数える場合、メッセージのロストはカウンタの不正確さを意味する
* 信頼性が重要になる

#### バッチ処理システムの信頼性
* 強い信頼性保証を提供
* 失敗したタスクは自動的にリトライされ、部分的な出力は破棄される
* 出力は障害が起きなかった場合と同じになるため、プログラミングモデルがシンプルに

#### ストリーミングにおける信頼性の保証
* バッチ処理の信頼性保証をストリーミングに適用する方法を検討

#### プロデューサからコンシューマへの直接メッセージング
##### 直接ネットワーク通信の利用
* 一部のメッセージングシステムは中間ノードを介さず、プロデューサとコンシューマ間で直接通信
* レイテンシが重要な金融業界では、株式市場のフィードにUDPマルチキャストが広く使用される

##### UDPマルチキャスト
* UDPは信頼性が低いが、アプリケーションレベルのプロトコルでリカバリ可能
* プロデューサは送信パケットを記憶し、必要に応じて再送

##### メッセージングライブラリの利用
* ZeroMQやnanomsgはブローカーを持たず、TCPやIPマルチキャスト上でパブリッシュ／サブスクライブを実装
* StatsDやBrubeckは信頼できないUDPメッセージングを使用し、メトリクス収集とモニタリングを行う
* UDPを使用すると、メトリクスは最善でも近似値になる

##### HTTPやRPCリクエストの利用
* コンシューマがネットワーク上でサービスを公開している場合、プロデューサはHTTPやRPCリクエストを発行
* Webhooksの考え方を背景に、コールバックURLを登録し、イベント発生時にリクエストを発行

##### 設計時の注意点
* ダイレクトメッセージングシステムは設計された状況下でうまく働くが、メッセージロストの可能性をアプリケーションコードが意識する必要がある
* フォールト耐性は限定的で、ネットワーク上でロストしたパケットを検出・再送しても、プロデューサとコンシューマはオンラインであることが前提

##### オフライン時の問題点
* コンシューマがオフラインの場合、到達不能だった間のメッセージを見落とす可能性
* 一部プロトコルでは、配信失敗メッセージをプロデューサがリトライ可能
* プロデューサがクラッシュすると、リトライされるはずだったメッセージのバッファが失われる可能性

#### メッセージブローカー
##### メッセージブローカーの概要
* メッセージブローカー（メッセージキュー）は、メッセージストリームの扱いに最適化された一種のデータベース
* サーバーとして動作し、プロデューサとコンシューマがクライアントとして接続
##### メッセージの送受信
* プロデューサはブローカーにメッセージを書き込み、コンシューマはブローカーからメッセージを読み取る
* データをブローカーに集中させることで、クライアントの接続や切断、クラッシュに容易に耐えられる
* 永続性の問題はブローカーに移る
##### メッセージの永続性
* メッセージをメモリにのみ保持するブローカーもある
* 設定次第では、メッセージをディスクに書き込み、ブローカーのクラッシュ時にもメッセージを保持するものもある
##### 低速なコンシューマへの対応
* 一般的に、ブローカーは無制限のキューイングを行う
* メッセージのドロップやバックプレッシャーは行わないが、設定による変更が可能
* キューイングの結果、コンシューマは非同期で動作
##### メッセージ送信のプロセス
* プロデューサはブローカーによるメッセージのバッファリングを待つだけで、コンシューマによる処理は待たない
* コンシューマへの配送は未確定な将来の時点で行われる
* 通常は数分の1秒以下で配送されるが、バックログがあると遅れることもある

#### メッセージブローカーとデータベースの比較
##### 2相コミットプロトコル
* 一部のメッセージブローカーはXAやJTAを使い、2相コミットプロトコルに参加可能
* これによりデータベースに似た性質を持つが、両者には重要な違いが存在
##### データ保持の違い
* データベース: 明示的に削除されるまでデータを保持
* メッセージブローカー: コンシューマへの配信成功時に自動的にメッセージを削除
* メッセージブローカーは長期間のデータ保存には不適
##### ワーキングセットとキューの長さ
* メッセージブローカー: ワーキングセットが非常に小さく、キューは短いという前提
* 低速なコンシューマによる大量のメッセージバッファリングはスループット低下の原因
##### インデックスと検索方法
* データベース: セカンダリインデックスや多様な検索方法をサポート
* メッセージブローカー: トピックの部分集合をサブスクライブする方法をサポート
##### データのスナップショットと通知
* データベース: クエリ結果はある時点でのスナップショットに基づく
* メッセージブローカー: 任意のクエリはサポートしないが、新しいメッセージがあればクライアントに通知
##### メッセージブローカーの標準と実装
* JMSやAMQPなどの標準にまとめられている
* 代表的なソフトウェア
    * RabbitMQ
    * ActiveMQ
    * HornetQ
    * Qpid
    * TIBCOEnterpriseMessageService
    * IBMMQ
    * AzureServiceBus
    * Google Cloud Pub/Sub

#### 複数のコンシューマ
##### 主なメッセージングパターン
* 複数のコンシューマが同じトピック内のメッセージを読み取る場合、主に使われるパターンは2つ
1. ロードバランシング
    * 各メッセージはどれか1つのコンシューマに配信される
    * 複数のコンシューマがメッセージ処理を分担
    * メッセージの割り当てはブローカーが管理
    * メッセージ処理の負荷が大きく、処理を並列化する場合に有効
    * AMQP: 同じキューからメッセージを消費する複数クライアントで実装
    * JMS: 共有サブスクリプションで実装
2. ファンアウト
    * 各メッセージはすべてのコンシューマに配信
    * 複数の独立したコンシューマが同じメッセージをブロードキャストで受信
    * 複数の異なるバッチジョブが同じ入力ファイルを読み取るのと同等
    * JMS: トピックのサブスクリプションで提供
    * AMQP: Exchangeの対応付けで提供

##### パターンの組み合わせ
* 例: 2つの独立したコンシューマグループが同じトピックをサブスクライブ
* 各グループは全メッセージを受信し、グループ内では1つのノードだけがメッセージを受信

#### 承認と再配信
##### 承認の必要性
* コンシューマがクラッシュする可能性があるため、ブローカーはメッセージの承認を利用
* コンシューマがメッセージを処理し終えたら、明示的にブローカーに通知
* 承認後、ブローカーはメッセージをキューから削除
##### 再配信の仕組み
* ブローカーが承認を受け取らない場合、他のコンシューマにメッセージを再配信
* 再配信は、クライアントがクラッシュやタイムアウトで承認を送れなかった場合に行われる
* 実際には処理済みのメッセージがネットワークの問題で承認されない場合もあり得る
##### メッセージの順序への影響
* 再配信とロードバランシングの組み合わせでメッセージ順序が変わることがある
* 図11-2では、コンシューマ1と2がそれぞれ異なるメッセージを処理中にクラッシュが発生
* 結果として、コンシューマ1はメッセージをm4、m3、m5の順序で処理
* プロデューサの送信順序とは異なる順序で処理されることになる
##### 順序の保証と問題回避
* JMS標準やAMQP標準ではメッセージ順序を保つことが求められる
* ロードバランシングと再配信の組み合わせで順序の変更は避けられない
* 順序の重要性がある場合、コンシューマごとにキューを使うことで問題を回避
* メッセージが互いに独立している場合、順序の変更は問題にならないが、因果関係がある場合は順序が重要

### パーティション化されたログ
##### 一時的な操作と恒久的な記録
* パケットのネットワーク送信やネットワークサービスのリクエストは通常一時的
* 恒久的に記録することも可能だが、一般的ではない
* メッセージブローカーもコンシューマに配信されたメッセージをすぐに消去
##### メッセージングとデータベースの対極的アプローチ
* メッセージブローカーはメッセージングが一時的なものと捉え、恒久的に記録しない
* データベースやファイルシステムはデータを恒久的に記録するものと捉える
##### 導出データ生成への影響
* バッチ処理はリードオンリーな入力データを使用し、繰り返し処理しても入力にダメージを与えない
* AMQP/JMSスタイルのメッセージングは承認によってメッセージが削除されるため、再実行で同じ結果は期待できない
##### 新しいコンシューマの追加
* 新たに追加されたコンシューマは登録時点以降のメッセージを受信
* 以前のメッセージは失われリカバリ不可
* データベースやファイルシステムは過去に書かれたデータをいつでも読むことができる
##### ハイブリッドアプローチ
* データベースの永続性とメッセージングの低レイテンシ通知機能の組み合わせ
* これがログベースメッセージブローカーの背景となる着想

#### メッセージストレージへのログの利用
##### ログの基本概念
* ログは追記のみ可能なディスク上のレコードの並び
* 3章でlog-structuredストレージエンジンとwrite-aheadログとして、5章でレプリケーションとして論じた
##### メッセージブローカーにおけるログの利用
* プロデューサはメッセージをログの末尾に追記し、コンシューマはシーケンシャルにログを読み取る
* コンシューマは末尾に到達したら、新しいメッセージの追記通知を待つ
##### パーティション化によるスケーリング
* ログをパーティション化することでスループットを向上
* 各パーティションは独立して読み書き可能
* パーティションは別々のマシンでホストされ、トピックは同種のメッセージを扱うパーティションのグループ
##### メッセージのシーケンス番号
* ブローカーは各パーティション内で単調増加するシーケンス番号（オフセット）をメッセージに割り当てる
* パーティション内では全順序が保証されるが、複数パーティション間では順序の保証はない
##### ログベースのメッセージブローカーの例
* Apache Kafka: ログベースのメッセージブローカー
* Amazon Kinesis Streams: ログベースのメッセージブローカー
* Twitter DistributedLog: ログベースのメッセージブローカー
* Google Cloud Pub/Sub: ログの抽象化ではなくJMSスタイルのAPIを公開
##### 高スループットと耐障害性
* パーティショニングによって毎秒数百万メッセージのスループットを実現
* メッセージのレプリケーションによって耐障害性を確保

#### 従来のメッセージングとログの比較
##### ログベースアプローチの利点
* 簡単にファンアウト型メッセージングをサポート
* 複数のコンシューマが独立にログを読み取れる
* メッセージを読み取ってもログから削除されない
##### ロードバランシングの方法
* ブローカーは個々のメッセージを割り当てるのではなく、パーティション全体をコンシューマグループのノード集合に割り当てる
* 各クライアントは割り当てられたパーティション内のすべてのメッセージを消費
##### 粒度の粗いロードバランシングの欠点
* トピックの消費作業を共有するノード数は、最大でそのトピックのログパーティション数まで
* 処理に時間がかかるメッセージが1つあると、同じパーティション内のそれ以降のメッセージの処理が滞る（ヘッドオブラインブロッキング）
##### 適用シナリオの比較
* JMS/AMQPスタイルのメッセージブローカー
    * メッセージ処理の負担が大きい場合
    * メッセージ単位で処理を並列化したい場合
    * メッセージの順序がそれほど重要でない場合
* ログベースアプローチ
    * メッセージ処理のスループットが高い必要がある場合
    * メッセージの処理が高速に行える場合
    * メッセージの順序が重要な場合

#### コンシューマのオフセット
##### オフセットによる処理管理
* パーティションをシーケンシャルに処理することで、どのメッセージが処理済みか把握しやすい
* コンシューマの現在のオフセットより小さいメッセージは処理済み、大きいメッセージは未処理
* ブローカーは個々のメッセージの承認を追跡する必要がなく、コンシューマのオフセットを定期的に記録すればよい
##### 管理オーバーヘッドの軽減
* オフセットの記録により管理のオーバーヘッドが減少
* バッチやパイプラインなどの手法が利用可能となり、スループットが向上
##### ログシーケンス番号との類似性
* コンシューマのオフセットはログシーケンス番号に似ている
* データベースのレプリケーションと同様に、切断後の再接続時に処理を再開できる
##### 障害時の処理
* コンシューマノードに障害が発生すると、パーティションはグループ内の他のノードに割り当てられる
* 新たに割り当てられたノードは最後に記録されたオフセットのメッセージから処理を再開
* 障害発生前に処理済みのメッセージが記録されていなければ、再度処理される可能性がある
##### 問題への対処方法
* 詳細は後の章で論じる

#### ディスク領域の利用
##### ディスク領域の管理
* ログに追記を続けるとディスク領域が不足する
* ログをセグメントに分割し、古いセグメントは削除またはアーカイブストレージに移動
* 低速なコンシューマが古いセグメントのオフセットを指すとメッセージが見落とされる可能性
##### 制限付きバッファとしてのログ
* ログは制限されたサイズを持つバッファ（循環バッファやリングバッファとも呼ばれる）
* ディスク上のバッファは非常に大きくできる
##### ディスク容量と書き込みスループットの計算
* 6TBのハードディスク: シーケンシャル書き込みのスループットは150MB/秒
* 上限速度で書き込むとディスクが一杯になるのに約11時間
* 通常の環境では数日から数週間分のメッセージをバッファリング可能
##### スループットの一定性
* すべてのログがディスクに書かれるため、スループットは一定
* メモリにメッセージを保持し、キューが大きくなるとディスクに書き出すシステムとは対照的
* そのようなシステムはキューが短い時は高速だが、ディスク書き込みが始まると低速になる

#### プロデューサにコンシューマがついて行けない場合

* **選択肢の論議**
  * コンシューマがプロデューサのメッセージ送信レートについて行けない場合の選択肢として、メッセージのドロップ、バッファリング、バックプレッシャーの適用がある
  * ログベースのアプローチは固定サイズのバッファリングの一形態

* **バッファの限界**
  * コンシューマが大きく後れを取ると、必要なメッセージがディスク上に保持されているものよりも古くなることがある
  * 古いメッセージは効果的にドロップされる

* **遅延のモニタリング**
  * コンシューマがログの先頭からどの程度遅れているかをモニタリング
  * 遅れが大きくなったら警告を発する

* **運用上のメリット**
  * バッファは大きいため、運用担当者が低速なコンシューマを修正する時間が十分にある
  * コンシューマが遅れ始めても、影響を受けるのはそのコンシューマのみ
  * 他のコンシューマへのサービスに影響はない
  * プロダクションログを実験的に利用してもプロダクションサービスを損なう心配が少ない

* **コンシューマのシャットダウンやクラッシュ**
  * シャットダウンやクラッシュした場合、そのリソース消費は止まり、残るのはそのコンシューマのオフセットのみ
  * 旧来のメッセージブローカーとは対照的で、旧来のブローカーではシャットダウンされたコンシューマのキューを削除しないとメモリを無駄に消費する可能性がある

#### 古いメッセージのリプレイ

* **破壊的操作 vs リードオンリー操作**
  * AMQPやJMSスタイル: メッセージの処理と承認はメッセージの削除を引き起こす破壊的操作
  * ログベースのメッセージブローカー: メッセージの消費はファイルからの読み取りに近く、リードオンリーの操作

* **コンシューマのオフセット**
  * メッセージの処理で唯一生じる副作用はコンシューマのオフセットの前進
  * オフセットはコンシューマが制御可能で、必要に応じて操作できる

* **メッセージの再処理**
  * コンシューマのコピーを作成し、過去のオフセットから再処理可能
  * 昨日のメッセージを再処理し、出力を別の場所に書き出すことができる
  * 処理コードを書き換えながら何度も繰り返し可能

* **ログベースメッセージングの利点**
  * 繰り返し可能な変換プロセスを通じて、データが明確に入力データと分離される
  * 実験やエラーからのリカバリが容易
  * データフローと結合するための優れたツール



## 11.2 データベースとストリーム
* **メッセージブローカーとデータベースの比較**
  * 従来は別々のツールと考えられていた
  * ログベースのメッセージブローカーはデータベースの着想を取り入れ、メッセージングに適用
  * メッセージングやストリーミングの考え方をデータベースに適用することも可能

* **イベントとしてのデータベース操作**
  * イベントは特定の時点での出来事のレコード
  * 出来事はユーザーのアクションやセンサーの値の取得、データベースへの書き込みなど
  * データベースへの書き込みもイベントとして捕捉、保存、処理可能

* **データベースとストリームの深いつながり**
  * レプリケーションログはデータベースへの書き込みイベントのストリーム
  * フォロワーは書き込みストリームを適用し、同じデータの正確なコピーを得る
  * イベントはデータの変化を記述

* **ステートマシンレプリケーション**
  * 各イベントがデータベースへの書き込みを表現
  * 全てのレプリカが同じ順序でイベントを処理することで同じ最終状態に達する
  * イベントストリームの一形態

* **ヘテロなデータシステムの問題と解決策**
  * 異種のデータシステムで生じる問題を検討
  * イベントストリームの着想をデータベースに適用して問題解決を探る

### システムの同期の保持
* **複数技術の組み合わせ**
  * 単一システムで全ての要求を満たすことは難しい
  * 複雑なアプリケーションでは複数の異なる技術を組み合わせる必要がある

* **異なる技術の使用例**
  * OLTPデータベースでユーザーリクエストを処理
  * キャッシュで頻度の高いリクエストの速度を向上
  * 全文検索インデックスで検索クエリを処理
  * データウェアハウスで分析を実行

* **データの同期**
  * データベースで更新されたアイテムはキャッシュ、検索インデックス、データウェアハウスでも更新が必要
  * データウェアハウスの同期は通常ETLプロセスで行われ、バッチ処理を伴う

* **2重書き込みの問題**
  * 2重書き込みは、データが変更された時にアプリケーションがそれぞれのシステムに書き込みを行う
  * 例: データベースに書き込み、検索インデックスを更新、キャッシュを無効化

* **レース条件**
  * 並行にクライアントがアイテムを更新し、タイミングの問題でシステムが不整合になることがある
  * データベースと検索インデックスの最終的な値が異なる場合が生じる

* **並行性と耐障害性の問題**
  * バージョンベクトルのような並行検出の仕組みが必要
  * 一方の書き込みが失敗し、もう一方が成功することでシステムが不整合になる可能性
  * アトミックなコミットの問題が関わり、解決には代償が伴う

* **シングルリーダーによる解決**
  * シングルリーダーでレプリケーションされたデータベースが1つある場合、リーダーが書き込み順序を決定
  * 単一のリーダーが存在しない場合、衝突が起こる可能性
  * データベースがリーダーで、検索インデックスがフォロワーである状況を作ることが望ましいが、実現が難しい場合がある

### 変更データのキャプチャ
* **データベースのレプリケーションログ**
  * 長い間、公開APIではなくデータベースの内部実装の詳細と見なされていた
  * クライアントはデータベースのデータモデルとクエリ言語を通じてデータベースにアクセス
  * レプリケーションログをパースしてデータを取り出す方法は存在しなかった

* **過去の問題**
  * 書き込まれた変更のログを取得するドキュメント化された方法がなかった
  * データベースの変更を取得し、他のストレージ技術にレプリケーションすることが難しかった

* **変更データキャプチャ（CDC）**
  * データベースに書かれたすべての変更を観察し、他のシステムへレプリケーションできる形で取り出すプロセス
  * 最近関心が高まっている

* **CDCの利点**
  * 書き込まれた変更がすぐにストリームとして利用できる場合に特に有用
  * データベースへの変更をキャプチャし、同じ変更を検索インデックスに適用可能
  * 変更が同じ順序で適用されるなら、検索インデックスとデータベースのデータが一致する

* **導出データシステムの役割**
  * 図11-5のように、検索インデックスやその他の導出データシステムは変更のストリームのコンシューマ

#### 変更データキャプチャの実装
* **導出データシステム**
  * ログのコンシューマは導出データシステムと呼ばれる
  * 検索インデックスやデータウェアハウスに保存されたデータは記録のシステムの別の見方

* **変更データキャプチャ（CDC）の目的**
  * 記録のシステムの変更を導出データシステムに反映させる
  * 導出システムのデータが正確なコピーであることを保証

* **CDCの基本構造**
  * 1つのデータベースをリーダー（変更をキャプチャされるもの）とし、他のシステムをフォロワーとする
  * ログベースのメッセージブローカーはメッセージの順序を保持し、変更イベントを転送するのに適している

* **CDCの実装方法**
  * データベーストリガを使用: すべての変更を監視し、変更ログのテーブルにエントリを追加
    * トリガは壊れやすく、パフォーマンス上のオーバーヘッドが大きい
  * レプリケーションログをパースする方法: 頑健だがスキーマ変更の課題がある

* **実際の利用例**
  * LinkedInのDatabus、FacebookのWormhole、Yahoo!のSherpa: 大規模環境で利用
  * BottledWater: PostgreSQL用のwrite-aheadログをデコードするAPIを使用
  * MaxwellとDebezium: binlogをパースしてMySQLで実現
  * Mongoriver: MongoDBのoplogを読み取り
  * GoldenGate: Oracle用の同様の機能

* **非同期のメリットと欠点**
  * 記録のシステムは変更がコンシューマに反映されるのを待たずにコミット
  * 低速なコンシューマを追加しても記録のシステムに影響が少ない
  * レプリケーションラグに関する問題が当てはまる

#### 初期のスナップショット
* **ログの役割**
  * データベースに適用されたすべての変更のログをリプレイすることで、データベースの状態を再構築できる

* **ログの制約**
  * すべての変更を永久に保持するとディスク領域が大きくなりすぎ、リプレイにも時間がかかる
  * ログは切り詰める必要がある

* **完全なコピーの必要性**
  * 新たに全文検索インデックスを構築するにはデータベース全体の完全なコピーが必要
  * 直近の変更ログだけでは、過去に更新されたアイテムを見落とす可能性がある

* **一貫したスナップショット**
  * ログの完全な履歴を持たない場合、一貫したスナップショットから始める必要がある
  * スナップショットは変更ログの既知の位置やオフセットに対応する必要がある
  * スナップショット後にどこから変更を適用し始めるかを特定する必要がある

* **CDCツールの機能**
  * CDCツールの中にはスナップショット機能が統合されているものがある
  * 一部のツールではスナップショットを手作業で行う必要がある

### ログのコンパクション

* **ログのコンパクションの重要性**
  * 保存するログの履歴が制限されている場合、新たに導出データシステムを追加する際にスナップショットが必要
  * ログのコンパクションはこれに対する優れた代替策を提供

* **コンパクションの原則**
  * 同じキーを持つログのレコードを探し、重複を廃棄
  * 最新の更新だけを保持
  * コンパクションとマージはバックグラウンドで動作

* **特別な値の処理**
  * null値（墓石）での更新は削除を示す
  * 上書きされない限り、キーはログに永遠に残る

* **必要な容量**
  * ログに必要な容量は過去の書き込み数ではなく、データベースの現時点の内容に依存

* **ログベースメッセージブローカーへの応用**
  * CDCシステムがすべての変更に主キーを持ち、最新の書き込みだけを保持することでコンパクションが有効
  * 新しいコンシューマはコンパクションされたログのオフセット0からスタートし、全メッセージをシーケンシャルにスキャン可能

* **完全なコピーの取得**
  * コンパクションされたログを使用して、データベースのスナップショットを取り直すことなく完全なコピーを取得可能

* **Apache Kafkaのサポート**
  * Kafkaはこのログコンパクション機能をサポート
  * メッセージブローカーが永続性のあるストレージとしても利用可能

#### 変更ストリームのためのAPIサポート

* **変更ストリームの第一級インターフェースとしてのサポート**
  * CDCが後付けの改良やリバースエンジニアリングではなく、第一級のインターフェースとしてサポートされるように

* **具体例**
  * RethinkDB: クエリ結果の変更通知をサブスクライブ可能
  * Firebase、CouchDB: 変更フィードに基づくデータの同期を提供
  * Meteor: MongoDBのoplogを使用してデータの変更をサブスクライブし、UIを更新
  * VoltDB: トランザクションをストリーム形式でエクスポート
    * リレーショナルデータモデルを使用
    * コミットされたトランザクションのタプルログを含む
    * 外部のコンシューマが非同期にログを消費

* **KafkaConnect**
  * 幅広いデータベースシステムをKafkaと結合するためのCDCツール
  * 変更イベントのストリームをKafkaで利用し、検索インデックスの更新やストリーム処理システムに流すことが可能



### イベントソーシング
* **概要**
  * イベントソーシングはドメイン駆動設計（DDD）のコミュニティで開発された手法
  * ストリーミングシステムに有益で関連性のある概念を取り入れている

* **変更データキャプチャ（CDC）との違い**
  * CDC: データベースをミュータブルな方法で利用し、レコードを更新・削除
    * 変更のログは低レベルで取り出され、書き込みの順序が保証される
    * アプリケーションはCDCの存在を意識しない
  * イベントソーシング: アプリケーションのロジックをイベントログに基づいて構築
    * イミュータブルなイベントのみを追記し、更新・削除は抑制または禁止
    * イベントはアプリケーションレベルでの出来事を反映

* **イベントソーシングの利点**
  * データモデリングの強力な手法
  * ユーザーのアクションをイミュータブルなイベントとして記録
  * アプリケーションの進化が容易になり、デバッグが支援される
  * バグに対する保護機能

* **具体例**
  * 「学生が講義への参加をキャンセルした」というイベントを保存することでアクションの意図を明確に表現
  * 新しい機能が追加された場合、既存のイベントから新しい副作用を容易に切り離せる

* **時系列データモデルとの相似性**
  * 時系列データモデルやスタースキーマのイベントログとファクトテーブルに似ている
  * 特化したデータベース（例: EventStore）も開発されているが、特定のツールに依存しない

* **ツールの使用**
  * 旧来のデータベースやログベースのメッセージブローカーもイベントソーシングスタイルのアプリケーション構築に使用可能

#### イベントログからの現在の状態の導出
* **ユーザーのニーズ**
  * ユーザーが知りたいのはシステムの変更履歴ではなく、現在の状態
  * 例: ショッピングサイトでユーザーはカートの現在の内容を見たい

* **イベントソーシングのアプローチ**
  * イベントログをアプリケーションの状態に変換
  * ユーザーに提示するのに適した形にする

* **変換ロジック**
  * 再実行で同じ状態が導出できるよう、ロジックは決定的であるべき
  * 任意のロジックを使用可能

* **ログのコンパクションの違い**
  * CDCの場合:
    * レコードの更新イベントには新しいバージョン全体が含まれる
    * プライマリキーの直近のイベントが現在の値を決定
    * ログのコンパクションで以前のイベントを廃棄可能
  * イベントソーシングの場合:
    * イベントは高レベルでモデル化
    * イベントはユーザーのアクションの意図を表現
    * 後のイベントは先行するイベントを置き換えない
    * 最終的な状態を再構築するためには完全な履歴が必要

* **スナップショットの利用**
  * イベントソーシングアプリケーションは現在の状態のスナップショットを保存する仕組みを持つ
  * 繰り返しログ全体を再処理する必要がない
  * これは読み取りとクラッシュからのリカバリを高速化するための最適化

* **完全なイベントログの保存**
  * システムはすべての生のイベントを恒久的に保存
  * 必要に応じて完全なイベントログを再処理できるようにする

* **次の議論**
  * この前提について「11.2.4.4イミュータビリティの限界」で論じる

#### コマンドとイベント
* **イベントソーシングの哲学**
  * イベントとコマンドを慎重に区別
  * ユーザーからのリクエストは最初はコマンド
  * コマンドは整合性の条件に違反する可能性があり失敗するかもしれない
  * コマンドの検証に成功し受け付けられたらイベントになる
  * イベントは永続性を持ち、イミュータブル

* **コマンドの例**
  * ユーザー名の登録、飛行機や劇場の席の予約
  * アプリケーションはそのリソースが既に取られていないかをチェックする必要がある
  * チェックが成功したら、対応するイベントを生成

* **イベントの特性**
  * イベントが生成された時点でそれはファクトとなる
  * 予約の変更やキャンセルも新たなイベントとして記録
  * イベントストリームのコンシューマはイベントを拒否できない
  * イベントはログのイミュータブルな一部になる

* **コマンドの検証**
  * コマンドがイベントになる前にすべての検証を同期的に行う必要がある
  * 検証とイベント公開はアトミックに行うことが求められる

* **検証の手法**
  * 直列化可能なトランザクションでコマンドを検証してイベントを公開
  * 別の方法として、予約リクエストを一時的な予約イベントと確認イベントに分割
  * 検証を非同期に行えるようにするための方法

### 状態、ストリーム、イミュータビリティ
* **バッチ処理とイミュータビリティ**
  * バッチ処理は入力ファイルのイミュータビリティの恩恵を受ける
  * 既存の入力ファイルに影響を与えずに実験的な処理を実行可能

* **イベントソーシングとCDCの強力さ**
  * イミュータビリティの原則がイベントソーシングや変更データキャプチャの強力さの理由

* **データベースの現在の状態**
  * データベースはアプリケーションの現在の状態を保存
  * 読み取りに対して最適化され、クエリ処理に便利

* **状態の変化とイミュータビリティ**
  * 状態は変化し、データベースは挿入、更新、削除をサポート
  * 変化の原因は一連のイベント
  * イミュータブルなイベントがミュータブルな状態を作る

* **イベントと状態の関係**
  * すべての変更ログ（changelog）は状態の進化を表現
  * アプリケーションの状態はイベントストリームを積分して得られる
  * 変更ストリームは状態を微分して得られる

* **永続性と状態の再現**
  * 永続性を持たせてchangelogを保存すると状態の再現が可能
  * イミュータブルなイベントログからミュータブルな状態が導出される

* **Pat Hellandの見解**
  * トランザクションログはデータベースに対するすべての変更を記録
  * 高速な追記だけがログを変更する方法
  * データベースの内容はログの最新レコードの値をキャッシュ
  * データベースはログの部分集合のキャッシュ

* **ログのコンパクション**
  * 各レコードの最新バージョンだけを残し、上書きされたバージョンは破棄
  * ログとデータベースの状態との差異を橋渡しする方法

#### イミュータブルなイベントの利点

* **イミュータビリティの歴史**
  * 会計士は金融簿記にイミュータビリティを使用
  * 取引は追記だけが行われる台帳に記録され、間違いがあっても取引は消去されず、修正取引が追加される

* **監査性の重要性**
  * 金融システムだけでなく、他の多くのシステムにもメリットがある
  * バグのあるコードがデータベースに書き込まれた場合、破壊的な上書きがなければリカバリが容易

* **情報の保持**
  * イミュータブルなイベントログは現在の状態だけでなく過去の状態も捉える
  * 例: ショッピングサイトでカートに追加された商品が削除されても、その情報はログに残る

#### イベントログからの複数のビューの導出

* **ミュータブルな状態とイミュータブルなイベントログの分離**
  * 同じイベントログから複数の表現を導出可能
  * 例: 分析データベースのDruid、分散キー‐バリューストアのPistachio、KafkaConnectのsink

* **アプリケーションの進化**
  * イベントログからの明示的な変換ステップにより、新機能の追加が容易
  * 既存のシステムを修正せずに新しいビューを構築し共存させることが可能

* **データの保存とアクセスの分離**
  * データの保存は単純明快になり、スキーマ設計やインデックス付けの複雑さを軽減
  * CQRS（コマンドクエリ責務分離）という考え方に基づく
  * 書き込みに最適化されたイベントログから読み取りに最適化されたビューを導出

* **具体例**
  * Twitterのホームタイムライン: フォローしている人々のツイートのキャッシュ
  * 読み取りに最適化された状態の例であり、高度に非正規化されているが管理された状態を保つ

#### 並行性の制御
* **イベントログの非同期性**
  * イベントログのコンシューマは通常非同期であるため、ログへの書き込みがビューに反映されないことがある
  * 「5.2.1自分が書いた内容の読み取り」で論じた問題と解決策

* **同期的なビューの更新**
  * ログへのイベントの追記とビューの更新を同期的に行う
  * 複数の書き込みをアトミックな単位にまとめる必要がある
  * イベントログとビューを同じストレージシステムに保持するか、分散トランザクションを使用

* **イベントログからの状態導出**
  * イベントログから現在の状態を導出することで並行性制御がシンプルになる
  * ユーザーアクションを自己完結したイベントとして設計
  * 1カ所に1回の書き込みだけで済むのでアトミックにすることが容易

* **パーティショニング**
  * イベントログとアプリケーションの状態が同じようにパーティショニングされている場合、並行性制御が不要
  * 単純明快なシングルスレッドのログのコンシューマが書き込みを処理

* **複数の状態パーティションへの影響**
  * あるイベントが複数の状態パーティションに影響を与える場合、追加の処理が必要

#### イミュータビリティの限界
* **イミュータビリティの依存**
  * 多くのシステムがイミュータブルなデータ構造やマルチバージョンデータを使用
  * Git、Mercurial、Fossilなどのバージョン管理システムもイミュータビリティに依存

* **イミュータブルな履歴の現実性**
  * データセットの操作頻度に依存
  * データが追加されるだけで変更や削除が少ない場合はイミュータブルにするのが容易

* **更新や削除が頻繁な場合**
  * イミュータブルな履歴が大きくなりすぎる
  * 断片化が問題になり、コンパクションやガベージコレクションのパフォーマンスが重要

* **データ削除の必要性**
  * プライバシー規定やデータ保護の法律によりデータ削除が必要な場合
  * ログに削除の印を追加するだけでは不十分で、履歴を書き直す必要がある

* **削除の難しさ**
  * データの完全な削除は難しい
  * ストレージエンジンやファイルシステムは新しい場所に書き込みを行う
  * バックアップはイミュータブルであることが多い

* **Datomicの切除とFossilの回避**
  * Datomicでは切除（excision）機能があり、Fossilには回避（shunning）という概念がある

* **本当にデータを削除するのは難しい**
  * データを取り出しにくくすることが目的
  * 「12.4.2.6法律と自己規制」でさらなる課題を論じる


## 11.3 ストリームの処理
* **ストリームの出所**
  * ユーザーのアクティビティイベント
  * センサー
  * データベースへの書き込み

* **ストリームの転送方法**
  * 直接のメッセージング
  * メッセージブローカー
  * イベントログ

* **ストリームの処理方法**
  * **データの書き込み**
    * データベース、キャッシュ、検索インデックスなどへの書き込み
    * 図11-5に示されるように、システムの他の部分で起きている変化と同期させる
    * 特に、ストリームのコンシューマがデータベースに書き込みを行う唯一のクライアントである場合に有効
  * **ユーザーへの通知**
    * メールでのアラート送信
    * 通知のプッシュ
    * リアルタイムダッシュボードへのイベントストリーミング
    * 最終的なコンシューマは人間
  * **ストリームの変換**
    * 1つ以上の入力ストリームを処理し、1つ以上の出力ストリームを生成
    * 複数の処理ステージからなるパイプラインを通過することもある
    * 最終的な出力（データの書き込みやユーザーへの通知）に至る

* **ストリーム処理のコード**
  * オペレータまたはジョブと呼ばれる
  * UnixのプロセスやMapReduceのジョブと密接に関係
  * データフローのパターンも似ている
  * 入力ストリームを読み取り専用で処理し、出力を他の場所に追記のみで書き出す

* **パーティショニングと並列化**
  * 10章で論じたMapReduceやデータフローエンジンのパターンに類似

* **ストリーム処理とバッチ処理の違い**
  * ストリームには終わりがない
  * 終わりのないデータセットではソートは意味を持たない
  * ソートマージ結合は使えない
  * 耐障害性のための仕組みが異なる
    * 数分間動作していたバッチジョブは失敗したタスクを最初からやり直せる
    * 数年にわたって動作していたストリーミングジョブはクラッシュ後に最初からやり直すことは現実的ではない

### ストリーム処理の利用
* **モニタリング用途**
  * 特定の事象発生時にアラートを通知
  * **例**
    * 不正検知システム：クレジットカード利用パターンの変化を監視し、異常があれば利用を停止
    * 証券取引システム：市場価格の変動を監視し、特定のルールに基づいて取引を実行
    * 製造業システム：工場内の機械の状態を監視し、異常があれば即時対応
    * 軍隊や諜報システム：攻撃の可能性がある人物の活動を追跡し、兆候があればアラートを発する

* **その他のストリーム処理の利用方法**
  * 比較と違いの明示

#### 複合イベント処理

* **複合イベント処理（CEP）**
  * 1990年代に発展
  * イベントストリームの解析を目的
  * 特定のイベントパターンの検出に特化

* **CEPの機能**
  * **ルール指定**
    * 正規表現が文字列中のパターンを検索するように、CEPではストリーム中のイベントパターンを検索
  * **クエリ言語**
    * SQLのような高レベルの宣言的クエリ言語やグラフィカルなユーザーインターフェースを使用
  * **処理エンジン**
    * ステートマシンを管理し、パターンマッチングを実行
    * パターンが見つかると、複合イベント（complex event）を出力

* **クエリとデータの関係性**
  * **データベース**
    * データを永続的に保存、クエリは一時的
  * **CEPエンジン**
    * クエリは長期間保存、イベントはエンジン内を連続的に流れる

* **CEPエンジンの実装例**
  * Esper
  * IBM InfoSphere Streams
  * Apama
  * TIBCO StreamBase
  * SQLstream
  * 分散ストリームプロセッサ（例：Samza）

#### ストリーム分析

* **ストリーム分析の特徴**
  * 大量のイベントに対するメトリクスの集計や統計に焦点
  * 特定のイベントの並びを見つけることへの関心は低い

* **ストリーム分析の例**
  * **イベントレートの計測**
    * 一定期間内の発生頻度の計測
  * **移動平均の計算**
    * 一定期間内の値の移動平均
  * **統計の比較**
    * 過去の期間との比較、トレンドの検出、アラートの発行

* **集計の期間**
  * ウィンドウと呼ばれる
  * 例：直近の5分間のサービスに対する秒あたりの平均クエリ数、99パーセンタイルのレスポンスタイム

* **確率的アルゴリズムの使用**
  * **例**
    * ブルームフィルタ：集合のメンバーシップのため
    * HyperLogLog：カーディナリティの推定
    * パーセンタイル推定アルゴリズム
  * **利点**
    * メモリ使用量が少ない

* **ストリーム処理フレームワーク**
  * **オープンソース**
    * Apache Storm
    * Spark Streaming
    * Flink
    * Concord
    * Samza
    * Kafka Streams
  * **ホストサービス**
    * Google Cloud Dataflow
    * Azure Stream Analytics

#### マテリアライズドビューの管理
* **導出データシステムの同期**
  * データベース変更のストリームを利用してキャッシュ、検索インデックス、データウェアハウスを同期
  * マテリアライズドビューのメンテナンス事例として考えられる

* **イベントソーシングとマテリアライズドビュー**
  * アプリケーションの状態はイベントログを適用して管理される
  * アプリケーションの状態もマテリアライズドビューの一種

* **ログのコンパクション**
  * 不要なイベントを除去
  * 任意の期間内のすべてのイベントが必要な場合がある

* **ストリームプロセッサの利用**
  * 永久にイベントを管理する必要があるため、分析指向フレームワークには反する
  * SamzaやKafkaStreamsはKafkaのログコンパクションをサポート

#### ストリームでの検索

* **検索機能**
  * 全文検索のクエリのように複合的な条件に基づいて個々のイベントを検索
  * メディアモニタリングサービスや不動産Webサイトなどで利用

* **Elasticsearchのpercolator**
  * ストリーム検索を実装するための選択肢
  * クエリを保存し、ドキュメントがクエリに通される

* **検索最適化**
  * ドキュメントだけでなくクエリにもインデックスを付け、マッチするクエリの集合を狭める

#### メッセージパッシングとRPC

* **メッセージパッシングシステム**
  * RPCの代わりとして利用
  * アクターモデルでのサービス間通信の仕組み

* **アクターフレームワークとストリーム処理**
  * アクターフレームワークはモジュール群の並行性と分散実行を管理
  * ストリーム処理は主にデータ管理の手法

* **アクター間通信とイベントログ**
  * アクター間の通信は一対一で短期間
  * イベントログは永続性があり、複数のサブスクライバを持つ

* **非循環パイプライン**
  * ストリームプロセッサは非循環パイプライン内にセットアップ
  * ジョブの出力としてストリームが生成される

* **Apache Stormの分散RPC**
  * イベント処理ノードにユーザーのクエリ処理を任せる
  * クエリが入力ストリームからのイベントに混ぜ込まれ、結果が集計される

* **アクターフレームワークでのストリーム処理**
  * クラッシュ時のメッセージ配信保証がないため、リトライのロジックを追加する必要がある


### 時間に関する考察
* **時間のウィンドウの利用**
  * 例: 「直近の5分間の平均」
  * バッチ処理ではイベントのタイムスタンプを基に処理
  * ストリーム処理では処理時刻を基にウィンドウを決定することが多い

* **処理時刻とイベント時刻**
  * バッチ処理は決定的であるため、同じ入力に対して同じ結果が得られる
  * ストリーム処理はシンプルだが、処理の遅延が大きいと問題が生じる

#### イベントの時刻（event time）と処理の時刻（processing time）
* **処理遅延の原因**
  * キューイング、ネットワーク障害、メッセージブローカーのパフォーマンス問題、コンシューマの再起動など
  * メッセージの遅延はメッセージの順序を予想できなくする

* **順序の問題**
  * 例: ユーザーのリクエストが異なるサーバーで処理され、順序が逆になる場合

* **具体例**
  * スターウォーズのエピソード番号と公開日の違い
  * 非連続性に対処するためのストリーム処理アルゴリズムの工夫が必要

* **データの不整合**
  * 例: リクエストのレートを計測するストリームプロセッサがシャットダウンと復帰を繰り返すと、異常なリクエストスパイクが発生する可能性

#### 準備ができていることの確認

* **ウィンドウ内のイベント受信確認の難しさ**
  * 特定のウィンドウ内のイベントをすべて受信したかの判断が難しい

* **ウィンドウ処理のタイミング**
  * イベントが37分台のウィンドウにカウントされてから時間が経過
  * どの時点でウィンドウの処理が完了したと宣言すべきかの判断

* **選択肢**
  * **無視**: はぐれイベントを無視し、ドロップされたイベント数をメトリクスとして追跡
  * **訂正**: ウィンドウに対する値を訂正し、はぐれイベントを含めて更新
    * 特別なメッセージでウィンドウの完了を通知する方法もある
    * 複数のプロデューサがイベントを生成している場合、それぞれを個別に追跡する必要がある

#### 結局のところ、どのクロックを使っているのか？

* **イベントタイムスタンプの割り当ての難しさ**
  * イベントがシステム中でバッファリングされる場合の問題
  * モバイルアプリケーションの利用状況メトリクスの例

* **デバイスのオフライン使用**
  * イベントをデバイス上にローカルでバッファ
  * インターネット接続が利用可能になった時点でサーバーに送信

* **遅延したはぐれイベントの問題**
  * 極端に遅延したイベントとして見える
  * イベントのタイムスタンプは実際にユーザーとのやりとりが生じた時間であるべき

* **デバイスのクロックの信頼性問題**
  * ユーザーが制御するクロックは信頼できないことが多い
  * 間違った時間に設定されている場合がある

* **サーバーのクロックの正確性**
  * 管理者の制御下にあるため正確
  * ユーザーとのやりとりを反映しにくい

* **不正確なデバイスのクロックを調整する方法**
  * 3つのタイムスタンプをログに記録
    * イベントの発生時刻（デバイスのクロック）
    * イベントがサーバーへ送信された時刻（デバイスのクロック）
    * イベントがサーバーに受信された時刻（サーバーのクロック）

* **クロックオフセットの推定**
  * イベント送信時刻と受信時刻の差分でオフセットを推定
  * 推定されたオフセットをイベント発生時刻に適用

* **バッチ処理との共通点**
  * ストリーム処理に限らない問題
  * 時間の経過に対する認識の違いによる影響

#### ウィンドウの種類

* **ウィンドウの定義**
  * イベントのタイムスタンプを決定した後、ウィンドウの定義を行う
  * ウィンドウを使ってイベント数のカウントや平均値の計算などの集計を行う

* **タンブリングウィンドウ（Tumbling Window）**
  * 固定長
  * すべてのイベントが厳密に1つのウィンドウに属する
  * 例：1分間のタンブリングウィンドウ
    * 10:03:00から10:03:59までのイベントが1つのウィンドウにグループ化
    * 10:04:00から10:04:59までのイベントが次のウィンドウにグループ化
  * 実装方法：各イベントのタイムスタンプを最も近い分に切り捨て

* **ホッピングウィンドウ（Hopping Window）**
  * 固定長だがウィンドウ同士を重ねる
  * 例：1分のホップサイズを持つ5分間のホップウィンドウ
    * 1つ目のウィンドウ：10:03:00から10:07:59までのイベント
    * 2つ目のウィンドウ：10:04:00から10:08:59までのイベント
  * 実装方法：まず1分間のタンブリングウィンドウを計算し、続いて複数のウィンドウに対して集計

* **スライディングウィンドウ**
  * 一定期間内に起きたすべてのイベントが含まれる
  * 例：5分間のスライディングウィンドウ
    * 10:03:39及び10:08:12に生じたイベントが含まれる可能性
  * 実装方法：時間でソートされたイベントのバッファを管理し、古いイベントを削除

* **セッションウィンドウ**
  * 期間は固定されていない
  * 同じユーザーの時間的に近いすべてのイベントをまとめる
  * ユーザーが一定時間（例：30分間）活動しなかったらウィンドウが終了
  * 主にWebサイトの分析で使用される

### ストリームの結合
* **バッチジョブの結合**
  * 10章で論じたバッチジョブのデータセット結合が、ストリーム処理にも必要
  * ストリームの結合はバッチジョブよりも難しい

* **結合の種類**
  * ストリーム‐ストリーム結合（ウィンドウ結合）
  * ストリーム‐テーブル結合
  * テーブル‐テーブル結合

#### ストリーム‐ストリーム結合（ウィンドウ結合）

* **例: Webサイトの検索機能**
  * 検索されたURLのトレンドを検出
  * 検索クエリと結果を含むイベントをログに記録
  * 検索結果のクリックを別のイベントとしてログに記録
  * クリックスルー率を計算するために、同じセッションIDを持つ検索アクションのイベントとクリックアクションのイベントをまとめる

* **結合の課題**
  * ユーザーが検索を放棄する場合、クリックは発生しないかもしれない
  * 検索とクリックの間隔が数秒から数週間に及ぶ可能性
  * ネットワーク遅延でクリックイベントが検索イベントよりも先に来ることがある

* **適当なウィンドウの選択**
  * 例: 最大1時間離れた検索とクリックを結合

* **イベントの埋め込みの限界**
  * 検索の詳細をクリックイベント内に埋め込むのは結合と等価ではない
  * クリックスルー率を計測するためには検索イベントとクリックイベントの両方が必要

* **結合の実装**
  * ストリームプロセッサが状態を管理
  * セッションIDでインデックス付けされた過去1時間内のすべてのイベントを保持
  * 検索イベントまたはクリックイベントが発生すると、インデックスに追加し、他のインデックスで同じセッションIDを持つ他のイベントをチェック
  * マッチするイベントがあれば、検索結果がクリックされたことを示すイベントを出力
  * マッチするクリックイベントがなく期限切れになった検索イベントがあれば、検索結果がクリックされなかったことを示すイベントを出力

#### ストリーム‐テーブル結合（ストリームのエンリッチ）

* **ユーザーのアクティビティ分析**
  * ユーザーのアクティビティイベントとユーザープロファイルデータベースのバッチジョブ結合
  * ストリームプロセッサ内での連続的な結合が自然

* **入力と出力**
  * 入力: ユーザーIDを含むアクティビティイベントのストリーム
  * 出力: ユーザーIDにプロファイル情報を補ったアクティビティイベントのストリーム

* **データベース情報によるエンリッチ**
  * データベースのルックアップによるプロファイル情報の追加
  * リモートデータベースクエリの遅さと過負荷のリスク

* **ローカルコピーの利用**
  * ストリームプロセッサにデータベースのコピーをロード
  * ネットワークのラウンドトリップを避け、ローカルでクエリを実行
  * インメモリのハッシュテーブルやローカルディスク上のインデックス

* **バッチジョブとの違い**
  * バッチジョブ: データベースのスナップショットを入力
  * ストリームプロセッサ: 長時間動作し、データベースのローカルコピーを最新に保つ必要

* **変更データキャプチャによる解決**
  * アクティビティイベントのストリームとユーザープロファイルデータベースのchangelogをサブスクライブ
  * プロファイルが変更されたらローカルコピーを更新
  * アクティビティイベントとプロファイルの更新の2つのストリームの結合

* **ストリーム‐ストリーム結合との類似点**
  * ストリーム‐テーブル結合: changelogストリームに対して無限の長さを持つウィンドウを使用
  * ストリーム入力に対してウィンドウ管理なし

#### テーブル‐テーブル結合（マテリアライズドビューのメンテナンス）

* **Twitterタイムラインの例**
  * ユーザーがフォローしている人々の最近のツイートを探してマージするのは負担が大きい
  * タイムラインキャッシュが必要
  * キャッシュはユーザーごとの「メール受信ボックス」のようなもので、送信されたツイートが書き込まれる

* **キャッシュのメンテナンスに必要なイベント処理**
  * **新しいツイート**: ユーザーuが新しいツイートを送信したとき、そのツイートはuをフォローしているすべてのユーザーのタイムラインに追加される
  * **ツイートの削除**: ユーザーがツイートを削除したら、そのツイートはすべてのユーザーのタイムラインから削除される
  * **フォロー開始**: ユーザーu1がユーザーu2をフォローし始めたら、u2による最近のツイートがu1のタイムラインに追加される
  * **フォロー停止**: ユーザーu1がユーザーu2のフォローを止めたら、u2のツイートをu1のタイムラインから削除する

* **ストリームプロセッサの実装**
  * ツイートのイベントストリーム（送信および削除）とフォロー関係のイベントストリーム（フォロー開始と停止）が必要
  * 各ユーザーに対するフォロワーの集合を含むデータベースが必要

* **マテリアライズドビューの管理**
  * ストリームの処理は、次のクエリのためのマテリアライズドビューを管理することと対応：
    ```sql
    SELECT follows.follower_id AS timeline_id,
           array_agg(tweets.* ORDER BY tweets.timestamp DESC)
    FROM tweets
    JOIN follows ON follows.followee_id = tweets.sender_id
    GROUP BY follows.follower_id
    ```
  * タイムラインはこのクエリ結果のキャッシュであり、その元になっているテーブルに変更が生じるたびに更新される

#### 結合の時間に対する依存

* **共通点**
  * ストリーム‐ストリーム、ストリーム‐テーブル、テーブル‐テーブルの結合はいずれも、ストリームプロセッサが状態を管理し、他の入力からメッセージが来るとその状態に対してクエリを実行する。
  * イベントの順序が重要であり、正しい順序で結合を行う必要がある。

* **時間に依存する問題**
  * イベントが別々のストリーム上でほぼ同時に発生する場合、どの順序で処理されるかは未定。
  * 例: ストリーム‐テーブル結合で、ユーザーのプロファイル更新後に発生するアクティビティイベントは、新旧どちらのプロファイルと結合されるべきか。
  * 状態が時間とともに変化する場合、結合に使用する時刻が問題になる。

* **販売例**
  * 販売時点で適用される税率は国、州、商品の種類、販売日によって異なる。
  * 販売データを税率のテーブルと結合する際には、販売時点での税率と結合する必要がある。
  * 過去のデータを再処理する場合、結合に使用する税率は再処理時点の税率とは異なる可能性がある。

* **非決定的な結合の問題**
  * 複数のストリームのイベント順序が決定されない場合、結合は非決定的になる。
  * 同じジョブを同じ入力に対して再実行しても、同じ結果が返らない可能性がある。

* **データウェアハウスの対応策**
  * 緩やかに変化する次元（SCD）として対応。
  * 結合されるレコードのバージョンごとにユニークな識別子を使用。
  * 例: 税率が変わるたびに新たな識別子を与え、請求書には販売時点の税率識別子を含める。
  * この方法で結合は決定的になるが、ログのコンパクションは不可能になる。

### 耐障害性
#### バッチ処理の耐障害性

* バッチ処理フレームワークはフォールトに対して容易に耐えられる。
  * MapReduceジョブ内のタスクが失敗しても、他のマシンで再実行可能。
  * 失敗したタスクの出力は破棄され、出力は成功したタスクのみが表示される。
* このアプローチにより、バッチジョブの出力はexactly-once（厳密に一度）セマンティクスを提供。

#### ストリーム処理の耐障害性

* ストリームは無限であり、処理を完了することがないため、タスク完了まで出力を隠すという選択肢はない。
* 耐障害性に対する解決策として以下がある。

#### マイクロバッチ処理とチェックポイント処理

* **マイクロバッチ処理**
  * ストリームを小さなブロックに分割し、ミニバッチとして処理。
  * SparkStreamingで使用され、バッチサイズは通常1秒程度。
  * バッチサイズが小さいとスケジューリングと調整のオーバーヘッドが増加、大きいと遅延が発生。
  * タンブリングウィンドウを暗黙的に提供（処理時刻に基づく）。
  * 大きなウィンドウが必要なジョブでは、マイクロバッチ間で状態を受け渡す必要がある。

* **チェックポイント処理**
  * Apache Flinkのアプローチ。
  * 定期的に状態の循環チェックポイントを生成し、永続ストレージに書き出す。
  * クラッシュ時には直近のチェックポイントから再起動し、最後のチェックポイントからクラッシュまでの間に生成された出力を廃棄。
  * チェックポイント処理はメッセージストリーム中のバリアを引き金に行われる。

* マイクロバッチ処理とチェックポイント処理はexactly-onceセマンティクスを提供するが、出力がストリームプロセッサを離れると問題が発生する。

#### アトミックなコミット

* **アトミックにする必要性**
  * イベントの処理が成功した場合、すべての出力と副作用が有効になることを保証する必要がある。
  * 出力には、メッセージングシステムへのメッセージ送信、データベースへの書き込み、オペレータの状態変更、入力メッセージの承認などが含まれる。
  * すべての操作はアトミックに行われる必要がある。

* **実装例**
  * Google Cloud DataflowやVoltDB、Apache Kafkaの計画された機能で使用されている。
  * 旧来の分散トランザクション（XA）とは異なり、ストリーム処理フレームワーク内での状態の変更とメッセージングを共に管理。

* **プロトコルオーバーヘッドの償却**
  * 複数の入力メッセージを1つのトランザクション内で処理することで、トランザクションプロトコルのオーバーヘッドを償却。

#### 冪等性

* 目標
  * 失敗したタスクの部分的な出力を廃棄し、安全にリトライすること
* 冪等な操作
  * 複数回実行しても一度だけ実行したときと同じ結果になる操作
  * 例: キー‐バリューストアでキーに固定的な値を設定する操作
  * 非冪等な例: カウンタのインクリメント（複数回実行で値が増加）
* メタデータを使用して非冪等な操作を冪等にする方法
  * Kafkaのメッセージに永続的で単調増加するオフセットを利用
  * データベースの更新にオフセットを含めることで、同じ更新を繰り返さない
* 冪等性に依存する前提条件
  * 同じメッセージが同じ順序でリプレイされる
  * 処理は決定的であること
  * 同じ値を並行に他のノードが更新しないこと
  * フェールオーバー時のフェンシングの必要性
* 効率性
  * わずかなオーバーヘッドでexactly-onceセマンティクスを実現可能

#### 障害後の状態の再構築

* 状態を必要とするストリーム処理のリカバリ方法
  * ウィンドウに対する集計やテーブル・インデックスを使う結合
* 状態のリモート保存とレプリケーション
  * メリット: 状態の安全な保存
  * デメリット: リモートクエリの低速化
* 状態のローカル保存と定期的なレプリケーション
  * メリット: 高速なアクセスと障害後の迅速な回復
  * 例: Flinkはオペレータの状態のスナップショットをHDFSに書き込む
  * SamzaとKafkaStreamsは変更データキャプチャを使用し、専用のKafkaトピックに状態変化を送信してレプリケーション
  * VoltDBは各入力メッセージを複数のノードで冗長処理して状態をレプリケーション
* 状態の再構築方法
  * 入力ストリームから再構築可能な場合、レプリケーションは不要
  * 例: 短期間のウィンドウに対する集計は入力イベントをリプレイするだけで高速に再構築可能
  * データベースのローカルレプリカは変更データキャプチャで管理し、ログコンパクションされた変更ストリームから再構築可能
* トレードオフ
  * 状態のローカル保存 vs リモート保存
  * ネットワークの遅延とディスクアクセスのレイテンシの比較
  * ストレージとネットワーキング技術の進化に伴うメリットの変動


## まとめ
### ストリーム処理の概要
* イベントストリームの目的と処理方法を論じる
* ストリーム処理はバッチ処理と似ているが、処理するのは終わることのないストリーム
* メッセージブローカーとイベントログはファイルシステムと同じ役割を果たす

### メッセージブローカーの種類
#### AMQP/JMSスタイルのメッセージブローカー
* 個々のメッセージをコンシューマに割り当て、処理成功時に承認
* 承認されたメッセージはブローカーから削除
* 非同期なRPCに適している
* タスクキューの中では順序処理が重要でなく、メッセージの再読み込みも不要

#### ログベースのメッセージブローカー
* 同じパーティション内のメッセージを同じ順序で配信
* パーティショニングを通じて並列性を実現
* コンシューマは処理メッセージのオフセットをチェックポイント処理で追跡
* メッセージをディスク上に保持し、必要に応じて古いメッセージを読み直せる

##### ログベースアプローチの利点
* レプリケーションログやlog-structuredストレージエンジンに類似
* ストリーム処理システムに適している
* ユーザーイベントやセンサー読み取り、金融データなどのデータソースをストリームとして扱える
* データベースのchangelogを通じて、全変更履歴を捕捉
* ログコンパクションでデータベース内容の完全なコピーを保持

### データベースとストリームの統合
* データベースの変更ログをストリームとして扱うとシステムの結合が強化される
* 導出データシステムは変更ログを消費し、継続的に最新状態を維持
* ゼロから始めて変更ログを消費することで新しいビューを構築可能
* ストリームのリプレイ機能は耐障害性を実現する手法の基礎

### ストリーム処理の目的
* イベントパターンの検索（複合イベント処理）
* ウィンドウ集計の演算（ストリーム分析）
* 導出データシステムの最新状態の維持（マテリアライズドビュー）

### 時間の考察
* 処理の時刻とイベントのタイムスタンプの区別
* ウィンドウ期間が過ぎた後のはぐれイベントの扱い

### ストリーム処理における結合の種類
#### ストリーム‐ストリーム結合
* 両方の入力ストリームがアクティビティイベントを含む
* 時間ウィンドウ内の関連するイベントを検索
* 自己結合の形態もある

#### ストリーム‐テーブル結合
* 片方のストリームがアクティビティイベント、もう片方がデータベース変更ログ
* 結合オペレータがデータベースにクエリを実行し、エンリッチされたイベントを出力

#### テーブル‐テーブル結合
* 両方の入力ストリームがデータベースの変更ログ
* 変更が結合され、マテリアライズドビューに対する変更ストリームとなる

### 耐障害性とexactly-onceセマンティクス
* 部分的な出力を破棄する必要があるが、ストリーム処理は継続的に出力を生成
* マイクロバッチ処理、チェックポイント処理、トランザクション、冪等な書き込みによる細かいリカバリの仕組みを利用